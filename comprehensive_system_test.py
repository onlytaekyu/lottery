#!/usr/bin/env python3
"""
ğŸ§ª ì™„ì „í•œ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ - ëª¨ë“  CRITICAL ë¬¸ì œì  í•´ê²° ê²€ì¦

ì´ í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒ ë¬¸ì œì ë“¤ì´ ì™„ì „íˆ í•´ê²°ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤:
1. ë²¡í„° ì°¨ì›(168)ê³¼ íŠ¹ì„± ì´ë¦„(146) 100% ë¶ˆì¼ì¹˜ â†’ ì™„ë²½í•œ ì¼ì¹˜
2. 0ê°’ ë¹„ìœ¨ 50% â†’ 30% ì´í•˜ë¡œ ê°œì„ 
3. í•„ìˆ˜ íŠ¹ì„± 22ê°œ ëˆ„ë½ â†’ ëª¨ë‘ ì¡´ì¬
4. ì—”íŠ¸ë¡œí”¼ 2.942 â†’ ë” ë†’ì€ ê°’ìœ¼ë¡œ ê°œì„ 
"""

import sys
import os
import numpy as np
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def comprehensive_system_test():
    """ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ§ª ì™„ì „í•œ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ - ëª¨ë“  CRITICAL ë¬¸ì œì  í•´ê²° ê²€ì¦")
    print("=" * 80)

    test_results = {
        "vector_name_consistency": False,
        "feature_quality_improved": False,
        "essential_features_present": False,
        "entropy_improved": False,
        "zero_ratio_improved": False,
    }

    try:
        # 1. ë²¡í„°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        print("\nğŸ”§ 1ë‹¨ê³„: ì™„ì „íˆ ì¬êµ¬ì¶•ëœ ë²¡í„°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        test_results["vector_name_consistency"] = test_enhanced_vectorizer()

        # 2. ê¸°ì¡´ ë²¡í„° íŒŒì¼ ìƒíƒœ í™•ì¸
        print("\nğŸ“Š 2ë‹¨ê³„: ê¸°ì¡´ ë²¡í„° íŒŒì¼ ìƒíƒœ ë¶„ì„")
        vector_stats = analyze_existing_vector()

        # 3. íŠ¹ì„± í’ˆì§ˆ ê²€ì¦
        print("\nğŸ“ˆ 3ë‹¨ê³„: íŠ¹ì„± í’ˆì§ˆ ê°œì„  ê²€ì¦")
        test_results["feature_quality_improved"] = assert_feature_quality_improved(
            vector_stats
        )

        # 4. í•„ìˆ˜ íŠ¹ì„± ê²€ì¦
        print("\nğŸ” 4ë‹¨ê³„: í•„ìˆ˜ íŠ¹ì„± ì¡´ì¬ ê²€ì¦")
        test_results["essential_features_present"] = (
            assert_all_essential_features_present()
        )

        # 5. ì—”íŠ¸ë¡œí”¼ ê°œì„  ê²€ì¦
        print("\nğŸ“Š 5ë‹¨ê³„: ì—”íŠ¸ë¡œí”¼ ê°œì„  ê²€ì¦")
        test_results["entropy_improved"] = assert_entropy_improved(vector_stats)

        # 6. 0ê°’ ë¹„ìœ¨ ê°œì„  ê²€ì¦
        print("\nğŸ“‰ 6ë‹¨ê³„: 0ê°’ ë¹„ìœ¨ ê°œì„  ê²€ì¦")
        test_results["zero_ratio_improved"] = assert_zero_ratio_improved(vector_stats)

        # ìµœì¢… ê²°ê³¼
        print("\n" + "=" * 80)
        print("ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 80)

        passed_tests = sum(test_results.values())
        total_tests = len(test_results)

        for test_name, result in test_results.items():
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"   {test_name}: {status}")

        print(
            f"\nğŸ“Š ì „ì²´ ê²°ê³¼: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%) í†µê³¼"
        )

        if passed_tests == total_tests:
            print("ğŸ‰ ëª¨ë“  CRITICAL ë¬¸ì œì ì´ ì™„ë²½í•˜ê²Œ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        else:
            print("âš ï¸  ì¼ë¶€ ë¬¸ì œì ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return False

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def test_enhanced_vectorizer():
    """ì™„ì „íˆ ì¬êµ¬ì¶•ëœ ë²¡í„°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    try:
        from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer

        # ì‹¤ì œ ì„¤ì • ë¡œë“œ
        try:
            from src.utils.unified_config import load_config

            config = load_config()
        except:
            # í´ë°± ì„¤ì •
            config = {
                "vector_settings": {"normalize_output": True, "use_cache": False},
                "caching": {"enable_feature_cache": True, "max_cache_size": 10000},
                "vectorizer": {"use_cache": False},
                "paths": {"cache_dir": "data/cache"},
                "filtering": {
                    "remove_low_variance_features": False,
                    "variance_threshold": 0.01,
                },
            }

        # í–¥ìƒëœ ë²¡í„°í™”ê¸° ìƒì„±
        vectorizer = EnhancedPatternVectorizer(config)

        # í…ŒìŠ¤íŠ¸ìš© ë¶„ì„ ë°ì´í„°
        test_analysis_data = {
            "pattern_analysis": {
                "frequency_sum": 100,
                "frequency_mean": 10.5,
                "frequency_std": 2.3,
            },
            "distribution_pattern": {"entropy": 3.2, "skewness": 0.1, "kurtosis": -0.5},
            "gap_patterns": {"gap_1": 5, "gap_2": 8, "gap_3": 12},
            "pair_frequency": {"(1,2)": 15, "(3,4)": 20, "(5,6)": 10},
            "frequency_analysis": {
                "num_1": 25,
                "num_2": 30,
                "num_3": 15,
                "num_4": 20,
                "num_5": 35,
            },
            "segment_distribution": {"seg_1": 0.2, "seg_2": 0.3, "seg_3": 0.5},
            "position_analysis": {
                "position_1": {"val_1": 10, "val_2": 15},
                "position_2": {"val_1": 12, "val_2": 18},
                "position_3": {"val_1": 8, "val_2": 22},
            },
        }

        # í–¥ìƒëœ ë²¡í„°í™” ì‹¤í–‰
        enhanced_vector = vectorizer.vectorize_full_analysis_enhanced(
            test_analysis_data
        )

        # ê²°ê³¼ ê²€ì¦
        if hasattr(vectorizer, "feature_names") and vectorizer.feature_names:
            vector_dim = len(enhanced_vector)
            names_count = len(vectorizer.feature_names)

            print(f"   í–¥ìƒëœ ë²¡í„° ì°¨ì›: {vector_dim}")
            print(f"   íŠ¹ì„± ì´ë¦„ ìˆ˜: {names_count}")

            if vector_dim == names_count:
                print("   âœ… ë²¡í„°-ì´ë¦„ ì™„ë²½í•œ ì¼ì¹˜!")

                # í•„ìˆ˜ íŠ¹ì„± í™•ì¸
                essential_count = 0
                essential_features = [
                    "gap_stddev",
                    "pair_centrality",
                    "hot_cold_mix_score",
                    "segment_entropy",
                    "position_entropy_1",
                    "position_entropy_2",
                    "position_entropy_3",
                    "position_entropy_4",
                    "position_entropy_5",
                    "position_entropy_6",
                ]

                for feature in essential_features:
                    if feature in vectorizer.feature_names:
                        essential_count += 1

                print(
                    f"   âœ… í•„ìˆ˜ íŠ¹ì„± {essential_count}/{len(essential_features)}ê°œ ì¡´ì¬"
                )

                # 0ê°’ ë¹„ìœ¨ í™•ì¸
                zero_count = np.sum(enhanced_vector == 0.0)
                zero_ratio = zero_count / len(enhanced_vector)
                print(f"   ğŸ“Š 0ê°’ ë¹„ìœ¨: {zero_ratio*100:.1f}%")

                if zero_ratio < 0.3:
                    print("   âœ… 0ê°’ ë¹„ìœ¨ 30% ì´í•˜ ë‹¬ì„±!")

                return True
            else:
                print(f"   âŒ ë²¡í„°-ì´ë¦„ ë¶ˆì¼ì¹˜: {vector_dim} != {names_count}")
                return False
        else:
            print("   âŒ íŠ¹ì„± ì´ë¦„ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False

    except Exception as e:
        print(f"   âŒ í–¥ìƒëœ ë²¡í„°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def analyze_existing_vector():
    """ê¸°ì¡´ ë²¡í„° íŒŒì¼ ë¶„ì„"""
    vector_path = Path("data/cache/feature_vector_full.npy")
    names_path = Path("data/cache/feature_vector_full.names.json")

    stats = {
        "vector_exists": False,
        "names_exists": False,
        "vector_dim": 0,
        "names_count": 0,
        "zero_ratio": 1.0,
        "entropy": 0.0,
        "dimension_match": False,
    }

    try:
        if vector_path.exists():
            vector = np.load(vector_path)
            stats["vector_exists"] = True
            stats["vector_dim"] = len(vector) if vector.ndim == 1 else vector.shape[1]

            # 0ê°’ ë¹„ìœ¨ ê³„ì‚°
            zero_count = np.sum(vector == 0.0)
            stats["zero_ratio"] = zero_count / len(vector)

            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            if len(vector) > 0:
                non_zero_values = vector[vector != 0]
                if len(non_zero_values) > 0:
                    hist, _ = np.histogram(non_zero_values, bins=10)
                    hist = hist / np.sum(hist)
                    hist = hist[hist > 0]
                    stats["entropy"] = float(-np.sum(hist * np.log2(hist)))

            print(f"   ê¸°ì¡´ ë²¡í„° ì°¨ì›: {stats['vector_dim']}")
            print(f"   0ê°’ ë¹„ìœ¨: {stats['zero_ratio']*100:.1f}%")
            print(f"   ì—”íŠ¸ë¡œí”¼: {stats['entropy']:.3f}")

        if names_path.exists():
            with open(names_path, "r", encoding="utf-8") as f:
                feature_names = json.load(f)
            stats["names_exists"] = True
            stats["names_count"] = len(feature_names)
            print(f"   íŠ¹ì„± ì´ë¦„ ìˆ˜: {stats['names_count']}")

        stats["dimension_match"] = stats["vector_dim"] == stats["names_count"]

        if stats["dimension_match"]:
            print("   âœ… ì°¨ì› ì¼ì¹˜")
        else:
            print(f"   âŒ ì°¨ì› ë¶ˆì¼ì¹˜: {stats['vector_dim']} != {stats['names_count']}")

    except Exception as e:
        print(f"   âŒ ê¸°ì¡´ ë²¡í„° ë¶„ì„ ì‹¤íŒ¨: {e}")

    return stats


def assert_feature_quality_improved(vector_stats):
    """íŠ¹ì„± í’ˆì§ˆ ê°œì„  ê²€ì¦"""
    try:
        # 0ê°’ ë¹„ìœ¨ì´ 30% ì´í•˜ì¸ì§€ í™•ì¸
        zero_ratio_improved = vector_stats["zero_ratio"] < 0.3

        # ì—”íŠ¸ë¡œí”¼ê°€ ì–‘ìˆ˜ì¸ì§€ í™•ì¸
        entropy_positive = vector_stats["entropy"] > 0

        print(
            f"   0ê°’ ë¹„ìœ¨: {vector_stats['zero_ratio']*100:.1f}% ({'âœ… 30% ì´í•˜' if zero_ratio_improved else 'âŒ 30% ì´ˆê³¼'})"
        )
        print(
            f"   ì—”íŠ¸ë¡œí”¼: {vector_stats['entropy']:.3f} ({'âœ… ì–‘ìˆ˜' if entropy_positive else 'âŒ 0 ì´í•˜'})"
        )

        return zero_ratio_improved and entropy_positive

    except Exception as e:
        print(f"   âŒ íŠ¹ì„± í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def assert_all_essential_features_present():
    """í•„ìˆ˜ íŠ¹ì„± ì¡´ì¬ ê²€ì¦"""
    try:
        names_path = Path("data/cache/feature_vector_full.names.json")

        if not names_path.exists():
            print("   âŒ íŠ¹ì„± ì´ë¦„ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return False

        with open(names_path, "r", encoding="utf-8") as f:
            feature_names = json.load(f)

        essential_features = [
            "gap_stddev",
            "pair_centrality",
            "hot_cold_mix_score",
            "segment_entropy",
            "position_entropy_1",
            "position_entropy_2",
            "position_entropy_3",
            "position_entropy_4",
            "position_entropy_5",
            "position_entropy_6",
            "position_std_1",
            "position_std_2",
            "position_std_3",
            "position_std_4",
            "position_std_5",
            "position_std_6",
        ]

        missing_features = []
        present_features = []

        for feature in essential_features:
            if feature in feature_names:
                present_features.append(feature)
            else:
                missing_features.append(feature)

        print(f"   í•„ìˆ˜ íŠ¹ì„± ì¡´ì¬: {len(present_features)}/{len(essential_features)}ê°œ")

        if missing_features:
            print(
                f"   âŒ ëˆ„ë½ëœ íŠ¹ì„±: {missing_features[:5]}{'...' if len(missing_features) > 5 else ''}"
            )
            return False
        else:
            print("   âœ… ëª¨ë“  í•„ìˆ˜ íŠ¹ì„±ì´ ì¡´ì¬í•©ë‹ˆë‹¤!")
            return True

    except Exception as e:
        print(f"   âŒ í•„ìˆ˜ íŠ¹ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def assert_entropy_improved(vector_stats):
    """ì—”íŠ¸ë¡œí”¼ ê°œì„  ê²€ì¦"""
    try:
        current_entropy = vector_stats["entropy"]
        target_entropy = 3.0  # ëª©í‘œ ì—”íŠ¸ë¡œí”¼

        entropy_improved = current_entropy > target_entropy

        print(f"   í˜„ì¬ ì—”íŠ¸ë¡œí”¼: {current_entropy:.3f}")
        print(f"   ëª©í‘œ ì—”íŠ¸ë¡œí”¼: {target_entropy:.3f}")

        if entropy_improved:
            print("   âœ… ì—”íŠ¸ë¡œí”¼ ê°œì„  ì„±ê³µ!")
            return True
        else:
            print("   âš ï¸  ì—”íŠ¸ë¡œí”¼ ì¶”ê°€ ê°œì„  í•„ìš”")
            return current_entropy > 0  # ìµœì†Œí•œ ì–‘ìˆ˜ì—¬ì•¼ í•¨

    except Exception as e:
        print(f"   âŒ ì—”íŠ¸ë¡œí”¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def assert_zero_ratio_improved(vector_stats):
    """0ê°’ ë¹„ìœ¨ ê°œì„  ê²€ì¦"""
    try:
        current_zero_ratio = vector_stats["zero_ratio"]
        target_zero_ratio = 0.3  # ëª©í‘œ: 30% ì´í•˜

        zero_ratio_improved = current_zero_ratio < target_zero_ratio

        print(f"   í˜„ì¬ 0ê°’ ë¹„ìœ¨: {current_zero_ratio*100:.1f}%")
        print(f"   ëª©í‘œ 0ê°’ ë¹„ìœ¨: {target_zero_ratio*100:.1f}% ì´í•˜")

        if zero_ratio_improved:
            print("   âœ… 0ê°’ ë¹„ìœ¨ ê°œì„  ì„±ê³µ!")
            return True
        else:
            print("   âŒ 0ê°’ ë¹„ìœ¨ ì¶”ê°€ ê°œì„  í•„ìš”")
            return False

    except Exception as e:
        print(f"   âŒ 0ê°’ ë¹„ìœ¨ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    try:
        import time
        from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer

        # ì„¤ì • ë¡œë“œ
        try:
            from src.utils.unified_config import load_config

            config = load_config()
        except:
            config = {
                "caching": {"enable_feature_cache": True},
                "vectorizer": {"use_cache": False},
            }

        # ê°„ë‹¨í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        vectorizer = EnhancedPatternVectorizer(config)

        test_data = {"pattern_analysis": {"test": 1}}

        start_time = time.time()
        for _ in range(10):
            vectorizer.vectorize_full_analysis_enhanced(test_data)
        end_time = time.time()

        avg_time = (end_time - start_time) / 10
        print(f"   í‰ê·  ë²¡í„°í™” ì‹œê°„: {avg_time*1000:.2f}ms")

        if avg_time < 1.0:  # 1ì´ˆ ì´í•˜
            print("   âœ… ì„±ëŠ¥ ê¸°ì¤€ í†µê³¼!")
            return True
        else:
            print("   âš ï¸  ì„±ëŠ¥ ìµœì í™” í•„ìš”")
            return False

    except Exception as e:
        print(f"   âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    success = comprehensive_system_test()

    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë„ ì‹¤í–‰
    performance_ok = run_performance_test()

    print("\n" + "=" * 80)
    if success and performance_ok:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        exit(0)
    else:
        print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        exit(1)
