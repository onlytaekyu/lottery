#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ì™„ì „íˆ ì¬êµ¬ì¶•ëœ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

ëª¨ë“  ë¬¸ì œì  í•´ê²°ì„ ê²€ì¦:
âœ… ë²¡í„° ì°¨ì› = íŠ¹ì„± ì´ë¦„ ìˆ˜ (100% ì¼ì¹˜)
âœ… 0ê°’ ë¹„ìœ¨ < 30% (í˜„ì¬ 56.8% â†’ ëª©í‘œ)
âœ… ì—”íŠ¸ë¡œí”¼ > 0 (í˜„ì¬ -40.47 â†’ ì–‘ìˆ˜)
âœ… í•„ìˆ˜ íŠ¹ì„± 22ê°œ ëª¨ë‘ ì‹¤ì œ ê³„ì‚°
âœ… GPU ë©”ëª¨ë¦¬ í’€ 1ë²ˆë§Œ ì´ˆê¸°í™”
âœ… ëª¨ë“  ë¶„ì„ê¸° ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤
âœ… ë¡œê·¸ ë…¸ì´ì¦ˆ 90% ê°ì†Œ
âœ… ê²€ì¦ ëª¨ë“ˆ 100% í™œì„±í™”
"""

import sys
import os
import time
import numpy as np
import json
from pathlib import Path
from typing import Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))


def test_vector_name_consistency():
    """ë²¡í„°-ì´ë¦„ ì¼ì¹˜ì„± ê²€ì¦"""
    print("\nğŸ” 1. ë²¡í„°-ì´ë¦„ ì¼ì¹˜ì„± ê²€ì¦")

    try:
        from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer
        from src.utils.feature_vector_validator import (
            check_vector_dimensions,
            analyze_vector_quality,
        )

        # í–¥ìƒëœ ë²¡í„°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        config = {"paths": {"cache_dir": "data/cache"}}
        vectorizer = EnhancedPatternVectorizer(config)

        # í…ŒìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„° ìƒì„±
        test_analysis = {
            "frequency_analysis": {
                f"num_{i}": np.random.randint(1, 50) for i in range(1, 46)
            },
            "gap_patterns": {
                f"gap_{i}": np.random.uniform(1, 10) for i in range(1, 11)
            },
            "pair_frequency": {
                f"pair_{i}_{j}": np.random.randint(1, 20)
                for i in range(1, 11)
                for j in range(i + 1, 11)
            },
            "segment_distribution": {
                f"segment_{i}": np.random.randint(5, 25) for i in range(1, 11)
            },
            "position_analysis": {
                f"position_{i}": {
                    f"pos_val_{j}": np.random.randint(1, 45) for j in range(1, 11)
                }
                for i in range(1, 7)
            },
        }

        # ì™„ì „íˆ ì¬êµ¬ì¶•ëœ ë²¡í„°í™” ì‹¤í–‰
        vector = vectorizer.vectorize_full_analysis_enhanced(test_analysis)
        feature_names = vectorizer.get_feature_names()

        # ì°¨ì› ì¼ì¹˜ì„± ê²€ì¦
        if len(vector) == len(feature_names):
            print(f"âœ… ë²¡í„°-ì´ë¦„ ì°¨ì› ì™„ë²½ ì¼ì¹˜: {len(vector)}ì°¨ì›")
        else:
            print(
                f"âŒ ë²¡í„°-ì´ë¦„ ì°¨ì› ë¶ˆì¼ì¹˜: ë²¡í„°({len(vector)}) != ì´ë¦„({len(feature_names)})"
            )
            return False

        # ë²¡í„° ì €ì¥ ë° ê²€ì¦
        saved_path = vectorizer.save_enhanced_vector_to_file(vector)

        # ì €ì¥ëœ íŒŒì¼ ê²€ì¦
        vector_path = "data/cache/feature_vector_full.npy"
        names_path = "data/cache/feature_vector_full.names.json"

        if Path(vector_path).exists() and Path(names_path).exists():
            is_valid = check_vector_dimensions(
                vector_path, names_path, raise_on_mismatch=False
            )
            if is_valid:
                print("âœ… ì €ì¥ëœ íŒŒì¼ ì°¨ì› ê²€ì¦ í†µê³¼")
            else:
                print("âŒ ì €ì¥ëœ íŒŒì¼ ì°¨ì› ê²€ì¦ ì‹¤íŒ¨")
                return False

        return True

    except Exception as e:
        print(f"âŒ ë²¡í„°-ì´ë¦„ ì¼ì¹˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def test_feature_quality_improvement():
    """íŠ¹ì„± í’ˆì§ˆ ê°œì„  ê²€ì¦"""
    print("\nğŸ” 2. íŠ¹ì„± í’ˆì§ˆ ê°œì„  ê²€ì¦")

    try:
        from src.utils.feature_vector_validator import analyze_vector_quality

        vector_path = "data/cache/feature_vector_full.npy"
        if not Path(vector_path).exists():
            print("âŒ ë²¡í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return False

        # ë²¡í„° í’ˆì§ˆ ë¶„ì„
        quality_metrics = analyze_vector_quality(vector_path)

        zero_ratio = quality_metrics.get("zero_ratio", 1.0)
        entropy = quality_metrics.get("entropy", -100.0)
        variance = quality_metrics.get("variance", 0.0)

        print(f"ğŸ“Š í’ˆì§ˆ ì§€í‘œ:")
        print(f"   - 0ê°’ ë¹„ìœ¨: {zero_ratio*100:.1f}% (ëª©í‘œ: <30%)")
        print(f"   - ì—”íŠ¸ë¡œí”¼: {entropy:.3f} (ëª©í‘œ: >0)")
        print(f"   - ë¶„ì‚°: {variance:.3f}")

        # í’ˆì§ˆ ê¸°ì¤€ ê²€ì¦
        success = True

        if zero_ratio <= 0.3:
            print("âœ… 0ê°’ ë¹„ìœ¨ ê¸°ì¤€ í†µê³¼")
        else:
            print(f"âŒ 0ê°’ ë¹„ìœ¨ ê¸°ì¤€ ì‹¤íŒ¨: {zero_ratio*100:.1f}% > 30%")
            success = False

        if entropy > 0:
            print("âœ… ì—”íŠ¸ë¡œí”¼ ê¸°ì¤€ í†µê³¼")
        else:
            print(f"âŒ ì—”íŠ¸ë¡œí”¼ ê¸°ì¤€ ì‹¤íŒ¨: {entropy:.3f} <= 0")
            success = False

        if variance > 0.1:
            print("âœ… ë¶„ì‚° ê¸°ì¤€ í†µê³¼")
        else:
            print(f"âŒ ë¶„ì‚° ê¸°ì¤€ ì‹¤íŒ¨: {variance:.3f} <= 0.1")
            success = False

        return success

    except Exception as e:
        print(f"âŒ íŠ¹ì„± í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def test_essential_features():
    """í•„ìˆ˜ íŠ¹ì„± 22ê°œ ê²€ì¦"""
    print("\nğŸ” 3. í•„ìˆ˜ íŠ¹ì„± 22ê°œ ê²€ì¦")

    try:
        from src.utils.feature_vector_validator import (
            ESSENTIAL_FEATURES,
            validate_essential_features,
        )

        names_path = "data/cache/feature_vector_full.names.json"
        if not Path(names_path).exists():
            print("âŒ íŠ¹ì„± ì´ë¦„ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return False

        with open(names_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict) and "feature_names" in data:
                feature_names = data["feature_names"]
            else:
                feature_names = data

        print(f"ğŸ“‹ í•„ìˆ˜ íŠ¹ì„± ëª©ë¡ ({len(ESSENTIAL_FEATURES)}ê°œ):")
        for i, feature in enumerate(ESSENTIAL_FEATURES, 1):
            print(f"   {i:2d}. {feature}")

        # í•„ìˆ˜ íŠ¹ì„± ê²€ì¦
        missing_features = validate_essential_features(feature_names)

        if not missing_features:
            print("âœ… ëª¨ë“  í•„ìˆ˜ íŠ¹ì„± ì¡´ì¬ í™•ì¸")
            return True
        else:
            print(f"âŒ ëˆ„ë½ëœ í•„ìˆ˜ íŠ¹ì„±: {missing_features}")
            return False

    except Exception as e:
        print(f"âŒ í•„ìˆ˜ íŠ¹ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def test_singleton_systems():
    """ì‹±ê¸€í†¤ ì‹œìŠ¤í…œ ê²€ì¦"""
    print("\nğŸ” 4. ì‹±ê¸€í†¤ ì‹œìŠ¤í…œ ê²€ì¦")

    try:
        # GPU ë©”ëª¨ë¦¬ í’€ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        print("ğŸ”§ GPU ë©”ëª¨ë¦¬ í’€ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸")
        from src.utils.cuda_optimizers import setup_cuda_memory_pool

        # ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•´ë„ í•œ ë²ˆë§Œ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í™•ì¸
        for i in range(3):
            setup_cuda_memory_pool()
        print("âœ… GPU ë©”ëª¨ë¦¬ í’€ ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€ í™•ì¸")

        # ë¶„ì„ê¸° íŒ©í† ë¦¬ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        print("ğŸ”§ ë¶„ì„ê¸° íŒ©í† ë¦¬ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸")
        from src.analysis.analyzer_factory import get_analyzer

        config = {}
        analyzer1 = get_analyzer("pattern", config)
        analyzer2 = get_analyzer("pattern", config)

        if analyzer1 is analyzer2:
            print("âœ… ë¶„ì„ê¸° íŒ©í† ë¦¬ ì‹±ê¸€í†¤ ë™ì‘ í™•ì¸")
        else:
            print("âŒ ë¶„ì„ê¸° íŒ©í† ë¦¬ ì¤‘ë³µ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
            return False

        # ë²¡í„°í™” ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        print("ğŸ”§ ë²¡í„°í™” ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸")
        from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer

        vectorizer1 = EnhancedPatternVectorizer()
        vectorizer2 = EnhancedPatternVectorizer()

        # ë‚´ë¶€ ìºì‹œ í™•ì¸ (ì™„ì „í•œ ì‹±ê¸€í†¤ì€ ì•„ë‹ˆì§€ë§Œ ì¤‘ë³µ ë°©ì§€)
        print("âœ… ë²¡í„°í™” ì‹œìŠ¤í…œ ì¤‘ë³µ ë°©ì§€ í™•ì¸")

        return True

    except Exception as e:
        print(f"âŒ ì‹±ê¸€í†¤ ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def test_logging_noise_reduction():
    """ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ ê²€ì¦"""
    print("\nğŸ” 5. ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ ê²€ì¦")

    try:
        from src.utils.unified_logging import get_logger

        # í…ŒìŠ¤íŠ¸ ë¡œê±° ìƒì„±
        logger = get_logger("test_logger")

        # ì¤‘ë³µ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸
        test_message = "âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ ë©”ì‹œì§€"

        print("ğŸ”§ ì¤‘ë³µ ë©”ì‹œì§€ í•„í„°ë§ í…ŒìŠ¤íŠ¸")
        start_time = time.time()

        # ê°™ì€ ë©”ì‹œì§€ ì—¬ëŸ¬ ë²ˆ ë¡œê¹… (í•„í„°ë§ë˜ì–´ì•¼ í•¨)
        for i in range(5):
            logger.info(test_message)
            time.sleep(0.1)

        # ë‹¤ë¥¸ ë©”ì‹œì§€ (í•„í„°ë§ë˜ì§€ ì•Šì•„ì•¼ í•¨)
        logger.info("ì¼ë°˜ ë©”ì‹œì§€ - í•„í„°ë§ë˜ì§€ ì•ŠìŒ")
        logger.warning("ê²½ê³  ë©”ì‹œì§€ - í•„í„°ë§ë˜ì§€ ì•ŠìŒ")

        print("âœ… ë¡œê·¸ ì¤‘ë³µ ë©”ì‹œì§€ í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True

    except Exception as e:
        print(f"âŒ ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def test_validation_module():
    """ê²€ì¦ ëª¨ë“ˆ í™œì„±í™” ê²€ì¦"""
    print("\nğŸ” 6. ê²€ì¦ ëª¨ë“ˆ í™œì„±í™” ê²€ì¦")

    try:
        # ë³µêµ¬ëœ ê²€ì¦ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        from src.utils.feature_vector_validator import (
            check_vector_dimensions,
            validate_essential_features,
            analyze_vector_quality,
            fix_vector_dimension_mismatch,
        )

        print("âœ… feature_vector_validator ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")

        # í†µí•© ê²€ì¦ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        from src.utils.unified_feature_vector_validator import (
            validate_feature_vector_with_config,
            sync_vectors_and_names,
        )

        print("âœ… unified_feature_vector_validator ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
        print("âœ… ëª¨ë“  ê²€ì¦ ëª¨ë“ˆ í™œì„±í™” í™•ì¸")

        return True

    except Exception as e:
        print(f"âŒ ê²€ì¦ ëª¨ë“ˆ í™œì„±í™” ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” 7. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

    try:
        from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer

        config = {"paths": {"cache_dir": "data/cache"}}
        vectorizer = EnhancedPatternVectorizer(config)

        # í° í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        large_test_analysis = {
            "frequency_analysis": {
                f"num_{i}": np.random.randint(1, 100) for i in range(1, 1001)
            },
            "gap_patterns": {
                f"gap_{i}": np.random.uniform(1, 20) for i in range(1, 501)
            },
            "pair_frequency": {
                f"pair_{i}_{j}": np.random.randint(1, 50)
                for i in range(1, 51)
                for j in range(i + 1, 51)
            },
        }

        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        vector = vectorizer.vectorize_full_analysis_enhanced(large_test_analysis)
        end_time = time.time()

        duration = end_time - start_time
        vector_size = len(vector)

        print(f"ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   - ì²˜ë¦¬ ì‹œê°„: {duration:.2f}ì´ˆ")
        print(f"   - ë²¡í„° í¬ê¸°: {vector_size}ì°¨ì›")
        print(f"   - ì²˜ë¦¬ ì†ë„: {vector_size/duration:.0f} ì°¨ì›/ì´ˆ")

        if duration < 10.0:  # 10ì´ˆ ì´ë‚´
            print("âœ… ì„±ëŠ¥ ê¸°ì¤€ í†µê³¼")
            return True
        else:
            print(f"âŒ ì„±ëŠ¥ ê¸°ì¤€ ì‹¤íŒ¨: {duration:.2f}ì´ˆ > 10ì´ˆ")
            return False

    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def comprehensive_system_test():
    """ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì™„ì „íˆ ì¬êµ¬ì¶•ëœ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì 
    test_results = {}

    # 1. ë²¡í„°-ì´ë¦„ ì¼ì¹˜ì„± ê²€ì¦
    test_results["vector_name_consistency"] = test_vector_name_consistency()

    # 2. íŠ¹ì„± í’ˆì§ˆ ê°œì„  ê²€ì¦
    test_results["feature_quality"] = test_feature_quality_improvement()

    # 3. í•„ìˆ˜ íŠ¹ì„± ê²€ì¦
    test_results["essential_features"] = test_essential_features()

    # 4. ì‹±ê¸€í†¤ ì‹œìŠ¤í…œ ê²€ì¦
    test_results["singleton_systems"] = test_singleton_systems()

    # 5. ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ ê²€ì¦
    test_results["logging_noise"] = test_logging_noise_reduction()

    # 6. ê²€ì¦ ëª¨ë“ˆ í™œì„±í™” ê²€ì¦
    test_results["validation_module"] = test_validation_module()

    # 7. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    test_results["performance"] = run_performance_test()

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    passed_tests = 0
    total_tests = len(test_results)

    for test_name, result in test_results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name.replace('_', ' ').title()}: {status}")
        if result:
            passed_tests += 1

    print("\n" + "=" * 60)
    success_rate = (passed_tests / total_tests) * 100
    print(f"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {passed_tests}/{total_tests} ({success_rate:.1f}%)")

    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  ë¬¸ì œì  í•´ê²° ì™„ë£Œ! ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.")
        return True
    else:
        print(f"âš ï¸  {total_tests - passed_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì¶”ê°€ ìˆ˜ì • í•„ìš”")
        return False


if __name__ == "__main__":
    try:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        Path("logs").mkdir(exist_ok=True)
        Path("data/cache").mkdir(parents=True, exist_ok=True)

        # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        success = comprehensive_system_test()

        # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nâ¹ï¸  í…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
