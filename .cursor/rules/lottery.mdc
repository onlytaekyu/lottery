---
description: 
globs: 
alwaysApply: true
---
# ğŸ¯ DAEBAK_AI í”„ë¡œì íŠ¸ í†µí•© ì½”ë”© ë£°

## ğŸ”§ MCP ì„œë²„ í•„ìˆ˜ í™œìš©
- **@filesystem**: íŒŒì¼ ìƒì„±/ìˆ˜ì •/ì‚­ì œ ì‹œ ìš°ì„  ì‚¬ìš©, ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡° íŒŒì•…
- **@codebase**: ê¸°ì¡´ ì½”ë“œ íŒ¨í„´ í™•ì¸ í•„ìˆ˜, ì¤‘ë³µ ë°©ì§€
- **@git**: ë³€ê²½ì‚¬í•­ ì¶”ì , ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ê¸°ë°˜ íŒ¨í„´ ìœ ì§€

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡° (ê³ ì •, ë³€ê²½ ê¸ˆì§€)
src/
â”œâ”€â”€ shared/         # ê³µí†µ íƒ€ì… (LotteryNumber, PatternAnalysis, ModelPrediction)
â”œâ”€â”€ analysis/       # ë¶„ì„ ëª¨ë“ˆ (BaseAnalyzer ìƒì†)
â”œâ”€â”€ core/          # í•µì‹¬ ì—”ì§„ (RecommendationEngine)
â”œâ”€â”€ utils/         # ìœ í‹¸ë¦¬í‹° (í†µí•© ì‹œìŠ¤í…œ)
â”œâ”€â”€ models/        # ML/DL ëª¨ë¸ (BaseModel ìƒì†)
â”‚   â”œâ”€â”€ ml/        # LightGBM, XGBoost, CatBoost, RandomForest
â”‚   â”œâ”€â”€ dl/        # MLP, AE, LSTM, GNN, Transformer
â”‚   â”œâ”€â”€ rl/        # DQN, PPO, Q-table
â”‚   â”œâ”€â”€ bayesian/  # BayesianNN
â”‚   â””â”€â”€ meta/      # MetaLearner
â”œâ”€â”€ evaluation/    # í‰ê°€ ëª¨ë“ˆ (Backtester)
â”œâ”€â”€ pipeline/      # íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ training/      # í›ˆë ¨ ëª¨ë“ˆ
â”œâ”€â”€ environment/   # í™˜ê²½ ì„¤ì •
â””â”€â”€ run/          # ì‹¤í–‰ íŒŒì¼ (wrapperë§Œ)

## âš™ï¸ ì„¤ì • ì ‘ê·¼ ê·œì¹™ (ì—„ê²© ì ìš©)
```python
# âœ… í—ˆìš©ëœ ë°©ì‹
config["training"]["use_filtered_vector"]

# âŒ ê¸ˆì§€ëœ ë°©ì‹
config.get("training", {}).get("use_filtered_vector", False)
safe_get(config, "training.use_filtered_vector")

# í‚¤ ëˆ„ë½ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ
try:
    value = config["required_key"]
except KeyError as e:
    logger.error(f"[ERROR] ì„¤ì • í‚¤ ëˆ„ë½: {str(e)}")
    raise RuntimeError("ì„¤ì • í‚¤ ëˆ„ë½ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
ğŸ“ íŒŒì¼ ê²½ë¡œ ê·œì¹™
python# ê³ ì • ê²½ë¡œ (ë³€ê²½ ê¸ˆì§€)
config_path = "config/config.yaml"
models_dir = "savedModels/{model_name}.pt"
results_dir = "data/result/analysis/"
vectors_dir = "data/cache/feature_vectors_full.npy"
reports_dir = "data/result/performance_reports/"

# âŒ ë‚ ì§œ í¬í•¨ ê¸ˆì§€, ì„ì˜ ê²½ë¡œ ìƒì„± ê¸ˆì§€
ğŸ”¨ ì½”ë”© í‘œì¤€
Import ìˆœì„œ
python# 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os, sys, json, time
from typing import Dict, Any, List, Optional

# 2. ì„œë“œíŒŒí‹°
import numpy as np
import torch
from sklearn.ensemble import RandomForestClassifier

# 3. í”„ë¡œì íŠ¸ ë‚´ë¶€
from ..shared.types import LotteryNumber, ModelPrediction
from ..utils.unified_logging import get_logger
from ..utils.cache_paths import get_cache_dir
í´ë˜ìŠ¤ êµ¬ì¡°
pythonclass AnalyzerExample(BaseAnalyzer):
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config, analyzer_type="example")
        self.logger = get_logger(__name__)
    
    def analyze(self, data: List[LotteryNumber]) -> Dict[str, Any]:
        try:
            # ë©”ì¸ ë¡œì§
            return result
        except SpecificError as e:
            self.logger.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
            # í´ë°± ë¡œì§
        except Exception as e:
            self.logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            raise
ğŸ¯ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê·œì¹™

ëª¨ë¸ í†µí•© ê·œì¹™
python# ë² ì´ìŠ¤ ëª¨ë¸ ìƒì† í•„ìˆ˜
class MyModel(BaseModel):
    def fit(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        # êµ¬í˜„ í•„ìˆ˜
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        # êµ¬í˜„ í•„ìˆ˜
    
    def save(self, path: str) -> bool:
        # êµ¬í˜„ í•„ìˆ˜
    
    def load(self, path: str) -> bool:
        # êµ¬í˜„ í•„ìˆ˜
ğŸš« ê¸ˆì§€ì‚¬í•­ (ì—„ê²© ì ìš©)

âŒ run*.py ë‚´ ì§ì ‘ ë¡œì§ ì‘ì„± (wrapperë§Œ í—ˆìš©)
âŒ torch.save() ì§ì ‘ ì‚¬ìš© (model_saver.py ì‚¬ìš©)
âŒ argparse, CLI ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
âŒ íŒŒì¼ëª…ì— timestamp í¬í•¨
âŒ Trainer í´ë˜ìŠ¤ ì§ì ‘ ìƒì† (UnifiedTrainer ì‚¬ìš©)
âŒ ì°¨ì› ë¶ˆì¼ì¹˜ í—ˆìš© (allow_mismatch=False ê³ ì •)

ğŸ“Š ì„±ëŠ¥ ìµœì í™” ê·œì¹™
python# ë©”ëª¨ë¦¬ ê´€ë¦¬
from ..utils.memory_manager import MemoryManager

# AMP ì‚¬ìš©
from ..utils.cuda_optimizers import AMPTrainer

# ìºì‹œ í™œìš©
from ..utils.cache_paths import get_cache_dir

# í”„ë¡œíŒŒì¼ë§
from ..utils.performance_tracker import performance_monitor