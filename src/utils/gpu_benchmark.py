"""
GPU ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª¨ë“ˆ

DAEBAK_AI Utils ëª¨ë“ˆì˜ GPU ìµœì í™” ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import time
import asyncio
import torch
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import json
import psutil
from concurrent.futures import ThreadPoolExecutor
import gc

from .unified_logging import get_logger
from .performance_optimizer import (
    get_smart_computation_engine,
    smart_compute,
    optimize_computation,
)
from .memory_manager import get_memory_manager
from .normalizer import get_gpu_normalizer, smart_normalize
from .async_io import get_gpu_async_io_manager, smart_read_file, smart_write_file

logger = get_logger(__name__)


@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    test_name: str
    gpu_time: Optional[float] = None
    cpu_time: Optional[float] = None
    multithread_time: Optional[float] = None
    gpu_memory_used: Optional[float] = None
    cpu_memory_used: Optional[float] = None
    throughput_gpu: Optional[float] = None
    throughput_cpu: Optional[float] = None
    speedup_ratio: Optional[float] = None
    success: bool = True
    error_message: Optional[str] = None

    def calculate_speedup(self):
        """ì†ë„ í–¥ìƒ ë¹„ìœ¨ ê³„ì‚°"""
        if self.gpu_time and self.cpu_time and self.gpu_time > 0:
            self.speedup_ratio = self.cpu_time / self.gpu_time
        elif self.multithread_time and self.cpu_time and self.multithread_time > 0:
            self.speedup_ratio = self.cpu_time / self.multithread_time


class GPUBenchmarkSuite:
    """GPU ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ ìŠ¤ìœ„íŠ¸"""

    def __init__(self):
        self.logger = get_logger(__name__)
        self.computation_engine = get_smart_computation_engine()
        self.memory_manager = get_memory_manager()
        self.gpu_normalizer = get_gpu_normalizer()
        self.gpu_io_manager = get_gpu_async_io_manager()

        self.gpu_available = torch.cuda.is_available()
        self.results: List[BenchmarkResult] = []

        if self.gpu_available:
            self.logger.info("GPU ë²¤ì¹˜ë§ˆí¬ ìŠ¤ìœ„íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.logger.warning("GPU ì—†ìŒ - CPU ì„±ëŠ¥ë§Œ ì¸¡ì •")

    def run_all_benchmarks(self) -> Dict[str, Any]:
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        self.logger.info("ğŸš€ GPU ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")

        # 1. ìŠ¤ë§ˆíŠ¸ ì»´í“¨í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬
        self._benchmark_smart_computation()

        # 2. ë©”ëª¨ë¦¬ ê´€ë¦¬ ë²¤ì¹˜ë§ˆí¬
        self._benchmark_memory_management()

        # 3. ì •ê·œí™” ë²¤ì¹˜ë§ˆí¬
        self._benchmark_normalization()

        # 4. ë¹„ë™ê¸° I/O ë²¤ì¹˜ë§ˆí¬
        asyncio.run(self._benchmark_async_io())

        # 5. í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        self._benchmark_integrated_performance()

        # ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
        return self._generate_performance_report()

    def _benchmark_smart_computation(self):
        """ìŠ¤ë§ˆíŠ¸ ì»´í“¨í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬"""
        self.logger.info("ğŸ“Š ìŠ¤ë§ˆíŠ¸ ì»´í“¨í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_sizes = [1000, 10000, 100000, 1000000]

        for size in test_sizes:
            result = BenchmarkResult(f"smart_computation_{size}")

            try:
                # í…ŒìŠ¤íŠ¸ ë°ì´í„°
                data = np.random.randn(size).astype(np.float32)

                def computation_task(arr):
                    if isinstance(arr, torch.Tensor):
                        return torch.mean(arr**2 + torch.sin(arr))
                    else:
                        return np.mean(arr**2 + np.sin(arr))

                # GPU/ë©€í‹°ì“°ë ˆë“œ/CPU ì„±ëŠ¥ ì¸¡ì •
                if self.gpu_available:
                    start_time = time.time()
                    gpu_result = smart_compute(
                        computation_task, data, operation_type="computation"
                    )
                    result.gpu_time = time.time() - start_time
                    result.gpu_memory_used = self.memory_manager.get_memory_usage("gpu")

                # CPU ì„±ëŠ¥ ì¸¡ì •
                start_time = time.time()
                cpu_result = computation_task(data)
                result.cpu_time = time.time() - start_time
                result.cpu_memory_used = self.memory_manager.get_memory_usage("cpu")

                # ì²˜ë¦¬ëŸ‰ ê³„ì‚°
                if result.gpu_time:
                    result.throughput_gpu = size / result.gpu_time
                if result.cpu_time:
                    result.throughput_cpu = size / result.cpu_time

                result.calculate_speedup()

                self.logger.info(
                    f"ë°ì´í„° í¬ê¸° {size}: GPU {result.gpu_time:.3f}s, CPU {result.cpu_time:.3f}s, ì†ë„í–¥ìƒ {result.speedup_ratio:.2f}x"
                )

            except Exception as e:
                result.success = False
                result.error_message = str(e)
                self.logger.error(f"ìŠ¤ë§ˆíŠ¸ ì»´í“¨í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

            self.results.append(result)

    def _benchmark_memory_management(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ ë²¤ì¹˜ë§ˆí¬"""
        self.logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë²¤ì¹˜ë§ˆí¬")

        tensor_sizes = [(1024, 1024), (2048, 2048), (4096, 4096)]

        for size in tensor_sizes:
            result = BenchmarkResult(f"memory_management_{size[0]}x{size[1]}")

            try:
                # ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ í• ë‹¹ í…ŒìŠ¤íŠ¸
                start_time = time.time()

                if self.gpu_available:
                    # GPU ë©”ëª¨ë¦¬ í• ë‹¹
                    tensor = self.memory_manager.smart_memory_allocation(
                        size, prefer_gpu=True
                    )
                    result.gpu_time = time.time() - start_time
                    result.gpu_memory_used = self.memory_manager.get_memory_usage("gpu")

                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    del tensor
                    torch.cuda.empty_cache()

                # CPU ë©”ëª¨ë¦¬ í• ë‹¹
                start_time = time.time()
                cpu_tensor = self.memory_manager.allocate_cpu_memory(size)
                result.cpu_time = time.time() - start_time
                result.cpu_memory_used = self.memory_manager.get_memory_usage("cpu")

                result.calculate_speedup()

                del cpu_tensor
                gc.collect()

                self.logger.info(
                    f"ë©”ëª¨ë¦¬ í• ë‹¹ {size}: GPU {result.gpu_time:.3f}s, CPU {result.cpu_time:.3f}s"
                )

            except Exception as e:
                result.success = False
                result.error_message = str(e)
                self.logger.error(f"ë©”ëª¨ë¦¬ ê´€ë¦¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

            self.results.append(result)

    def _benchmark_normalization(self):
        """ì •ê·œí™” ë²¤ì¹˜ë§ˆí¬"""
        self.logger.info("ğŸ“ ì •ê·œí™” ë²¤ì¹˜ë§ˆí¬")

        data_sizes = [10000, 100000, 1000000]
        methods = ["zscore", "minmax", "robust"]

        for size in data_sizes:
            for method in methods:
                result = BenchmarkResult(f"normalization_{method}_{size}")

                try:
                    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
                    data = np.random.randn(size, 10).astype(np.float32)

                    # GPU ì •ê·œí™”
                    if self.gpu_available:
                        start_time = time.time()
                        gpu_normalized = smart_normalize(data, method=method)
                        result.gpu_time = time.time() - start_time
                        result.gpu_memory_used = self.memory_manager.get_memory_usage(
                            "gpu"
                        )

                    # CPU ì •ê·œí™” (ê¸°ì¡´ ë°©ì‹)
                    start_time = time.time()
                    if method == "zscore":
                        cpu_normalized = (data - np.mean(data, axis=0)) / np.std(
                            data, axis=0
                        )
                    elif method == "minmax":
                        min_val = np.min(data, axis=0)
                        max_val = np.max(data, axis=0)
                        cpu_normalized = (data - min_val) / (max_val - min_val)
                    else:  # robust
                        median = np.median(data, axis=0)
                        mad = np.median(np.abs(data - median), axis=0)
                        cpu_normalized = (data - median) / mad

                    result.cpu_time = time.time() - start_time
                    result.cpu_memory_used = self.memory_manager.get_memory_usage("cpu")

                    # ì²˜ë¦¬ëŸ‰ ê³„ì‚°
                    if result.gpu_time:
                        result.throughput_gpu = size / result.gpu_time
                    if result.cpu_time:
                        result.throughput_cpu = size / result.cpu_time

                    result.calculate_speedup()

                    self.logger.info(
                        f"ì •ê·œí™” {method} {size}: GPU {result.gpu_time:.3f}s, CPU {result.cpu_time:.3f}s, ì†ë„í–¥ìƒ {result.speedup_ratio:.2f}x"
                    )

                except Exception as e:
                    result.success = False
                    result.error_message = str(e)
                    self.logger.error(f"ì •ê·œí™” ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

                self.results.append(result)

    async def _benchmark_async_io(self):
        """ë¹„ë™ê¸° I/O ë²¤ì¹˜ë§ˆí¬"""
        self.logger.info("ğŸ’½ ë¹„ë™ê¸° I/O ë²¤ì¹˜ë§ˆí¬")

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ í¬ê¸°
        file_sizes = [
            1024 * 1024,
            10 * 1024 * 1024,
            100 * 1024 * 1024,
        ]  # 1MB, 10MB, 100MB
        test_dir = Path("data/benchmark_temp")
        test_dir.mkdir(parents=True, exist_ok=True)

        for size in file_sizes:
            result = BenchmarkResult(f"async_io_{size//1024//1024}MB")

            try:
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
                test_data = np.random.randint(0, 256, size, dtype=np.uint8).tobytes()
                test_file = test_dir / f"test_{size}.bin"

                # GPU ìš°ì„ ìˆœìœ„ I/O
                if self.gpu_available:
                    start_time = time.time()
                    await smart_write_file(test_file, test_data)
                    read_data = await smart_read_file(test_file, load_to_gpu=True)
                    result.gpu_time = time.time() - start_time
                    result.gpu_memory_used = self.memory_manager.get_memory_usage("gpu")

                # ì¼ë°˜ I/O
                start_time = time.time()
                with open(test_file, "wb") as f:
                    f.write(test_data)
                with open(test_file, "rb") as f:
                    cpu_data = f.read()
                result.cpu_time = time.time() - start_time
                result.cpu_memory_used = self.memory_manager.get_memory_usage("cpu")

                # ì²˜ë¦¬ëŸ‰ ê³„ì‚° (MB/s)
                size_mb = size / (1024 * 1024)
                if result.gpu_time:
                    result.throughput_gpu = size_mb / result.gpu_time
                if result.cpu_time:
                    result.throughput_cpu = size_mb / result.cpu_time

                result.calculate_speedup()

                self.logger.info(
                    f"I/O {size_mb:.1f}MB: GPU {result.gpu_time:.3f}s, CPU {result.cpu_time:.3f}s, ì²˜ë¦¬ëŸ‰ GPU {result.throughput_gpu:.1f}MB/s"
                )

                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
                test_file.unlink(missing_ok=True)

            except Exception as e:
                result.success = False
                result.error_message = str(e)
                self.logger.error(f"ë¹„ë™ê¸° I/O ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

            self.results.append(result)

        # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬
        try:
            test_dir.rmdir()
        except:
            pass

    def _benchmark_integrated_performance(self):
        """í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        self.logger.info("ğŸ”„ í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")

        result = BenchmarkResult("integrated_performance")

        try:
            # ë³µí•© ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            data_size = 50000
            data = np.random.randn(data_size, 20).astype(np.float32)

            # GPU í†µí•© ì‘ì—…
            if self.gpu_available:
                start_time = time.time()

                # 1. ë©”ëª¨ë¦¬ í• ë‹¹
                gpu_tensor = self.memory_manager.smart_memory_allocation(
                    (data_size, 20), prefer_gpu=True
                )

                # 2. ë°ì´í„° ì •ê·œí™”
                normalized_data = smart_normalize(data, method="zscore")

                # 3. ì—°ì‚° ì²˜ë¦¬
                def complex_computation(arr):
                    if isinstance(arr, torch.Tensor):
                        return torch.mean(arr**2) + torch.std(arr) * torch.sum(
                            torch.sin(arr)
                        )
                    else:
                        return np.mean(arr**2) + np.std(arr) * np.sum(np.sin(arr))

                gpu_result = smart_compute(complex_computation, normalized_data)

                result.gpu_time = time.time() - start_time
                result.gpu_memory_used = self.memory_manager.get_memory_usage("gpu")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del gpu_tensor
                torch.cuda.empty_cache()

            # CPU í†µí•© ì‘ì—…
            start_time = time.time()

            # 1. ë©”ëª¨ë¦¬ í• ë‹¹
            cpu_array = np.zeros((data_size, 20), dtype=np.float32)

            # 2. ë°ì´í„° ì •ê·œí™”
            normalized_cpu = (data - np.mean(data, axis=0)) / np.std(data, axis=0)

            # 3. ì—°ì‚° ì²˜ë¦¬
            cpu_result = np.mean(normalized_cpu**2) + np.std(normalized_cpu) * np.sum(
                np.sin(normalized_cpu)
            )

            result.cpu_time = time.time() - start_time
            result.cpu_memory_used = self.memory_manager.get_memory_usage("cpu")

            result.calculate_speedup()

            self.logger.info(
                f"í†µí•© ì„±ëŠ¥: GPU {result.gpu_time:.3f}s, CPU {result.cpu_time:.3f}s, ì†ë„í–¥ìƒ {result.speedup_ratio:.2f}x"
            )

        except Exception as e:
            result.success = False
            result.error_message = str(e)
            self.logger.error(f"í†µí•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

        self.results.append(result)

    def _generate_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        self.logger.info("ğŸ“‹ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±")

        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = [r for r in self.results if r.success]

        if not successful_results:
            return {"error": "ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨"}

        # í†µê³„ ê³„ì‚°
        gpu_times = [r.gpu_time for r in successful_results if r.gpu_time is not None]
        cpu_times = [r.cpu_time for r in successful_results if r.cpu_time is not None]
        speedup_ratios = [
            r.speedup_ratio for r in successful_results if r.speedup_ratio is not None
        ]

        report = {
            "summary": {
                "total_tests": len(self.results),
                "successful_tests": len(successful_results),
                "failed_tests": len(self.results) - len(successful_results),
                "gpu_available": self.gpu_available,
            },
            "performance_metrics": {
                "average_gpu_time": np.mean(gpu_times) if gpu_times else None,
                "average_cpu_time": np.mean(cpu_times) if cpu_times else None,
                "average_speedup": np.mean(speedup_ratios) if speedup_ratios else None,
                "max_speedup": np.max(speedup_ratios) if speedup_ratios else None,
                "min_speedup": np.min(speedup_ratios) if speedup_ratios else None,
            },
            "system_info": {
                "gpu_count": torch.cuda.device_count() if self.gpu_available else 0,
                "gpu_name": (
                    torch.cuda.get_device_name(0) if self.gpu_available else None
                ),
                "gpu_memory_total": (
                    torch.cuda.get_device_properties(0).total_memory / (1024**3)
                    if self.gpu_available
                    else None
                ),
                "cpu_count": psutil.cpu_count(),
                "total_memory_gb": psutil.virtual_memory().total / (1024**3),
            },
            "detailed_results": [
                {
                    "test_name": r.test_name,
                    "gpu_time": r.gpu_time,
                    "cpu_time": r.cpu_time,
                    "speedup_ratio": r.speedup_ratio,
                    "throughput_gpu": r.throughput_gpu,
                    "throughput_cpu": r.throughput_cpu,
                    "success": r.success,
                    "error_message": r.error_message,
                }
                for r in self.results
            ],
            "recommendations": self._generate_recommendations(successful_results),
        }

        # ë¦¬í¬íŠ¸ ì €ì¥
        self._save_report(report)

        return report

    def _generate_recommendations(self, results: List[BenchmarkResult]) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ì†ë„ í–¥ìƒ ë¶„ì„
        speedup_ratios = [
            r.speedup_ratio for r in results if r.speedup_ratio is not None
        ]

        if speedup_ratios:
            avg_speedup = np.mean(speedup_ratios)

            if avg_speedup > 3.0:
                recommendations.append(
                    "âœ… GPU ê°€ì†ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”."
                )
            elif avg_speedup > 1.5:
                recommendations.append(
                    "âš¡ GPU ê°€ì†ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤. ë” í° ë°ì´í„°ì…‹ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            elif avg_speedup > 1.0:
                recommendations.append(
                    "ğŸ”§ GPU ê°€ì† íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì„¤ì •ì„ ì¡°ì •í•´ë³´ì„¸ìš”."
                )
            else:
                recommendations.append(
                    "âš ï¸ GPU ì„±ëŠ¥ì´ CPUë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
                )

        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë¶„ì„
        gpu_memory_usage = [
            r.gpu_memory_used for r in results if r.gpu_memory_used is not None
        ]
        if gpu_memory_usage:
            avg_gpu_memory = np.mean(gpu_memory_usage)

            if avg_gpu_memory > 0.9:
                recommendations.append(
                    "ğŸš¨ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ëŠ˜ë¦¬ì„¸ìš”."
                )
            elif avg_gpu_memory > 0.7:
                recommendations.append(
                    "âš¡ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì ë‹¹í•©ë‹ˆë‹¤. ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì˜ ê· í˜•ì´ ì¢‹ìŠµë‹ˆë‹¤."
                )
            else:
                recommendations.append(
                    "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤. ë” í° ë°°ì¹˜ í¬ê¸°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )

        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¶„ì„
        failed_tests = [r for r in self.results if not r.success]
        if failed_tests:
            recommendations.append(
                f"âŒ {len(failed_tests)}ê°œ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ í™•ì¸í•˜ì„¸ìš”."
            )

        return recommendations

    def _save_report(self, report: Dict[str, Any]):
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        try:
            report_dir = Path("data/result/performance_reports")
            report_dir.mkdir(parents=True, exist_ok=True)

            timestamp = time.strftime("%Y%m%d_%H%M%S")
            report_file = report_dir / f"gpu_benchmark_report_{timestamp}.json"

            with open(report_file, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            self.logger.info(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")

        except Exception as e:
            self.logger.error(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def run_gpu_benchmark() -> Dict[str, Any]:
    """GPU ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (í¸ì˜ í•¨ìˆ˜)"""
    benchmark_suite = GPUBenchmarkSuite()
    return benchmark_suite.run_all_benchmarks()


def quick_performance_check() -> Dict[str, Any]:
    """ë¹ ë¥¸ ì„±ëŠ¥ ì²´í¬"""
    logger.info("ğŸ” ë¹ ë¥¸ ì„±ëŠ¥ ì²´í¬ ì‹œì‘")

    try:
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì •ë³´
        system_info = {
            "gpu_available": torch.cuda.is_available(),
            "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "cpu_count": psutil.cpu_count(),
            "total_memory_gb": psutil.virtual_memory().total / (1024**3),
        }

        if system_info["gpu_available"]:
            system_info["gpu_name"] = torch.cuda.get_device_name(0)
            system_info["gpu_memory_gb"] = torch.cuda.get_device_properties(
                0
            ).total_memory / (1024**3)

        # ê°„ë‹¨í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        test_data = np.random.randn(10000, 10).astype(np.float32)

        # GPU í…ŒìŠ¤íŠ¸
        gpu_time = None
        if system_info["gpu_available"]:
            start_time = time.time()
            gpu_result = smart_compute(
                lambda x: (
                    torch.mean(x**2) if isinstance(x, torch.Tensor) else np.mean(x**2)
                ),
                test_data,
            )
            gpu_time = time.time() - start_time

        # CPU í…ŒìŠ¤íŠ¸
        start_time = time.time()
        cpu_result = np.mean(test_data**2)
        cpu_time = time.time() - start_time

        performance_info = {
            "gpu_time": gpu_time,
            "cpu_time": cpu_time,
            "speedup": gpu_time and (cpu_time / gpu_time),
        }

        result = {
            "system_info": system_info,
            "performance_info": performance_info,
            "status": "success",
        }

        logger.info(
            f"ì„±ëŠ¥ ì²´í¬ ì™„ë£Œ: GPU ê°€ì† {performance_info['speedup']:.2f}x"
            if performance_info["speedup"]
            else "ì„±ëŠ¥ ì²´í¬ ì™„ë£Œ (GPU ì—†ìŒ)"
        )

        return result

    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ì²´í¬ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}
