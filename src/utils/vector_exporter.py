#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
íŠ¹ì„± ë²¡í„° ë‚´ë³´ë‚´ê¸° ìœ í‹¸ë¦¬í‹°

ì´ ëª¨ë“ˆì€ íŠ¹ì„± ë²¡í„°ì™€ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ í‘œì¤€í™”ëœ ë°©ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë²¡í„° ë°ì´í„°, íŠ¹ì„± ì´ë¦„, ì¸ë±ìŠ¤ ë§¤í•‘ ë“±ì„ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

ğŸ”§ ì¤‘ë³µ í•¨ìˆ˜ í†µí•©:
- save_feature_names: feature_name_tracker.pyì—ì„œ ì¬ì‚¬ìš©
- save_feature_index_mapping: feature_name_tracker.pyì—ì„œ ì¬ì‚¬ìš©
- load_feature_names: feature_name_tracker.pyì—ì„œ ì¬ì‚¬ìš©
"""

import os
import json
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

from ..utils.unified_logging import get_logger

# ğŸ”§ ì¤‘ë³µëœ ê¸°ëŠ¥ í†µí•© - ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
from .feature_name_tracker import (
    save_feature_names,
    load_feature_names,
    save_feature_index_mapping,
)

logger = get_logger(__name__)

def save_feature_vector_and_metadata(
    vector: np.ndarray,
    feature_names: List[str],
    base_path: str,
    save_index_map: bool = True,
    metadata: Optional[Dict[str, Any]] = None,
) -> bool:
    """
    íŠ¹ì„± ë²¡í„°ì™€ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ í‘œì¤€í™”ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        vector: íŠ¹ì„± ë²¡í„° (2D ë˜ëŠ” 1D ë°°ì—´)
        feature_names: íŠ¹ì„± ì´ë¦„ ëª©ë¡
        base_path: ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì œì™¸)
        save_index_map: ì¸ë±ìŠ¤ ë§¤í•‘ ì €ì¥ ì—¬ë¶€
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ ì‚¬í•­)

    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ë²¡í„° ì°¨ì› í™•ì¸ ë° ìœ íš¨ì„± ê²€ì¦
        if len(vector.shape) == 1:
            if vector.shape[0] != len(feature_names):
                logger.warning(
                    f"ë²¡í„° í¬ê¸°({vector.shape[0]})ì™€ íŠ¹ì„± ì´ë¦„ ìˆ˜({len(feature_names)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )
                return False
        else:
            if vector.shape[1] != len(feature_names):
                logger.warning(
                    f"ë²¡í„° ì—´ ìˆ˜({vector.shape[1]})ì™€ íŠ¹ì„± ì´ë¦„ ìˆ˜({len(feature_names)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )
                return False

        # ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        base_dir = os.path.dirname(base_path)
        if base_dir and not os.path.exists(base_dir):
            os.makedirs(base_dir, exist_ok=True)

        # 1. ë²¡í„° ì €ì¥
        vector_path = f"{base_path}.npy"
        try:
            np.save(vector_path, vector)
            logger.info(f"ë²¡í„° ì €ì¥ ì™„ë£Œ: {vector_path}, í˜•íƒœ: {vector.shape}")
        except Exception as e:
            logger.error(f"ë²¡í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

        # 2. íŠ¹ì„± ì´ë¦„ ì €ì¥ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        names_path = f"{base_path}.names.json"
        try:
            save_feature_names(feature_names, names_path)
        except Exception as e:
            logger.error(f"íŠ¹ì„± ì´ë¦„ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

        # 3. ì¸ë±ìŠ¤ ë§¤í•‘ ì €ì¥ (ì„ íƒ ì‚¬í•­, ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        if save_index_map:
            index_path = f"{base_path}.index.json"
            try:
                save_feature_index_mapping(feature_names, index_path)
            except Exception as e:
                logger.warning(f"ì¸ë±ìŠ¤ ë§¤í•‘ ì €ì¥ì— ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤: {e}")

        # 4. ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì €ì¥ (ì„ íƒ ì‚¬í•­)
        if metadata:
            meta_path = f"{base_path}.meta.json"
            try:
                # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                metadata.update(
                    {
                        "timestamp": datetime.now().isoformat(),
                        "vector_shape": list(vector.shape),
                        "feature_count": len(feature_names),
                    }
                )

                with open(meta_path, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)

                logger.info(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_path}")
            except Exception as e:
                logger.warning(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return True
    except Exception as e:
        logger.error(f"ë²¡í„° ë° ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def save_vector_bundle(
    vector: np.ndarray,
    feature_names: List[str],
    base_path: str,
    metadata: Optional[Dict[str, Any]] = None,
    apply_low_variance_filter: bool = True,
    low_variance_path: str = "data/cache/low_variance_features.json",
) -> bool:
    """
    ë²¡í„° ë²ˆë“¤ ì €ì¥ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)

    Args:
        vector: ì €ì¥í•  ë²¡í„°
        feature_names: íŠ¹ì„± ì´ë¦„ ëª©ë¡
        base_path: ê¸°ë³¸ ì €ì¥ ê²½ë¡œ
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        apply_low_variance_filter: ì €ë¶„ì‚° í•„í„° ì ìš© ì—¬ë¶€
        low_variance_path: ì €ë¶„ì‚° íŠ¹ì„± ì •ë³´ íŒŒì¼ ê²½ë¡œ

    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©í•˜ì—¬ ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        return save_feature_vector_and_metadata(
            vector=vector,
            feature_names=feature_names,
            base_path=base_path,
            save_index_map=True,
            metadata=metadata,
        )
    except Exception as e:
        logger.error(f"ë²¡í„° ë²ˆë“¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_feature_vector(
    base_path: str = "data/cache/feature_vector_full",
    use_filtered: Optional[bool] = None,
    config: Optional[Dict[str, Any]] = None,
) -> Tuple[np.ndarray, List[str]]:
    """
    íŠ¹ì„± ë²¡í„°ì™€ ì´ë¦„ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        base_path: ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì œì™¸)
        use_filtered: í•„í„°ë§ëœ ë²¡í„° ì‚¬ìš© ì—¬ë¶€
        config: ì„¤ì • ê°ì²´

    Returns:
        (ë²¡í„°, íŠ¹ì„± ì´ë¦„ ëª©ë¡) íŠœí”Œ

    Raises:
        FileNotFoundError: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ
        ValueError: ë²¡í„°ì™€ íŠ¹ì„± ì´ë¦„ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œ
    """
    try:
        # íŒŒì¼ ê²½ë¡œ ê²°ì •
        if use_filtered:
            vector_path = f"{base_path}_filtered.npy"
            names_path = f"{base_path}_filtered.names.json"
        else:
            vector_path = f"{base_path}.npy"
            names_path = f"{base_path}.names.json"

        # ë²¡í„° ë¡œë“œ
        if not os.path.exists(vector_path):
            raise FileNotFoundError(f"ë²¡í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vector_path}")

        vector = np.load(vector_path)

        # íŠ¹ì„± ì´ë¦„ ë¡œë“œ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        feature_names = load_feature_names(names_path)

        # ì°¨ì› ì¼ì¹˜ í™•ì¸
        expected_features = (
            vector.shape[1] if len(vector.shape) > 1 else vector.shape[0]
        )
        if expected_features != len(feature_names):
            raise ValueError(
                f"ë²¡í„° íŠ¹ì„± ìˆ˜({expected_features})ì™€ íŠ¹ì„± ì´ë¦„ ìˆ˜({len(feature_names)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )

        logger.info(
            f"íŠ¹ì„± ë²¡í„° ë¡œë“œ ì™„ë£Œ: {vector.shape}, íŠ¹ì„± ìˆ˜: {len(feature_names)}"
        )
        return vector, feature_names

    except Exception as e:
        logger.error(f"íŠ¹ì„± ë²¡í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

def export_vector_with_filtering(
    vector: np.ndarray,
    feature_names: List[str],
    base_path: str,
    low_var_path: Optional[str] = "data/cache/low_variance_features.json",
    save_filtered: bool = True,
) -> bool:
    """
    ì›ë³¸ ë²¡í„°ì™€ ì €ë¶„ì‚° í•„í„°ë§ëœ ë²¡í„°ë¥¼ í•¨ê»˜ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        vector: íŠ¹ì„± ë²¡í„° (2D ë˜ëŠ” 1D ë°°ì—´)
        feature_names: íŠ¹ì„± ì´ë¦„ ëª©ë¡
        base_path: ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì œì™¸)
        low_var_path: ì €ë¶„ì‚° íŠ¹ì„± ì •ë³´ íŒŒì¼ ê²½ë¡œ
        save_filtered: í•„í„°ë§ëœ ë²¡í„° ì €ì¥ ì—¬ë¶€

    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # 1. ì›ë³¸ ë²¡í„° ë° ë©”íƒ€ë°ì´í„° ì €ì¥
        if not save_feature_vector_and_metadata(
            vector=vector,
            feature_names=feature_names,
            base_path=base_path,
            save_index_map=True,
        ):
            return False

        # 2. ì €ë¶„ì‚° í•„í„°ë§ ì ìš© (ì„ íƒ ì‚¬í•­)
        if save_filtered and low_var_path and os.path.exists(low_var_path):
            try:
                # ì €ë¶„ì‚° íŠ¹ì„± ì •ë³´ ë¡œë“œ
                with open(low_var_path, "r", encoding="utf-8") as f:
                    low_var_info = json.load(f)

                removed_feature_names = low_var_info.get("removed_feature_names", [])

                if removed_feature_names:
                    # í•„í„° ë§ˆìŠ¤í¬ ìƒì„±
                    mask = [name not in removed_feature_names for name in feature_names]

                    # í•„í„°ë§ëœ íŠ¹ì„± ì´ë¦„
                    filtered_names = [
                        name for name, keep in zip(feature_names, mask) if keep
                    ]

                    # ë²¡í„° í•„í„°ë§
                    if len(vector.shape) == 1:
                        # 1D ë²¡í„°
                        filtered_vector = vector[mask]
                    else:
                        # 2D ë²¡í„°
                        filtered_vector = vector[:, mask]

                    # í•„í„°ë§ëœ ë²¡í„° ë° ë©”íƒ€ë°ì´í„° ì €ì¥
                    filtered_base_path = f"{base_path}_filtered"

                    metadata = {
                        "original_feature_count": len(feature_names),
                        "filtered_feature_count": len(filtered_names),
                        "removed_feature_count": len(removed_feature_names),
                        "removed_features": removed_feature_names,
                    }

                    save_feature_vector_and_metadata(
                        vector=filtered_vector,
                        feature_names=filtered_names,
                        base_path=filtered_base_path,
                        save_index_map=True,
                        metadata=metadata,
                    )

                    logger.info(
                        f"í•„í„°ë§ëœ ë²¡í„° ì €ì¥ ì™„ë£Œ: {filtered_base_path}.npy "
                        f"(ì›ë³¸: {len(feature_names)}ê°œ â†’ í•„í„°ë§: {len(filtered_names)}ê°œ íŠ¹ì„±)"
                    )
            except Exception as e:
                logger.warning(f"ì €ë¶„ì‚° í•„í„°ë§ ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return True
    except Exception as e:
        logger.error(f"ë²¡í„° ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def export_gnn_state_inputs(
    pair_graph_vector: np.ndarray,
    feature_names: List[str],
    base_path: str = "data/cache/pair_graph_compressed_vector",
) -> bool:
    """
    GNN ì…ë ¥ìš© ê·¸ë˜í”„ ë²¡í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        pair_graph_vector: ìŒ ê·¸ë˜í”„ ë²¡í„°
        feature_names: íŠ¹ì„± ì´ë¦„ ëª©ë¡
        base_path: ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì œì™¸)

    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    return save_feature_vector_and_metadata(
        vector=pair_graph_vector,
        feature_names=feature_names,
        base_path=base_path,
        save_index_map=True,
        metadata={
            "vector_type": "graph_structure",
            "description": "GNN ëª¨ë¸ ë° ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ì…ë ¥ìš© ê·¸ë˜í”„ êµ¬ì¡° ë²¡í„°",
        },
    )
