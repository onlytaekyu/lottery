"""CUDA ë©”ëª¨ë¦¬ ê´€ë¦¬ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ CUDA ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë©”ëª¨ë¦¬ ì‚¬ìš© íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ê¸°ëŠ¥ë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
"""

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, TypeVar, Generic
from threading import Lock, Thread
from queue import Empty
from concurrent.futures import ThreadPoolExecutor
import time
import gc
import torch
from pathlib import Path
import threading
import queue
from collections import OrderedDict
import psutil
import platform
import traceback
from contextlib import contextmanager
import os
import random

# ìƒëŒ€ê²½ë¡œ ì„í¬íŠ¸ë¡œ ë³€ê²½
from .unified_logging import get_logger

logger = get_logger(__name__)


# CUDA ì„¤ì • í”Œë«í¼ë³„ ìµœì í™”
def get_cuda_alloc_config():
    """í”Œë«í¼ì— ë”°ë¥¸ CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ì„¤ì • ë°˜í™˜"""
    if platform.system() == "Windows":
        return "max_split_size_mb:512"
    else:
        return "expandable_segments:True,max_split_size_mb:512"


# CUDA ì„¤ì • ì ìš© (ì¤‘ë³µ ë°©ì§€)
if torch.cuda.is_available() and "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
    cuda_config = get_cuda_alloc_config()
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = cuda_config
    logger.info(f"CUDA ë©”ëª¨ë¦¬ ì„¤ì •: {cuda_config}")
elif torch.cuda.is_available():
    logger.debug(
        f"CUDA ë©”ëª¨ë¦¬ ì„¤ì • ì´ë¯¸ ì ìš©ë¨: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF', 'N/A')}"
    )

T = TypeVar("T")


@dataclass
class ThreadLocalConfig:
    """ìŠ¤ë ˆë“œ ë¡œì»¬ ì„¤ì • í´ë˜ìŠ¤"""

    max_size: int = 1000
    max_memory: int = 1 << 30  # 1GB
    ttl: float = 3600.0  # 1ì‹œê°„
    cleanup_interval: float = 300.0  # 5ë¶„
    stats: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ThreadLocalCacheEntry(Generic[T]):
    """ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ í•­ëª© í´ë˜ìŠ¤"""

    value: T
    size: int
    access_count: int = 0
    last_access: float = 0.0
    ttl: float = 0.0


class ThreadLocalCache(Generic[T]):
    """ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ í´ë˜ìŠ¤"""

    def __init__(self, config: Optional[ThreadLocalConfig] = None):
        """
        ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ ì´ˆê¸°í™”

        Args:
            config: ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ ì„¤ì •
        """
        self.config = config or ThreadLocalConfig()
        self._lock = threading.RLock()
        self._hit_count = 0
        self._miss_count = 0
        self._eviction_count = 0
        self._stats = {
            "hit_count": 0,
            "miss_count": 0,
            "eviction_count": 0,
            "memory_usage": 0,
        }
        self._local = threading.local()
        self._last_cleanup = time.time()

    def _get_cache(self) -> OrderedDict[str, ThreadLocalCacheEntry[T]]:
        """ìŠ¤ë ˆë“œë³„ ìºì‹œ ê°€ì ¸ì˜¤ê¸°"""
        if not hasattr(self._local, "cache"):
            self._local.cache = OrderedDict()
        return self._local.cache

    def _cleanup(self):
        """ë§Œë£Œëœ ìºì‹œ í•­ëª© ì •ë¦¬"""
        try:
            current_time = time.time()
            if current_time - self._last_cleanup < self.config.cleanup_interval:
                return

            with self._lock:
                cache = self._get_cache()
                expired_keys = []
                for key, entry in cache.items():
                    if entry.ttl > 0 and current_time - entry.last_access > entry.ttl:
                        expired_keys.append(key)
                        self._stats["eviction_count"] += 1
                        self._stats["memory_usage"] -= entry.size

                for key in expired_keys:
                    del cache[key]

                self._last_cleanup = current_time
                logger.info(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {len(expired_keys)}ê°œ í•­ëª© ì œê±°")

        except Exception as e:
            logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

    def get(self, key: str) -> Optional[T]:
        """
        ìºì‹œì—ì„œ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            key: ìºì‹œ í‚¤

        Returns:
            ìºì‹œëœ ê°’ ë˜ëŠ” None
        """
        with self._lock:
            cache = self._get_cache()
            if key in cache:
                entry = cache[key]
                entry.access_count += 1
                entry.last_access = time.time()
                self._stats["hit_count"] += 1
                self._hit_count += 1
                return entry.value
            self._stats["miss_count"] += 1
            self._miss_count += 1
            return None

    def put(self, key: str, value: T, size: Optional[int] = None) -> bool:
        """ê°’ ìºì‹±"""
        try:
            self._cleanup()
            cache = self._get_cache()

            # í¬ê¸° ê³„ì‚°
            if size is None:
                size = self._estimate_size(value)

            # ë©”ëª¨ë¦¬ ì œí•œ í™•ì¸
            while (
                len(cache) >= self.config.max_size
                or self._stats["memory_usage"] + size > self.config.max_memory  # type: ignore
            ):
                if not cache:
                    return False

                # LRU í•­ëª© ì œê±°
                _, entry = cache.popitem(last=False)
                self._stats["eviction_count"] += 1
                self._stats["memory_usage"] -= entry.size  # type: ignore

            # ìƒˆ í•­ëª© ì¶”ê°€
            cache[key] = ThreadLocalCacheEntry(
                value=value,
                size=size,
                last_access=time.time(),
                ttl=self.config.ttl,
            )
            self._stats["memory_usage"] += size  # type: ignore
            return True

        except Exception as e:
            logger.error(f"ìºì‹œ ê°’ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False

    def _estimate_size(self, value: T) -> int:
        """ê°’ì˜ ëŒ€ëµì ì¸ í¬ê¸° ì¶”ì •"""
        try:
            if isinstance(value, (str, bytes)):
                return len(value)
            elif isinstance(value, (list, tuple)):
                return sum(self._estimate_size(item) for item in value)
            elif isinstance(value, dict):
                return sum(
                    self._estimate_size(k) + self._estimate_size(v)
                    for k, v in value.items()
                )
            else:
                return 1 << 10  # ê¸°ë³¸ í¬ê¸° 1KB
        except Exception:
            return 1 << 10  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í¬ê¸°

    def clear(self):
        """ìºì‹œ ë¹„ìš°ê¸°"""
        try:
            with self._lock:
                cache = self._get_cache()
                self._stats["memory_usage"] = 0
                cache.clear()
                logger.info("ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        stats = {}
        with self._lock:
            stats["hit_count"] = self._hit_count
            stats["miss_count"] = self._miss_count
            stats["eviction_count"] = self._eviction_count
            stats["access_count"] = self._hit_count + self._miss_count
            stats["hit_rate"] = (
                (self._hit_count / (self._hit_count + self._miss_count)) * 100
                if (self._hit_count + self._miss_count) > 0
                else 0
            )
            stats["entry_count"] = len(self._get_cache())
            stats["memory_usage"] = self._stats["memory_usage"]
            stats["memory_limit"] = self.config.max_memory
            stats["usage_percent"] = (  # type: ignore
                100 * self._stats["memory_usage"] / self.config.max_memory
                if self.config.max_memory > 0
                else 0
            )
            stats["items_count"] = len(self._get_cache())
            stats["device"] = "cpu"  # type: ignore
            return stats

    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        with self._lock:
            for key in self._stats:
                self._stats[key] = 0


# ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì • í´ë˜ìŠ¤
@dataclass
class MemoryConfig:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì • í´ë˜ìŠ¤"""

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ë ¨ ì„¤ì •
    max_memory_usage: float = 0.85  # ì•ˆì „ì„ ìœ„í•´ 85%ë¡œ ì œí•œ
    cache_size: int = 256 * 1024 * 1024  # ìºì‹œ í¬ê¸° (256MB)
    min_batch_size: int = 1
    max_batch_size: int = 128  # ìµœëŒ€ ë°°ì¹˜ í¬ê¸° ì œí•œ
    optimal_batch_size: int = 16  # ìµœì  ë°°ì¹˜ í¬ê¸°
    memory_track_interval: int = 5  # ë©”ëª¨ë¦¬ ì¶”ì  ê°„ê²©
    memory_frags_threshold: float = 0.3
    memory_usage_warning: float = 0.95  # ê²½ê³  ì„ê³„ê°’

    # ì›Œì»¤ ê´€ë ¨ ì„¤ì •
    num_workers: int = 2  # ì›Œì»¤ ìˆ˜ ì¤„ì„ (ë©”ëª¨ë¦¬ ë¶€ë‹´ ê°ì†Œ)
    prefetch_factor: int = 2

    # ë©”ëª¨ë¦¬ í’€ ê´€ë ¨ ì„¤ì •
    pool_size: int = 32
    compression_threshold: int = 16 << 20  # 16MB
    alignment_size: int = 256

    # ìµœì í™” ê´€ë ¨ ì„¤ì •
    use_memory_pooling: bool = True
    use_memory_alignment: bool = True
    use_memory_compression: bool = True
    use_memory_prefetching: bool = False
    use_memory_reuse: bool = True
    use_memory_tracking: bool = True
    use_memory_optimization: bool = True
    use_memory_compaction: bool = True
    use_memory_pinning: bool = False
    use_memory_streaming: bool = False
    use_memory_events: bool = False
    use_memory_graphs: bool = False
    use_memory_peer_access: bool = False
    use_memory_unified: bool = False
    use_memory_multi_gpu: bool = False
    gpu_ids: List[int] = field(default_factory=lambda: [0])

    # ë©”ëª¨ë¦¬ í’€ í†µê³„
    memory_pool_sizes: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_usage: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_hits: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_misses: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_evictions: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_compressions: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_decompressions: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_prefetches: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_reuses: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_alignments: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_errors: Dict[Tuple[torch.Size, torch.dtype], int] = field(
        default_factory=dict
    )
    memory_pool_stats: Dict[str, Any] = field(default_factory=dict)
    auto_cleanup_interval: float = 120.0  # ìë™ ì •ë¦¬ ê°„ê²© (2ë¶„ìœ¼ë¡œ ì¦ê°€)

    # í”Œë«í¼ë³„ ë©”ëª¨ë¦¬ ì„¤ì •
    platform: str = platform.system()

    # í”Œë«í¼ë³„ ìµœì í™” ì„¤ì •
    use_pinned_memory: bool = field(init=False)
    use_shared_memory: bool = field(init=False)
    cuda_memory_config: str = field(init=False)

    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        # í”Œë«í¼ë³„ ìµœì í™” ì„¤ì • ì´ˆê¸°í™”
        if self.platform == "Windows":
            # WindowsëŠ” ì¼ë¶€ CUDA ê¸°ëŠ¥ ì œí•œ
            self.use_pinned_memory = False
            self.use_shared_memory = False
            self.cuda_memory_config = "max_split_size_mb:512"
        else:
            # Linux/MacOS
            self.use_pinned_memory = True
            self.use_shared_memory = True
            self.cuda_memory_config = "expandable_segments:True,max_split_size_mb:512"

        # ë©”ëª¨ë¦¬ ì„¤ì • ê²€ì¦
        self.max_memory_usage = max(0.1, min(self.max_memory_usage, 0.95))
        self.cache_size = max(1 << 20, min(self.cache_size, 1 << 30))  # 1MB ~ 1GB
        self.min_batch_size = max(1, min(self.min_batch_size, self.max_batch_size))
        self.max_batch_size = max(self.min_batch_size, min(self.max_batch_size, 256))
        self.optimal_batch_size = max(
            self.min_batch_size, min(self.optimal_batch_size, self.max_batch_size)
        )
        self.memory_track_interval = max(1, min(self.memory_track_interval, 60))
        self.memory_frags_threshold = max(0.1, min(self.memory_frags_threshold, 0.5))
        self.memory_usage_warning = max(0.5, min(self.memory_usage_warning, 0.98))

        # ì›Œì»¤ ì„¤ì • ê²€ì¦
        self.num_workers = max(1, min(self.num_workers, os.cpu_count() or 4))
        self.prefetch_factor = max(1, min(self.prefetch_factor, 4))

        # í’€ ì„¤ì • ê²€ì¦
        self.pool_size = max(10, min(self.pool_size, 128))
        self.compression_threshold = max(
            1 << 10, min(self.compression_threshold, 1 << 28)
        )
        self.alignment_size = max(32, min(self.alignment_size, 512))

        # GPU ID ê²€ì¦
        if torch.cuda.is_available():
            self.gpu_ids = [
                gpu_id
                for gpu_id in self.gpu_ids
                if 0 <= gpu_id < torch.cuda.device_count()
            ]
            if not self.gpu_ids:
                self.gpu_ids = [0]
        else:
            self.gpu_ids = []

    def update(self, new_config: Dict[str, Any]):
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        for key, value in new_config.items():
            if hasattr(self, key):
                setattr(self, key, value)
        self.__post_init__()  # ì—…ë°ì´íŠ¸ëœ ê°’ ê²€ì¦


@dataclass
class CacheEntry:
    """ìºì‹œ í•­ëª© í´ë˜ìŠ¤"""

    tensor: torch.Tensor
    size: int
    access_count: int = 0
    last_access: float = 0.0
    compressed: bool = False
    compressed_data: Optional[bytes] = None
    creation_time: float = field(default_factory=time.time)
    last_modified: float = field(default_factory=time.time)

    def update_access(self):
        """ì ‘ê·¼ ì •ë³´ ì—…ë°ì´íŠ¸"""
        self.access_count += 1
        self.last_access = time.time()


class MemoryPool:
    """ë©”ëª¨ë¦¬ í’€"""

    def __init__(self, config: MemoryConfig):
        self.config = config
        self.pools: Dict[Tuple[torch.Size, torch.dtype], List[torch.Tensor]] = {}
        self.allocated_tensors: Dict[int, Tuple[torch.Size, torch.dtype]] = {}
        self.lock = Lock()
        self._initialize()

    def _initialize(self):
        """ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ í…ì„œ íƒ€ì…ì— ëŒ€í•œ í’€ ìƒì„±
            if torch.cuda.is_available() and self.config.use_memory_pooling:
                # GPU í’€ ì„¤ì •
                torch.backends.cudnn.benchmark = True
                for device_id in self.config.gpu_ids:
                    with torch.cuda.device(device_id):
                        if hasattr(torch.cuda, "empty_cache"):
                            torch.cuda.empty_cache()
                logger.info(f"CUDA ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì™„ë£Œ: {self.config.gpu_ids}")
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    def _create_pool(self, shape: Tuple[int, ...], dtype: torch.dtype):
        """íŠ¹ì • í¬ê¸°ì™€ íƒ€ì…ì˜ í’€ ìƒì„±"""
        try:
            if (torch.Size(shape), dtype) not in self.pools:
                self.pools[(torch.Size(shape), dtype)] = []
                logger.debug(f"ìƒˆ ë©”ëª¨ë¦¬ í’€ ìƒì„±: í˜•íƒœ={shape}, íƒ€ì…={dtype}")
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í’€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    def _align_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """í…ì„œ ì •ë ¬"""
        if not self.config.use_memory_alignment:
            return tensor

        try:
            shape = tensor.shape
            dtype = tensor.dtype
            size = tensor.numel() * tensor.element_size()

            # ì •ë ¬ í¬ê¸° ê³„ì‚°
            if size < self.config.alignment_size:
                return tensor

            # ì •ë ¬ í•„ìš” ì—†ëŠ” ê²½ìš°
            if size % self.config.alignment_size == 0:
                return tensor

            # ì •ë ¬ í¬ê¸° ê³„ì‚°
            aligned_size = (
                (size + self.config.alignment_size - 1)
                // self.config.alignment_size
                * self.config.alignment_size
            )

            # í•„ìš”í•œ ê²½ìš°ì—ë§Œ ìƒˆ í…ì„œ ìƒì„±
            if aligned_size != size:
                # ê³„ì • í¬ê¸° ê¸°ë¡
                self.config.memory_pool_alignments[(torch.Size(shape), dtype)] = (
                    self.config.memory_pool_alignments.get(
                        (torch.Size(shape), dtype), 0
                    )
                    + 1
                )
                # ì •ë ¬ëœ í¬ê¸°ë¡œ ìƒˆ í…ì„œ ìƒì„±
                new_shape = (aligned_size // tensor.element_size(),)
                aligned_tensor = torch.empty(
                    new_shape, dtype=dtype, device=tensor.device
                )
                return aligned_tensor.view(shape)
            return tensor
        except Exception as e:
            logger.error(f"í…ì„œ ì •ë ¬ ì‹¤íŒ¨: {str(e)}")
            return tensor

    def get_tensor(
        self, shape: Tuple[int, ...], dtype: torch.dtype
    ) -> Optional[torch.Tensor]:
        """í’€ì—ì„œ í…ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            with self.lock:
                key = (torch.Size(shape), dtype)
                if key not in self.pools:
                    self._create_pool(shape, dtype)
                    self.config.memory_pool_misses[key] = (
                        self.config.memory_pool_misses.get(key, 0) + 1
                    )
                    return None

                if not self.pools[key]:
                    self.config.memory_pool_misses[key] = (
                        self.config.memory_pool_misses.get(key, 0) + 1
                    )
                    return None

                tensor = self.pools[key].pop()
                self.allocated_tensors[id(tensor)] = key
                self.config.memory_pool_hits[key] = (
                    self.config.memory_pool_hits.get(key, 0) + 1
                )
                return tensor
        except Exception as e:
            logger.error(f"í’€ì—ì„œ í…ì„œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return None

    def return_tensor(self, tensor: torch.Tensor):
        """í…ì„œë¥¼ í’€ë¡œ ë°˜í™˜"""
        try:
            tensor_id = id(tensor)
            with self.lock:
                if tensor_id not in self.allocated_tensors:
                    return

                key = self.allocated_tensors[tensor_id]
                # í’€ í¬ê¸° ì œí•œ
                if len(self.pools[key]) >= self.config.pool_size:
                    # í’€ì´ ê½‰ ì°¬ ê²½ìš°, ê°€ì¥ ì˜¤ë˜ëœ í…ì„œ ì œê±°
                    self.pools[key].pop(0)
                    self.config.memory_pool_evictions[key] = (
                        self.config.memory_pool_evictions.get(key, 0) + 1
                    )

                self.pools[key].append(tensor)
                del self.allocated_tensors[tensor_id]
                self.config.memory_pool_reuses[key] = (
                    self.config.memory_pool_reuses.get(key, 0) + 1
                )
        except Exception as e:
            logger.error(f"í…ì„œ í’€ ë°˜í™˜ ì‹¤íŒ¨: {str(e)}")

    def cleanup(self):
        """ëª¨ë“  í’€ ì •ë¦¬"""
        try:
            with self.lock:
                self.pools.clear()
                self.allocated_tensors.clear()
                logger.info("ë©”ëª¨ë¦¬ í’€ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í’€ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")


class TensorCache:
    """í…ì„œ ìºì‹œ"""

    def __init__(
        self,
        max_memory_size: int = 1 * 1024 * 1024 * 1024,  # 1GBë¡œ ê¸°ë³¸ í¬ê¸° ì¤„ì„
        device: str = "cuda" if torch.cuda.is_available() else "cpu",
    ):
        self.max_memory_size = max_memory_size
        self.device = device
        self.cache: Dict[str, CacheEntry] = {}
        self.lock = Lock()
        self.current_memory_usage = 0
        self.hit_count = 0
        self.miss_count = 0
        self.stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0,
            "insertions": 0,
        }

    def put(self, key: str, tensor: torch.Tensor) -> bool:
        """í…ì„œ ìºì‹±"""
        try:
            tensor_size = tensor.numel() * tensor.element_size()

            with self.lock:
                # ì´ë¯¸ ìˆëŠ” í‚¤ì¸ ê²½ìš° ì—…ë°ì´íŠ¸
                if key in self.cache:
                    old_entry = self.cache[key]
                    self.current_memory_usage -= old_entry.size

                # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ê³µê°„ í™•ë³´
                while (
                    self.current_memory_usage + tensor_size > self.max_memory_size
                    and self.cache
                ):
                    self._evict()

                # ì—¬ì „íˆ ê³µê°„ì´ ë¶€ì¡±í•˜ë©´ ì‹¤íŒ¨
                if self.current_memory_usage + tensor_size > self.max_memory_size:
                    return False

                # í…ì„œ ë³µì‚¬ (ë¶„ë¦¬)
                cached_tensor = tensor.clone().detach()
                entry = CacheEntry(
                    tensor=cached_tensor,
                    size=tensor_size,
                )
                self.cache[key] = entry
                self.current_memory_usage += tensor_size
                self.stats["insertions"] += 1
                return True
        except Exception as e:
            logger.error(f"í…ì„œ ìºì‹± ì‹¤íŒ¨: {str(e)}")
            return False

    def get(self, key: str) -> Optional[torch.Tensor]:
        """ìºì‹œëœ í…ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            with self.lock:
                if key in self.cache:
                    entry = self.cache[key]
                    entry.update_access()
                    self.hit_count += 1
                    return entry.tensor
                self.miss_count += 1
                return None
        except Exception as e:
            logger.error(f"ìºì‹œëœ í…ì„œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return None

    def _evict(self) -> bool:
        """LRU í•­ëª© ì œê±°"""
        try:
            if not self.cache:
                return False

            # ê°€ì¥ ì˜¤ë˜ì „ì— ì ‘ê·¼í•œ í•­ëª© ì°¾ê¸°
            lru_key = min(self.cache.keys(), key=lambda k: self.cache[k].last_access)
            entry = self.cache.pop(lru_key)
            self.current_memory_usage -= entry.size
            self.stats["evictions"] += 1
            return True
        except Exception as e:
            logger.error(f"ìºì‹œ í•­ëª© ì œê±° ì‹¤íŒ¨: {str(e)}")
            return False

    def clear(self):
        """ìºì‹œ ë¹„ìš°ê¸°"""
        try:
            with self.lock:
                self.cache.clear()
                self.current_memory_usage = 0
                logger.info("í…ì„œ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í…ì„œ ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        with self.lock:
            stats = {}
            stats["hit_count"] = self.hit_count
            stats["miss_count"] = self.miss_count
            stats["access_count"] = self.hit_count + self.miss_count
            stats["hit_rate"] = (
                (self.hit_count / (self.hit_count + self.miss_count)) * 100
                if (self.hit_count + self.miss_count) > 0
                else 0
            )
            stats["cache_size"] = self.current_memory_usage
            stats["memory_usage"] = self.current_memory_usage
            stats["memory_limit"] = self.max_memory_size
            stats["usage_percent"] = (  # type: ignore
                100 * self.current_memory_usage / self.max_memory_size
                if self.max_memory_size > 0
                else 0
            )
            stats["items_count"] = len(self.cache)
            stats["device"] = self.device  # type: ignore
            return stats


class MemoryManager:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""

    _instance = None

    def __init__(self, config: Optional[MemoryConfig] = None):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.config = config or MemoryConfig()
        self._last_cleanup_time = time.time()
        self._cleanup_count = 0
        self._memory_history = []

        # ìµœì í™”ëœ ì •ë¦¬ ì„¤ì •
        self.cleanup_interval = 30.0  # 2ì´ˆ â†’ 30ì´ˆë¡œ ì¦ê°€
        self.cleanup_threshold = 0.8  # 80% ì‚¬ìš©ì‹œì—ë§Œ ì •ë¦¬
        self.max_memory_usage_mb = 1024  # 1GB ì œí•œ

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_monitoring = True

        logger.info(
            f"ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” - ì •ë¦¬ ê°„ê²©: {self.cleanup_interval}ì´ˆ, ì„ê³„ê°’: {self.cleanup_threshold*100}%"
        )

        self.lock = threading.RLock()
        self.memory_pool = MemoryPool(self.config)

        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.log_dir = Path(__file__).parent.parent.parent / "logs"
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼
        self.memory_log_file = self.log_dir / "memory_usage.csv"

        # ì›Œì»¤ ìŠ¤ë ˆë“œ
        self.worker_threads = []
        self.allocation_queue = queue.Queue()
        self.deallocation_queue = queue.Queue()
        self.stop_event = threading.Event()
        self.cleanup_thread = None
        self.cache_manager_thread = None
        self.auto_cleanup_thread = None
        self.memory_monitor_thread = None

        # ìŠ¤ë ˆë“œ í’€ ì´ˆê¸°í™”
        self.executor = ThreadPoolExecutor(max_workers=2)

        # í…ì„œ ìºì‹œ
        self.tensor_cache = TensorCache(
            max_memory_size=self.config.cache_size,
            device="cuda" if torch.cuda.is_available() else "cpu",
        )

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        self.memory_usage = {
            "gpu": 0.0,
            "ram": 0.0,
            "gpu_allocated": 0,
            "gpu_reserved": 0,
            "gpu_max_allocated": 0,
            "gpu_max_reserved": 0,
        }

        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.gpu_memory_allocated = []
        self.gpu_memory_reserved = []
        self.timestamps = []

        # ë©”ëª¨ë¦¬ ë¦­ ê°ì§€
        self.allocations = {}
        self.allocation_counts = {}
        self.deallocations = {}
        self.deallocation_counts = {}

        # ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì • ê´€ë ¨
        self.optimal_batch_size = self.config.optimal_batch_size
        self.current_batch_size = self.optimal_batch_size

        # ìŠ¤ì¼€ì¼ë§ ì„¤ì •
        self.scaling_factors = {
            "memory_low": 1.2,  # ë©”ëª¨ë¦¬ ì—¬ìœ  ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€ ë¹„ìœ¨
            "memory_high": 0.8,  # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ í¬ê¸° ê°ì†Œ ë¹„ìœ¨
        }

        # ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ
        self.thread_local_cache = ThreadLocalCache(ThreadLocalConfig())

        # ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        self.memory_event_listeners = []

        # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ í™œì„±í™” (CUDAë§Œ í•´ë‹¹)
        self.memory_graphs_enabled = (
            torch.cuda.is_available() and self.config.use_memory_graphs
        )
        self.current_stream = None
        self.current_graph = None

        # ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ì¹´ìš´í„°
        self._cache_hits = 0
        self._cache_misses = 0

        # ë§ˆì§€ë§‰ ë©”ëª¨ë¦¬ í™•ì¸ ì‹œê°„ ë° ê²½ê³  ìƒíƒœ ì¶”ì 
        self._last_cleanup_time = time.time()
        self._memory_warning_issued = False
        self._memory_warning_count = 0
        self._last_warning_time = time.time()

        # CUDA ì„¤ì • ì´ˆê¸°í™”
        self._initial_cuda_setup()

        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        self._start_worker_threads()
        self._start_cleanup_thread()

    def _initial_cuda_setup(self):
        """ì´ˆê¸° CUDA ì„¤ì •"""
        if not torch.cuda.is_available():
            logger.info("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        # CUDA í• ë‹¹ ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
        if "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
            os.environ["PYTORCH_CUDA_ALLOC_CONF"] = self.config.cuda_memory_config
            logger.debug(f"CUDA ë©”ëª¨ë¦¬ ì„¤ì •: {self.config.cuda_memory_config}")
        else:
            logger.debug("CUDA ë©”ëª¨ë¦¬ ì„¤ì • ì´ë¯¸ ì ìš©ë¨")

    def _start_worker_threads(self):
        """ì‘ì—…ì ìŠ¤ë ˆë“œ ì‹œì‘"""
        try:
            if self.worker_threads:
                logger.debug("ì‘ì—…ì ìŠ¤ë ˆë“œê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
                return

            # ìŠ¤ë ˆë“œ ì¤‘ì§€ í”Œë˜ê·¸ ì´ˆê¸°í™”
            self.stop_event.clear()

            # ë©”ëª¨ë¦¬ ì •ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
            self.cleanup_thread = Thread(
                target=self._cleanup_loop, daemon=True, name="MemoryCleanupThread"
            )
            self.cleanup_thread.start()

            # ì‘ì—…ì ìŠ¤ë ˆë“œ ì‹œì‘
            for i in range(self.config.num_workers):
                thread = Thread(
                    target=self._worker_loop,
                    daemon=True,
                    name=f"MemoryWorkerThread-{i}",
                )
                thread.start()
                self.worker_threads.append(thread)

            logger.debug(
                f"ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì‘ì—…ì ìŠ¤ë ˆë“œ {len(self.worker_threads)}ê°œ ì‹œì‘ë¨"
            )
        except Exception as e:
            logger.error(f"ì‘ì—…ì ìŠ¤ë ˆë“œ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _cleanup_loop(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ ë£¨í”„"""
        try:
            while not self.stop_event.is_set():
                try:
                    # ì¼ì • ì‹œê°„ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ë° ìºì‹œ ì •ë¦¬
                    self._cleanup_memory()
                    time.sleep(self.config.memory_track_interval)
                except Exception as e:
                    logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ë£¨í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    time.sleep(
                        self.config.memory_track_interval * 2
                    )  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ë£¨í”„ ì¢…ë£Œ: {str(e)}")

    def _worker_loop(self):
        """ì‘ì—…ì ìŠ¤ë ˆë“œ ë£¨í”„"""
        try:
            while not self.stop_event.is_set():
                try:
                    # í• ë‹¹ íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                    try:
                        task = self.allocation_queue.get(timeout=1.0)
                        self._process_allocation_task(task)
                        self.allocation_queue.task_done()
                    except Empty:
                        pass

                    # í•´ì œ íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì—†ìŒ)
                    try:
                        task = self.deallocation_queue.get_nowait()
                        self._process_deallocation_task(task)
                        self.deallocation_queue.task_done()
                    except Empty:
                        pass

                except Exception as e:
                    logger.error(f"ì‘ì—…ì ë£¨í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

                # ì ì‹œ ëŒ€ê¸°
                time.sleep(0.01)
        except Exception as e:
            logger.error(f"ì‘ì—…ì ë£¨í”„ ì¢…ë£Œ: {str(e)}")

    def _start_cleanup_thread(self):
        """ìë™ ì •ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘"""
        try:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ìŠ¤ë ˆë“œê°€ ìˆìœ¼ë©´ ì¤‘ì§€
            if hasattr(self, "cleanup_thread") and self.cleanup_thread is not None:
                self.stop_event.set()
                if self.cleanup_thread.is_alive():
                    self.cleanup_thread.join(timeout=1.0)

            # ì •ì§€ ì´ë²¤íŠ¸ ì´ˆê¸°í™”
            self.stop_event = threading.Event()

            # ìë™ ì •ë¦¬ ìŠ¤ë ˆë“œ ìƒì„± ë° ì‹œì‘
            self.cleanup_thread = threading.Thread(
                target=self._auto_cleanup_task, daemon=True, name="MemoryAutoCleanup"
            )
            self.cleanup_thread.start()
            logger.debug("ìë™ ì •ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
        except Exception as e:
            logger.error(f"ìë™ ì •ë¦¬ ìŠ¤ë ˆë“œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            self.cleanup_thread = None

    def _memory_monitor_task(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‘ì—… (ì›Œì»¤ ìŠ¤ë ˆë“œ)"""
        try:
            while not self.stop_event.is_set():
                try:
                    # ë©”ëª¨ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸
                    self._update_gpu_memory_stats()

                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
                    if torch.cuda.is_available():
                        logger.debug(
                            f"GPU ë©”ëª¨ë¦¬: í• ë‹¹={torch.cuda.memory_allocated() / (1024**2):.1f}MB, "
                            f"ì˜ˆì•½={torch.cuda.memory_reserved() / (1024**2):.1f}MB"
                        )

                    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                    ram_usage = psutil.virtual_memory().percent
                    logger.debug(f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {ram_usage:.1f}%")

                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ê²½ìš° ì •ë¦¬ ìš”ì²­
                    if ram_usage > 90 or (
                        torch.cuda.is_available()
                        and torch.cuda.memory_allocated()
                        / torch.cuda.get_device_properties(0).total_memory
                        > 0.9
                    ):
                        logger.warning("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ì •ë¦¬ ìš”ì²­...")
                        self._cleanup_internal()

                    # ì¼ì • ì‹œê°„ ëŒ€ê¸°
                    time.sleep(self.config.memory_track_interval)
                except Exception as e:
                    logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    time.sleep(10)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹¤íŒ¨: {str(e)}")

    def _cache_manager_task(self):
        """ìºì‹œ ê´€ë¦¬ ì‘ì—… (ì›Œì»¤ ìŠ¤ë ˆë“œ)"""
        try:
            # ì²˜ìŒì— ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ë‹¤ë¥¸ ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ë„ë¡ í•¨
            time.sleep(5)

            while not self.stop_event.is_set():
                try:
                    # ìºì‹œ í•­ëª© ì •ë¦¬ (30ë¶„ ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì€ í•­ëª©)
                    with self.lock:
                        now = time.time()
                        expired_keys = []

                        # ì˜¤ë˜ëœ í•­ëª© ì‹ë³„
                        for key, entry in self.allocations.items():
                            if now - entry.last_access > 1800:  # 30ë¶„
                                expired_keys.append(key)

                        # ë§Œë£Œëœ í•­ëª© ì œê±°
                        for key in expired_keys:
                            del self.allocations[key]

                        if expired_keys:
                            logger.info(
                                f"{len(expired_keys)}ê°œì˜ ë§Œë£Œëœ ìºì‹œ í•­ëª© ì œê±°ë¨"
                            )

                    # ì¼ì • ì‹œê°„ ëŒ€ê¸°
                    time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ê²€ì‚¬
                except Exception as e:
                    logger.error(f"ìºì‹œ ê´€ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    time.sleep(60)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
        except Exception as e:
            logger.error(f"ìºì‹œ ê´€ë¦¬ íƒœìŠ¤í¬ ì‹¤íŒ¨: {str(e)}")

    def _auto_cleanup_task(self):
        """ìë™ ì •ë¦¬ ì‘ì—… (ì›Œì»¤ ìŠ¤ë ˆë“œ)"""
        try:
            # ì²˜ìŒì— ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ë‹¤ë¥¸ ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ë„ë¡ í•¨
            time.sleep(10)

            while not self.stop_event.is_set():
                try:
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ë° ì •ë¦¬
                    if self.should_cleanup():
                        logger.info("ìë™ ì •ë¦¬ ì‹œì‘...")
                        self._cleanup_internal()
                        logger.info("ìë™ ì •ë¦¬ ì™„ë£Œ")

                    # ì¼ì • ì‹œê°„ ëŒ€ê¸°
                    time.sleep(self.config.auto_cleanup_interval)
                except Exception as e:
                    logger.error(f"ìë™ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    time.sleep(60)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
        except Exception as e:
            logger.error(f"ìë™ ì •ë¦¬ íƒœìŠ¤í¬ ì‹¤íŒ¨: {str(e)}")

    @contextmanager
    def allocation_scope(self):
        """
        ë©”ëª¨ë¦¬ í• ë‹¹ ìŠ¤ì½”í”„ (ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €)

        ì´ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ìƒì„±ëœ í…ì„œëŠ” ì¶”ì ë˜ì–´ ê´€ë¦¬ë©ë‹ˆë‹¤.
        """
        try:
            # ì§„ì… ì‹œ ë©”ëª¨ë¦¬ ìƒíƒœ ê¸°ë¡
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                before_allocated = torch.cuda.memory_allocated()
                before_reserved = torch.cuda.memory_reserved()

            # ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ ì½”ë“œ ì‹¤í–‰
            yield

        finally:
            # ì¢…ë£Œ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬ ê³ ë ¤
            if torch.cuda.is_available():
                torch.cuda.synchronize()
                after_allocated = torch.cuda.memory_allocated()
                after_reserved = torch.cuda.memory_reserved()

                delta_allocated = after_allocated - before_allocated
                delta_reserved = after_reserved - before_reserved

                # ë³€í™”ëŸ‰ì´ í¬ë©´ ê¸°ë¡
                if abs(delta_allocated) > 10 * 1024 * 1024:  # 10MB ì´ìƒ
                    logger.debug(
                        f"ë©”ëª¨ë¦¬ ë³€í™”: í• ë‹¹={delta_allocated/(1024*1024):.1f}MB, "
                        f"ì˜ˆì•½={delta_reserved/(1024*1024):.1f}MB"
                    )

    @contextmanager
    def batch_processing(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        try:
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
            logger.debug("ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
            yield
        finally:
            # ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ í›„ ì •ë¦¬
            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                logger.debug("ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ ë° ë©”ëª¨ë¦¬ ì •ë¦¬")
            except Exception as e:
                logger.warning(f"ë°°ì¹˜ ì²˜ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def should_cleanup(self) -> bool:
        """
        ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš” ì—¬ë¶€ í™•ì¸ - ìµœì í™”ëœ ë²„ì „

        Returns:
            ì •ë¦¬ í•„ìš” ì—¬ë¶€
        """
        try:
            current_time = time.time()

            # ìµœì†Œ ì •ë¦¬ ê°„ê²© í™•ì¸ (30ì´ˆë¡œ ì¦ê°€)
            if current_time - self._last_cleanup_time < self.cleanup_interval:
                return False

            if torch.cuda.is_available():
                # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê²€ì‚¬
                memory_usage = (
                    torch.cuda.memory_allocated()
                    / torch.cuda.get_device_properties(0).total_memory
                )

                # ë©”ëª¨ë¦¬ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                self._update_memory_history(memory_usage)

                # ê²½ê³  ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê²½ê³  ë°œìƒ
                if (
                    memory_usage > self.config.memory_usage_warning
                    and not self._memory_warning_issued
                ):
                    self._memory_warning_issued = True
                    self._memory_warning_count += 1
                    self._last_warning_time = current_time
                    logger.warning(
                        f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {memory_usage*100:.1f}% "
                        f"(ê²½ê³  {self._memory_warning_count}íšŒ ë°œìƒ)"
                    )

                # ê²½ê³  ìƒíƒœ ë³µêµ¬
                if (
                    self._memory_warning_issued
                    and memory_usage < self.config.memory_usage_warning - 0.1
                ):
                    self._memory_warning_issued = False

                # ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì¡°ê±´
                memory_pressure = memory_usage > self.cleanup_threshold
                increasing_trend = self._is_memory_increasing()

                should_clean = memory_pressure or (
                    increasing_trend and memory_usage > 0.6
                )

                if should_clean and self.performance_monitoring:
                    logger.info(
                        f"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš”: ì‚¬ìš©ë¥ ={memory_usage*100:.1f}%"
                    )

                return should_clean
            else:
                # CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê²€ì‚¬
                memory_usage = psutil.virtual_memory().percent / 100.0
                self._update_memory_history(memory_usage)

                memory_pressure = memory_usage > self.cleanup_threshold
                increasing_trend = self._is_memory_increasing()

                should_clean = memory_pressure or (
                    increasing_trend and memory_usage > 0.7
                )

                if should_clean and self.performance_monitoring:
                    logger.info(
                        f"ğŸ§¹ CPU ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš”: ì‚¬ìš©ë¥ ={memory_usage*100:.1f}%"
                    )

                return should_clean

        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìš” ì—¬ë¶€ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    def _update_memory_history(self, usage: float):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
        current_time = time.time()

        if not hasattr(self, "_memory_history"):
            self._memory_history = []

        self._memory_history.append((current_time, usage))

        # ìµœê·¼ 10ê°œ ê¸°ë¡ë§Œ ìœ ì§€
        if len(self._memory_history) > 10:
            self._memory_history = self._memory_history[-10:]

    def _is_memory_increasing(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì¶”ì„¸ í™•ì¸"""
        if not hasattr(self, "_memory_history") or len(self._memory_history) < 3:
            return False

        try:
            # ìµœê·¼ 3ê°œ ê¸°ë¡ì˜ í‰ê· ê³¼ ì´ì „ ê¸°ë¡ ë¹„êµ
            recent_avg = sum(usage for _, usage in self._memory_history[-3:]) / 3
            older_avg = (
                sum(usage for _, usage in self._memory_history[-6:-3]) / 3
                if len(self._memory_history) >= 6
                else recent_avg
            )

            # 10% ì´ìƒ ì¦ê°€ì‹œ ì¦ê°€ ì¶”ì„¸ë¡œ íŒë‹¨
            return recent_avg > older_avg * 1.1

        except Exception:
            return False

    def cleanup(self) -> None:
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            with self.lock:
                start_time = time.time()

                # ìºì‹œëœ í…ì„œ ì •ë¦¬
                for key in list(self.allocations.keys()):
                    del self.allocations[key]
                self.allocations.clear()

                # í…ì„œ ìºì‹œ ì •ë¦¬
                if hasattr(self, "tensor_cache"):
                    self.tensor_cache.clear()

                # CUDA ìºì‹œ ì •ë¦¬
                if torch.cuda.is_available():
                    # ì§„í–‰ ì¤‘ì¸ CUDA ì‘ì—… ë™ê¸°í™”
                    torch.cuda.synchronize()

                    # CUDA ìºì‹œ ì •ë¦¬
                    torch.cuda.empty_cache()

                    # GPU ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
                    memory_allocated = torch.cuda.memory_allocated() / (1024 * 1024)
                    memory_reserved = torch.cuda.memory_reserved() / (1024 * 1024)
                    logger.debug(
                        f"CUDA ë©”ëª¨ë¦¬ ì •ë¦¬ í›„: í• ë‹¹={memory_allocated:.1f}MB, ì˜ˆì•½={memory_reserved:.1f}MB"
                    )

                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
                gc.collect()

                # í’€ ì •ë¦¬ ê³ ë ¤
                if hasattr(self, "memory_pool"):
                    if random.random() < 0.1:  # 10% í™•ë¥ ë¡œ í’€ë„ ì™„ì „ ì •ë¦¬
                        self.memory_pool.cleanup()
                        logger.debug("ë©”ëª¨ë¦¬ í’€ ì •ë¦¬ ì™„ë£Œ")

                duration = time.time() - start_time
                if duration > 0.1:  # 0.1ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš°ë§Œ INFO ë¡œê·¸
                    logger.info(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ)")
                else:
                    logger.debug(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ)")

        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            traceback.print_exc()

    def get_memory_usage(self, memory_type: str = "gpu") -> float:
        """
        ì‹œìŠ¤í…œ/GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            memory_type: "gpu" ë˜ëŠ” "ram" (ê¸°ë³¸ê°’: "gpu")

        Returns:
            ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (0.0 ~ 1.0)
        """
        try:
            if memory_type == "gpu" and torch.cuda.is_available():
                # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                total_memory = torch.cuda.get_device_properties(0).total_memory
                memory_allocated = torch.cuda.memory_allocated(0)
                return memory_allocated / total_memory
            else:
                # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                return psutil.virtual_memory().percent / 100.0
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def get_available_memory(self, memory_type: str = "cpu") -> float:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ë¹„ìœ¨ ë°˜í™˜

        Args:
            memory_type: ë©”ëª¨ë¦¬ ìœ í˜• ("gpu" ë˜ëŠ” "cpu")

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ë¹„ìœ¨ (0.0 ~ 1.0)
        """
        try:
            if memory_type == "gpu" and torch.cuda.is_available():
                total_memory = torch.cuda.get_device_properties(0).total_memory
                memory_allocated = torch.cuda.memory_allocated(0)
                return 1.0 - (memory_allocated / total_memory)
            elif memory_type == "cpu":
                memory_info = psutil.virtual_memory()
                return memory_info.available / memory_info.total
            else:
                return 1.0  # ê¸°ë³¸ê°’
        except Exception as e:
            logger.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0.5  # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’

    def check_gpu_memory(self, required_bytes: int) -> bool:
        """
        GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸

        Args:
            required_bytes: í•„ìš”í•œ ë©”ëª¨ë¦¬ í¬ê¸° (ë°”ì´íŠ¸)

        Returns:
            ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
        """
        try:
            if not torch.cuda.is_available():
                return False

            total_memory = torch.cuda.get_device_properties(0).total_memory
            memory_allocated = torch.cuda.memory_allocated(0)
            available_memory = total_memory - memory_allocated

            # ì•ˆì „ ë§ˆì§„ 10% ì ìš©
            safe_available = available_memory * 0.9

            return required_bytes <= safe_available
        except Exception as e:
            logger.error(f"GPU ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def _update_gpu_memory_stats(self):
        """GPU ë©”ëª¨ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if torch.cuda.is_available():
            try:
                current_device = torch.cuda.current_device()
                self.gpu_memory_allocated = torch.cuda.memory_allocated(
                    current_device
                ) / (1024 * 1024)
                self.gpu_memory_reserved = torch.cuda.memory_reserved(
                    current_device
                ) / (1024 * 1024)

                # OOM ìœ„í—˜ ê°ì§€
                if self.gpu_memory_allocated > 0.95 * torch.cuda.get_device_properties(
                    0
                ).total_memory / (1024 * 1024):
                    logger.warning(
                        f"OOM ìœ„í—˜! GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {self.gpu_memory_allocated:.1f}MB"
                    )
                    # ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬
                    self.cleanup()
            except Exception as e:
                logger.error(f"GPU ë©”ëª¨ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

    def clear_cache(self):
        """ë©”ëª¨ë¦¬ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        try:
            # í…ì„œ ìºì‹œ ì •ë¦¬
            if hasattr(self, "tensor_cache"):
                self.tensor_cache.clear()

            # ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ ì •ë¦¬
            if hasattr(self, "thread_local_cache"):
                self.thread_local_cache.clear()

            # CUDA ìºì‹œ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.info("CUDA ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ê·¸ ì™¸ í• ë‹¹ ìºì‹œ ì •ë¦¬
            with self.lock:
                if hasattr(self, "allocations"):
                    self.allocations.clear()

            # ê°€ë¹„ì§€ ì»¬ë ‰í„° ì‹¤í–‰
            gc.collect()

            logger.info("ëª¨ë“  ë©”ëª¨ë¦¬ ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True

        except Exception as e:
            logger.error(f"ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    def _cleanup_internal(self):
        """ë‚´ë¶€ ì •ë¦¬ ë¡œì§"""
        try:
            # ì •ë¦¬ ìŠ¤ë ˆë“œ ì¢…ë£Œ
            if hasattr(self, "stop_event"):
                self.stop_event.set()

            # ì‹¤ì œ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
            self._perform_cleanup()

            logger.info("ë‚´ë¶€ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            # ì†Œë©¸ìì—ì„œ í˜¸ì¶œë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€í•œ ì˜ˆì™¸ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            try:
                logger.error(f"ë‚´ë¶€ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            except Exception:
                pass

    def _perform_cleanup(self):
        """ìì› ì •ë¦¬ ì‘ì—…"""
        try:
            # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()

            # 1. CUDA ìºì‹œ ì •ë¦¬
            if torch.cuda.is_available():
                # ìºì‹œ ì •ë¦¬ ì „ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                before_memory = torch.cuda.memory_allocated() / (1024 * 1024)

                # ìºì‹œ ì •ë¦¬
                torch.cuda.empty_cache()

                # ë™ê¸°í™” ë° ìºì‹œ ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                torch.cuda.synchronize()
                after_memory = torch.cuda.memory_allocated() / (1024 * 1024)

                # ë©”ëª¨ë¦¬ ë³€í™” ë¡œê¹…
                if before_memory - after_memory > 5:  # 5MB ì´ìƒ ì ˆì•½ëœ ê²½ìš°ë§Œ ë¡œê¹…
                    logger.debug(
                        f"CUDA ìºì‹œ ì •ë¦¬: {before_memory:.1f}MB â†’ {after_memory:.1f}MB "
                        f"(ì ˆì•½: {before_memory - after_memory:.1f}MB)"
                    )

            # 2. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            gc.collect()

            # 3. ë©”ëª¨ë¦¬ í’€ ì •ë¦¬ (20% í™•ë¥ )
            if hasattr(self, "memory_pool") and random.random() < 0.2:
                self.memory_pool.cleanup()

            # 4. ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹œ ì •ë¦¬
            if hasattr(self, "thread_local_cache"):
                self.thread_local_cache._cleanup()

            # ì†Œìš” ì‹œê°„ ê³„ì‚° ë° ë¡œê¹…
            duration = time.time() - start_time
            logger.debug(f"ì •ë¦¬ ì‘ì—… ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ)")

        except Exception as e:
            logger.error(f"ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def _process_allocation_task(self, task):
        """í• ë‹¹ ì‘ì—… ì²˜ë¦¬"""
        if task is None:
            return  # ì¢…ë£Œ ì‹ í˜¸

        try:
            # ì‘ì—… ì²˜ë¦¬ ë¡œì§
            pass  # ì‹¤ì œ êµ¬í˜„ ë‚´ìš©ì€ ì—¬ê¸°ì— ì¶”ê°€
        except Exception as e:
            logger.error(f"í• ë‹¹ ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _process_deallocation_task(self, task):
        """í•´ì œ ì‘ì—… ì²˜ë¦¬"""
        if task is None:
            return  # ì¢…ë£Œ ì‹ í˜¸

        try:
            # ì‘ì—… ì²˜ë¦¬ ë¡œì§
            pass  # ì‹¤ì œ êµ¬í˜„ ë‚´ìš©ì€ ì—¬ê¸°ì— ì¶”ê°€
        except Exception as e:
            logger.error(f"í•´ì œ ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            # ì •ë¦¬ ìŠ¤ë ˆë“œ ì¢…ë£Œ
            if hasattr(self, "stop_event"):
                self.stop_event.set()

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()

            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, "executor") and self.executor is not None:
                self.executor.shutdown(wait=False)

            logger.debug("ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            with self.lock:
                start_time = time.time()

                # ìºì‹œëœ í…ì„œ ì •ë¦¬
                for key in list(self.allocations.keys()):
                    del self.allocations[key]
                self.allocations.clear()

                # í…ì„œ ìºì‹œ ì •ë¦¬
                if hasattr(self, "tensor_cache"):
                    self.tensor_cache.clear()

                # CUDA ìºì‹œ ì •ë¦¬
                if torch.cuda.is_available():
                    # ì§„í–‰ ì¤‘ì¸ CUDA ì‘ì—… ë™ê¸°í™”
                    torch.cuda.synchronize()

                    # CUDA ìºì‹œ ì •ë¦¬
                    torch.cuda.empty_cache()

                    # GPU ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
                    memory_allocated = torch.cuda.memory_allocated() / (1024 * 1024)
                    memory_reserved = torch.cuda.memory_reserved() / (1024 * 1024)
                    logger.debug(
                        f"CUDA ë©”ëª¨ë¦¬ ì •ë¦¬ í›„: í• ë‹¹={memory_allocated:.1f}MB, ì˜ˆì•½={memory_reserved:.1f}MB"
                    )

                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
                gc.collect()

                # í’€ ì •ë¦¬ ê³ ë ¤
                if hasattr(self, "memory_pool"):
                    if random.random() < 0.1:  # 10% í™•ë¥ ë¡œ í’€ë„ ì™„ì „ ì •ë¦¬
                        self.memory_pool.cleanup()
                        logger.debug("ë©”ëª¨ë¦¬ í’€ ì •ë¦¬ ì™„ë£Œ")

                duration = time.time() - start_time
                if duration > 0.1:  # 0.1ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš°ë§Œ INFO ë¡œê·¸
                    logger.info(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ)")
                else:
                    logger.debug(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ)")

                return True
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return False

    def check_memory_for_batch(
        self, batch_size: int, operation_name: str = "", memory_type: str = "gpu"
    ) -> bool:
        """
        íŠ¹ì • ë°°ì¹˜ í¬ê¸°ì˜ ì‘ì—…ì— ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸

        Args:
            batch_size: í™•ì¸í•  ë°°ì¹˜ í¬ê¸°
            operation_name: ì‘ì—… ì´ë¦„ (ë¡œê¹…ìš©)
            memory_type: í™•ì¸í•  ë©”ëª¨ë¦¬ ìœ í˜• ("gpu" ë˜ëŠ” "ram")

        Returns:
            ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False
        """
        try:
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            current_usage = self.get_memory_usage(memory_type)

            # ë°°ì¹˜ í¬ê¸°ì— ë”°ë¥¸ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
            # 0.01ì€ ë°°ì¹˜ë‹¹ ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ ì¶”ì •ì¹˜ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ê³¼ ë°ì´í„°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            estimated_increase = 0.01 * batch_size

            # ìµœëŒ€ í—ˆìš© ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            max_allowed = self.config.max_memory_usage

            # ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í—ˆìš© ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
            has_enough_memory = (current_usage + estimated_increase) <= max_allowed

            if not has_enough_memory:
                logger.warning(
                    f"ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜ˆìƒ: {operation_name}, í˜„ì¬={current_usage:.2f}, "
                    f"ì˜ˆìƒ ì¦ê°€={estimated_increase:.2f}, ìµœëŒ€ í—ˆìš©={max_allowed:.2f}"
                )

                # ë¶€ì¡±í•œ ê²½ìš° ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„
                self._cleanup_internal()

                # ì •ë¦¬ í›„ ë‹¤ì‹œ í™•ì¸
                current_usage = self.get_memory_usage(memory_type)
                has_enough_memory = (current_usage + estimated_increase) <= max_allowed

                if has_enough_memory:
                    logger.info(
                        f"ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ í™•ë³´ë¨: {operation_name}"
                    )

            return has_enough_memory

        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return True  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ì§„í–‰ í—ˆìš©

    def get_safe_batch_size(
        self, max_batch_size: Optional[int] = None, memory_type: str = "gpu"
    ) -> int:
        """
        í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœì— ë”°ë¼ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°°ì¹˜ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        Args:
            max_batch_size: ìµœëŒ€ ë°°ì¹˜ í¬ê¸° ì œí•œ (ê¸°ë³¸ê°’: None, ì„¤ì •ì˜ max_batch_size ì‚¬ìš©)
            memory_type: í™•ì¸í•  ë©”ëª¨ë¦¬ ìœ í˜• ("gpu" ë˜ëŠ” "ram")

        Returns:
            ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
        """
        try:
            # ìµœëŒ€ ë°°ì¹˜ í¬ê¸°ê°€ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´
            if max_batch_size is None:
                max_batch_size = self.config.max_batch_size

            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            current_usage = self.get_memory_usage(memory_type)

            # ìµœëŒ€ í—ˆìš© ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            max_allowed = self.config.max_memory_usage

            # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ë¹„ìœ¨
            available_memory_ratio = max(0.0, (max_allowed - current_usage))

            # ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš° ì •ë¦¬ ì‹œë„
            if available_memory_ratio < 0.1:  # 10% ë¯¸ë§Œì˜ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
                logger.warning(
                    f"ë©”ëª¨ë¦¬ ë¶€ì¡±, ì •ë¦¬ ì‹œë„ (ì‚¬ìš© ê°€ëŠ¥: {available_memory_ratio:.1%})"
                )
                self._cleanup_internal()
                current_usage = self.get_memory_usage(memory_type)
                available_memory_ratio = max(0.0, (max_allowed - current_usage))
                logger.info(f"ì •ë¦¬ í›„ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {available_memory_ratio:.1%}")

            # ë°°ì¹˜ë‹¹ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            estimated_memory_per_batch = 0.01  # ë°°ì¹˜ë‹¹ ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ ì¶”ì •ì¹˜

            # ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸° ê³„ì‚° (ìµœì†Œí•œ ì„¤ì •ì˜ min_batch_size ì´ìƒ)
            safe_batch_size = max(
                self.config.min_batch_size,
                min(
                    max_batch_size,
                    int(
                        available_memory_ratio / estimated_memory_per_batch * 0.8
                    ),  # 80%ë§Œ ì‚¬ìš©
                ),
            )

            # ë¡œê·¸ ê¸°ë¡
            logger.debug(
                f"ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°: {safe_batch_size}, "
                f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {available_memory_ratio:.1%}, "
                f"ìµœëŒ€ ë°°ì¹˜ í¬ê¸°: {max_batch_size}"
            )

            return safe_batch_size

        except Exception as e:
            logger.error(f"ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë³´ìˆ˜ì ì¸ ê°’ ë°˜í™˜
            return max(1, min(8, getattr(self.config, "min_batch_size", 1)))


def cleanup_analysis():
    """ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ í•¨ìˆ˜"""
    try:
        # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        gc.collect()

        # CUDA ë©”ëª¨ë¦¬ í•´ì œ
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
        memory_info = psutil.virtual_memory()
        logger.info(
            f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ - ì‚¬ìš©ëŸ‰: {memory_info.percent:.1f}%, ì‚¬ìš©ê°€ëŠ¥: {memory_info.available / (1024**3):.1f}GB"
        )

    except Exception as e:
        logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@contextmanager
def memory_managed_analysis():
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        # ì‹œì‘ ì „ ë©”ëª¨ë¦¬ ìƒíƒœ ê¸°ë¡
        start_memory = psutil.virtual_memory()
        logger.info(f"ë¶„ì„ ì‹œì‘ - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {start_memory.percent:.1f}%")

        yield

    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise
    finally:
        # ì¢…ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_analysis()

        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ ê¸°ë¡
        end_memory = psutil.virtual_memory()
        logger.info(f"ë¶„ì„ ì™„ë£Œ - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {end_memory.percent:.1f}%")


def get_memory_manager(config: Optional[MemoryConfig] = None) -> MemoryManager:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    if config is None:
        config = MemoryConfig()
    return MemoryManager(config)
