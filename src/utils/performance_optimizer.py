"""
í†µí•© ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ

GPU ìµœìš°ì„  ì—°ì‚° ì²˜ë¦¬, ë©€í‹°ì“°ë ˆë“œ ìµœì í™”, ë©”ëª¨ë¦¬ ê´€ë¦¬, í”„ë¡œíŒŒì¼ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import time
import threading
import multiprocessing
from typing import Dict, Any, Optional, List, Callable, Union, Tuple
from dataclasses import dataclass, field
from contextlib import contextmanager
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import psutil
import gc
from functools import wraps
import logging
from pathlib import Path
import json
import numpy as np

# GPU ê´€ë ¨ import (ì„ íƒì )
try:
    import torch
    import torch.nn as nn
    import torch.cuda.amp as amp

    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# NVIDIA GPU ëª¨ë‹ˆí„°ë§ (ì„ íƒì )
try:
    import pynvml

    PYNVML_AVAILABLE = True
    pynvml.nvmlInit()
except ImportError:
    PYNVML_AVAILABLE = False

# ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•œ ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""

    # ì‹œê°„ ê´€ë ¨
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    duration: Optional[float] = None

    # CPU ê´€ë ¨
    cpu_usage_start: float = 0.0
    cpu_usage_end: float = 0.0
    cpu_count: int = field(default_factory=multiprocessing.cpu_count)

    # ë©”ëª¨ë¦¬ ê´€ë ¨
    memory_start: float = 0.0
    memory_end: float = 0.0
    memory_peak: float = 0.0
    memory_diff: float = 0.0

    # GPU ê´€ë ¨ (CUDA ì‚¬ìš© ê°€ëŠ¥ì‹œ)
    gpu_memory_start: Optional[float] = None
    gpu_memory_end: Optional[float] = None
    gpu_memory_peak: Optional[float] = None
    gpu_utilization: Optional[float] = None
    gpu_temperature: Optional[float] = None

    # ì²˜ë¦¬ëŸ‰ ê´€ë ¨
    items_processed: int = 0
    throughput: Optional[float] = None  # items/second

    # ê¸°íƒ€
    function_name: str = ""
    thread_id: int = field(default_factory=threading.get_ident)
    process_id: int = field(default_factory=os.getpid)

    def finalize(self):
        """ë©”íŠ¸ë¦­ ìµœì¢… ê³„ì‚°"""
        if self.end_time is None:
            self.end_time = time.time()

        self.duration = self.end_time - self.start_time
        self.memory_diff = self.memory_end - self.memory_start

        if self.duration > 0 and self.items_processed > 0:
            self.throughput = self.items_processed / self.duration

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "function_name": self.function_name,
            "duration": self.duration,
            "cpu_usage_start": self.cpu_usage_start,
            "cpu_usage_end": self.cpu_usage_end,
            "memory_start_mb": self.memory_start,
            "memory_end_mb": self.memory_end,
            "memory_diff_mb": self.memory_diff,
            "memory_peak_mb": self.memory_peak,
            "gpu_memory_start_mb": self.gpu_memory_start,
            "gpu_memory_end_mb": self.gpu_memory_end,
            "gpu_memory_peak_mb": self.gpu_memory_peak,
            "gpu_utilization": self.gpu_utilization,
            "gpu_temperature": self.gpu_temperature,
            "items_processed": self.items_processed,
            "throughput": self.throughput,
            "thread_id": self.thread_id,
            "process_id": self.process_id,
        }


class GPUOptimizer:
    """GPU ìµœì í™” í´ë˜ìŠ¤"""

    def __init__(self):
        self.device = None
        self.device_count = 0
        self.memory_fraction = 0.9
        self.amp_enabled = False

        if TORCH_AVAILABLE and torch.cuda.is_available():
            self.device = torch.device("cuda")
            self.device_count = torch.cuda.device_count()
            self._setup_gpu_optimizations()
        else:
            self.device = torch.device("cpu") if TORCH_AVAILABLE else None
            logger.warning("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

    def _setup_gpu_optimizations(self):
        """GPU ìµœì í™” ì„¤ì •"""
        if not TORCH_AVAILABLE:
            return

        try:
            # ë©”ëª¨ë¦¬ í’€ ì„¤ì •
            torch.cuda.set_per_process_memory_fraction(self.memory_fraction)

            # cuDNN ìµœì í™”
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True

            # AMP í™œì„±í™”
            self.amp_enabled = True

            logger.info(f"GPU ìµœì í™” ì„¤ì • ì™„ë£Œ - {self.device_count}ê°œ GPU ì‚¬ìš© ê°€ëŠ¥")

        except Exception as e:
            logger.error(f"GPU ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")

    def get_gpu_memory_info(self) -> Dict[str, float]:
        """GPU ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            return {}

        try:
            memory_allocated = torch.cuda.memory_allocated() / 1024**2  # MB
            memory_reserved = torch.cuda.memory_reserved() / 1024**2  # MB
            memory_total = (
                torch.cuda.get_device_properties(0).total_memory / 1024**2
            )  # MB

            return {
                "allocated_mb": memory_allocated,
                "reserved_mb": memory_reserved,
                "total_mb": memory_total,
                "utilization_percent": (memory_allocated / memory_total) * 100,
            }
        except Exception as e:
            logger.error(f"GPU ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

    def get_gpu_temperature(self) -> Optional[float]:
        """GPU ì˜¨ë„ ë°˜í™˜"""
        if not PYNVML_AVAILABLE:
            return None

        try:
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
            return float(temp)
        except Exception as e:
            logger.debug(f"GPU ì˜¨ë„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None

    def optimize_tensor(self, tensor: "torch.Tensor") -> "torch.Tensor":
        """í…ì„œ GPU ìµœì í™”"""
        if not TORCH_AVAILABLE or self.device is None:
            return tensor

        try:
            # GPUë¡œ ì´ë™
            if self.device.type == "cuda" and not tensor.is_cuda:
                tensor = tensor.to(self.device, non_blocking=True)

            # ë©”ëª¨ë¦¬ ë ˆì´ì•„ì›ƒ ìµœì í™”
            if not tensor.is_contiguous():
                tensor = tensor.contiguous()

            return tensor

        except Exception as e:
            logger.error(f"í…ì„œ ìµœì í™” ì‹¤íŒ¨: {e}")
            return tensor

    @contextmanager
    def autocast_context(self):
        """AMP autocast ì»¨í…ìŠ¤íŠ¸"""
        if TORCH_AVAILABLE and self.amp_enabled and torch.cuda.is_available():
            with torch.cuda.amp.autocast():
                yield
        else:
            yield

    def clear_gpu_cache(self):
        """GPU ìºì‹œ ì •ë¦¬"""
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()


class MemoryOptimizer:
    """ë©”ëª¨ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""

    def __init__(self, max_memory_percent: float = 80.0):
        self.max_memory_percent = max_memory_percent
        self.process = psutil.Process()

    def get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB)"""
        return self.process.memory_info().rss / 1024 / 1024

    def get_memory_percent(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë°˜í™˜ (%)"""
        return self.process.memory_percent()

    def is_memory_critical(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì ì„ ë„˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.get_memory_percent() > self.max_memory_percent

    def force_garbage_collection(self):
        """ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜"""
        collected = gc.collect()
        logger.debug(f"ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì™„ë£Œ: {collected}ê°œ ê°ì²´ ì •ë¦¬")
        return collected

    @contextmanager
    def memory_monitor(self, threshold_mb: float = 100.0):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì»¨í…ìŠ¤íŠ¸"""
        start_memory = self.get_memory_usage()

        try:
            yield
        finally:
            end_memory = self.get_memory_usage()
            memory_diff = end_memory - start_memory

            if memory_diff > threshold_mb:
                logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€: {memory_diff:.1f}MB")

            if self.is_memory_critical():
                logger.warning(
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì ì„ ë„˜ì—ˆìŠµë‹ˆë‹¤. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
                )
                self.force_garbage_collection()


class MultiThreadOptimizer:
    """ë©€í‹°ìŠ¤ë ˆë“œ ìµœì í™” í´ë˜ìŠ¤"""

    def __init__(self, max_workers: Optional[int] = None):
        self.max_workers = max_workers or min(32, (os.cpu_count() or 1) + 4)
        self.cpu_count = os.cpu_count() or 1

    def parallel_map(
        self,
        func: Callable,
        items: List[Any],
        use_processes: bool = False,
        chunk_size: Optional[int] = None,
    ) -> List[Any]:
        """ë³‘ë ¬ ë§µ ì²˜ë¦¬"""
        if len(items) <= 1:
            return [func(item) for item in items]

        # ì²­í¬ í¬ê¸° ìë™ ê³„ì‚°
        if chunk_size is None:
            chunk_size = max(1, len(items) // (self.max_workers * 2))

        executor_class = ProcessPoolExecutor if use_processes else ThreadPoolExecutor

        try:
            with executor_class(max_workers=self.max_workers) as executor:
                if use_processes and chunk_size > 1:
                    # í”„ë¡œì„¸ìŠ¤ í’€ì—ì„œëŠ” ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                    chunks = [
                        items[i : i + chunk_size]
                        for i in range(0, len(items), chunk_size)
                    ]
                    chunk_func = lambda chunk: [func(item) for item in chunk]

                    futures = [executor.submit(chunk_func, chunk) for chunk in chunks]
                    results = []

                    for future in as_completed(futures):
                        results.extend(future.result())

                    # ì›ë˜ ìˆœì„œ ë³µì›
                    return results[: len(items)]
                else:
                    # ìŠ¤ë ˆë“œ í’€ì—ì„œëŠ” ê°œë³„ ì²˜ë¦¬
                    futures = [executor.submit(func, item) for item in items]
                    return [future.result() for future in futures]

        except Exception as e:
            logger.error(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # í´ë°±: ìˆœì°¨ ì²˜ë¦¬
            return [func(item) for item in items]

    def batch_process(
        self,
        func: Callable,
        items: List[Any],
        batch_size: int = 100,
        progress_callback: Optional[Callable] = None,
    ) -> List[Any]:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        results = []
        total_batches = (len(items) + batch_size - 1) // batch_size

        for i, batch_start in enumerate(range(0, len(items), batch_size)):
            batch_end = min(batch_start + batch_size, len(items))
            batch = items[batch_start:batch_end]

            batch_results = [func(item) for item in batch]
            results.extend(batch_results)

            if progress_callback:
                progress_callback(i + 1, total_batches)

        return results


class PerformanceProfiler:
    """ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬"""

    def __init__(self, save_to_file: bool = True, output_dir: str = "logs/performance"):
        self.save_to_file = save_to_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.gpu_optimizer = GPUOptimizer()
        self.memory_optimizer = MemoryOptimizer()

        self.metrics_history: List[PerformanceMetrics] = []
        self._lock = threading.Lock()

    def profile_function(
        self,
        func: Optional[Callable] = None,
        *,
        include_gpu: bool = True,
        include_memory: bool = True,
        items_count: Optional[int] = None,
    ):
        """í•¨ìˆ˜ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""

        def decorator(f: Callable):
            @wraps(f)
            def wrapper(*args, **kwargs):
                metrics = PerformanceMetrics(function_name=f.__name__)

                # ì‹œì‘ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics.start_time = time.time()

                if include_memory:
                    metrics.memory_start = self.memory_optimizer.get_memory_usage()
                    metrics.cpu_usage_start = psutil.cpu_percent()

                if (
                    include_gpu
                    and self.gpu_optimizer.device
                    and self.gpu_optimizer.device.type == "cuda"
                ):
                    gpu_info = self.gpu_optimizer.get_gpu_memory_info()
                    metrics.gpu_memory_start = gpu_info.get("allocated_mb", 0)
                    metrics.gpu_temperature = self.gpu_optimizer.get_gpu_temperature()

                try:
                    # í•¨ìˆ˜ ì‹¤í–‰
                    result = f(*args, **kwargs)

                    # ì²˜ë¦¬ëœ ì•„ì´í…œ ìˆ˜ ì„¤ì •
                    if items_count is not None:
                        metrics.items_processed = items_count
                    elif hasattr(result, "__len__"):
                        try:
                            metrics.items_processed = len(result)
                        except:
                            pass

                    return result

                finally:
                    # ì¢…ë£Œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                    metrics.end_time = time.time()

                    if include_memory:
                        metrics.memory_end = self.memory_optimizer.get_memory_usage()
                        metrics.cpu_usage_end = psutil.cpu_percent()

                        # ë©”ëª¨ë¦¬ í”¼í¬ ì¶”ì •
                        metrics.memory_peak = max(
                            metrics.memory_start, metrics.memory_end
                        )

                    if (
                        include_gpu
                        and self.gpu_optimizer.device
                        and self.gpu_optimizer.device.type == "cuda"
                    ):
                        gpu_info = self.gpu_optimizer.get_gpu_memory_info()
                        metrics.gpu_memory_end = gpu_info.get("allocated_mb", 0)
                        metrics.gpu_utilization = gpu_info.get("utilization_percent", 0)

                        if metrics.gpu_memory_start is not None:
                            metrics.gpu_memory_peak = max(
                                metrics.gpu_memory_start, metrics.gpu_memory_end
                            )

                    # ë©”íŠ¸ë¦­ ìµœì¢… ê³„ì‚°
                    metrics.finalize()

                    # ë©”íŠ¸ë¦­ ì €ì¥
                    self._save_metrics(metrics)

                    # ë¡œê¹…
                    self._log_performance(metrics)

            return wrapper

        if func is None:
            return decorator
        else:
            return decorator(func)

    def _save_metrics(self, metrics: PerformanceMetrics):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        with self._lock:
            self.metrics_history.append(metrics)

            # íŒŒì¼ ì €ì¥
            if self.save_to_file:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"performance_{timestamp}_{metrics.function_name}.json"
                filepath = self.output_dir / filename

                try:
                    with open(filepath, "w", encoding="utf-8") as f:
                        json.dump(metrics.to_dict(), f, indent=2)
                except Exception as e:
                    logger.error(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _log_performance(self, metrics: PerformanceMetrics):
        """ì„±ëŠ¥ ë¡œê¹…"""
        log_msg = f"ğŸš€ {metrics.function_name} ì„±ëŠ¥ ë¶„ì„:"
        log_msg += f"\n  â±ï¸  ì‹¤í–‰ ì‹œê°„: {metrics.duration:.3f}ì´ˆ"

        if metrics.memory_diff != 0:
            log_msg += f"\n  ğŸ’¾ ë©”ëª¨ë¦¬ ë³€í™”: {metrics.memory_diff:+.1f}MB"

        if metrics.throughput:
            log_msg += f"\n  ğŸ“Š ì²˜ë¦¬ëŸ‰: {metrics.throughput:.1f} items/sec"

        if metrics.gpu_memory_start is not None:
            gpu_diff = (metrics.gpu_memory_end or 0) - metrics.gpu_memory_start
            log_msg += f"\n  ğŸ® GPU ë©”ëª¨ë¦¬ ë³€í™”: {gpu_diff:+.1f}MB"

        if metrics.gpu_temperature:
            log_msg += f"\n  ğŸŒ¡ï¸  GPU ì˜¨ë„: {metrics.gpu_temperature}Â°C"

        logger.info(log_msg)

    def get_performance_summary(
        self, function_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        with self._lock:
            if function_name:
                filtered_metrics = [
                    m for m in self.metrics_history if m.function_name == function_name
                ]
            else:
                filtered_metrics = self.metrics_history

            if not filtered_metrics:
                return {}

            durations = [m.duration for m in filtered_metrics if m.duration]
            memory_diffs = [m.memory_diff for m in filtered_metrics]
            throughputs = [m.throughput for m in filtered_metrics if m.throughput]

            return {
                "function_name": function_name or "all",
                "call_count": len(filtered_metrics),
                "avg_duration": sum(durations) / len(durations) if durations else 0,
                "min_duration": min(durations) if durations else 0,
                "max_duration": max(durations) if durations else 0,
                "avg_memory_diff": (
                    sum(memory_diffs) / len(memory_diffs) if memory_diffs else 0
                ),
                "avg_throughput": (
                    sum(throughputs) / len(throughputs) if throughputs else 0
                ),
                "total_items_processed": sum(
                    m.items_processed for m in filtered_metrics
                ),
            }

    def clear_history(self):
        """íˆìŠ¤í† ë¦¬ ì •ë¦¬"""
        with self._lock:
            self.metrics_history.clear()


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_profiler = None
_profiler_lock = threading.Lock()


def get_performance_profiler() -> PerformanceProfiler:
    """ì „ì—­ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬ ë°˜í™˜"""
    global _global_profiler

    if _global_profiler is None:
        with _profiler_lock:
            if _global_profiler is None:
                _global_profiler = PerformanceProfiler()

    return _global_profiler


# í¸ì˜ í•¨ìˆ˜ë“¤
def profile(func: Optional[Callable] = None, **kwargs):
    """ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„° (í¸ì˜ í•¨ìˆ˜)"""
    profiler = get_performance_profiler()
    return profiler.profile_function(func, **kwargs)


@contextmanager
def gpu_optimization():
    """GPU ìµœì í™” ì»¨í…ìŠ¤íŠ¸"""
    optimizer = GPUOptimizer()
    try:
        with optimizer.autocast_context():
            yield optimizer
    finally:
        optimizer.clear_gpu_cache()


@contextmanager
def memory_optimization(threshold_mb: float = 100.0):
    """ë©”ëª¨ë¦¬ ìµœì í™” ì»¨í…ìŠ¤íŠ¸"""
    optimizer = MemoryOptimizer()
    with optimizer.memory_monitor(threshold_mb):
        yield optimizer


def parallel_map(func: Callable, items: List[Any], **kwargs) -> List[Any]:
    """ë³‘ë ¬ ë§µ ì²˜ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    optimizer = MultiThreadOptimizer()
    return optimizer.parallel_map(func, items, **kwargs)


def get_system_performance_report() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
    # CPU ì •ë³´
    cpu_info = {
        "count": os.cpu_count(),
        "usage_percent": psutil.cpu_percent(interval=1),
        "frequency": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else {},
    }

    # ë©”ëª¨ë¦¬ ì •ë³´
    memory_info = psutil.virtual_memory()._asdict()
    memory_info["usage_gb"] = memory_info["used"] / 1024**3
    memory_info["available_gb"] = memory_info["available"] / 1024**3

    # GPU ì •ë³´
    gpu_optimizer = GPUOptimizer()
    gpu_info = gpu_optimizer.get_gpu_memory_info()
    gpu_info["temperature"] = gpu_optimizer.get_gpu_temperature()
    gpu_info["device_count"] = gpu_optimizer.device_count

    # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬ ìš”ì•½
    profiler = get_performance_profiler()
    performance_summary = profiler.get_performance_summary()

    return {
        "timestamp": time.time(),
        "cpu": cpu_info,
        "memory": memory_info,
        "gpu": gpu_info,
        "performance_summary": performance_summary,
    }


@dataclass
class ComputationStrategy:
    """ì—°ì‚° ì „ëµ ì •ì˜"""

    strategy_type: str  # "gpu", "multithread", "cpu"
    device: Optional[str] = None
    workers: Optional[int] = None
    memory_efficient: bool = True
    use_amp: bool = False

    def __post_init__(self):
        if (
            self.strategy_type == "gpu"
            and TORCH_AVAILABLE
            and torch.cuda.is_available()
        ):
            self.device = "cuda"
            self.use_amp = True
        elif self.strategy_type == "multithread":
            self.workers = self.workers or min(multiprocessing.cpu_count(), 8)
        elif self.strategy_type == "cpu":
            self.workers = 1


class SmartComputationEngine:
    """ìŠ¤ë§ˆíŠ¸ ì—°ì‚° ì—”ì§„ - GPU > ë©€í‹°ì“°ë ˆë“œ > CPU ìˆœ ì²˜ë¦¬"""

    def __init__(self, gpu_memory_threshold: float = 0.8):
        self.gpu_memory_threshold = gpu_memory_threshold
        self.logger = logging.getLogger(__name__)
        self._initialize_strategies()

    def _initialize_strategies(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ì‚° ì „ëµ ì´ˆê¸°í™”"""
        self.strategies = []

        # 1. GPU ì „ëµ (ìµœìš°ì„ )
        if TORCH_AVAILABLE and torch.cuda.is_available():
            self.strategies.append(ComputationStrategy("gpu"))
            self.logger.info("GPU ì—°ì‚° ì „ëµ í™œì„±í™”")

        # 2. ë©€í‹°ì“°ë ˆë“œ ì „ëµ
        if multiprocessing.cpu_count() > 1:
            self.strategies.append(ComputationStrategy("multithread"))
            self.logger.info(
                f"ë©€í‹°ì“°ë ˆë“œ ì—°ì‚° ì „ëµ í™œì„±í™” ({multiprocessing.cpu_count()}ê°œ ì½”ì–´)"
            )

        # 3. CPU ì „ëµ (ê¸°ë³¸)
        self.strategies.append(ComputationStrategy("cpu"))
        self.logger.info("CPU ì—°ì‚° ì „ëµ í™œì„±í™”")

    def select_optimal_strategy(
        self, data_size: int, operation_type: str = "general"
    ) -> ComputationStrategy:
        """ìµœì  ì—°ì‚° ì „ëµ ì„ íƒ"""

        # GPU ì „ëµ ìš°ì„  ê²€í† 
        for strategy in self.strategies:
            if strategy.strategy_type == "gpu":
                if self._is_gpu_available_for_computation(data_size):
                    self.logger.info(f"GPU ì „ëµ ì„ íƒ (ë°ì´í„° í¬ê¸°: {data_size})")
                    return strategy
                else:
                    self.logger.warning("GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ë‹¤ë¥¸ ì „ëµ ì„ íƒ")

        # ë©€í‹°ì“°ë ˆë“œ ì „ëµ ê²€í† 
        for strategy in self.strategies:
            if strategy.strategy_type == "multithread":
                if data_size > 1000:  # í° ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ë©€í‹°ì“°ë ˆë“œ í™œìš©
                    self.logger.info(f"ë©€í‹°ì“°ë ˆë“œ ì „ëµ ì„ íƒ (ë°ì´í„° í¬ê¸°: {data_size})")
                    return strategy

        # CPU ì „ëµ (ê¸°ë³¸)
        cpu_strategy = next(s for s in self.strategies if s.strategy_type == "cpu")
        self.logger.info(f"CPU ì „ëµ ì„ íƒ (ë°ì´í„° í¬ê¸°: {data_size})")
        return cpu_strategy

    def _is_gpu_available_for_computation(self, data_size: int) -> bool:
        """GPU ì—°ì‚° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            return False

        try:
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
            memory_allocated = torch.cuda.memory_allocated()
            memory_total = torch.cuda.get_device_properties(0).total_memory
            memory_usage_ratio = memory_allocated / memory_total

            # ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° (ëŒ€ëµì )
            estimated_memory_needed = data_size * 4 * 8  # float32 * 8 (ì—¬ìœ ë¶„)
            available_memory = memory_total - memory_allocated

            return (
                memory_usage_ratio < self.gpu_memory_threshold
                and estimated_memory_needed < available_memory
            )
        except Exception as e:
            self.logger.error(f"GPU ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def execute_computation(self, func: Callable, data: Any, **kwargs) -> Any:
        """ìµœì  ì „ëµìœ¼ë¡œ ì—°ì‚° ì‹¤í–‰"""

        # ë°ì´í„° í¬ê¸° ì¶”ì •
        data_size = self._estimate_data_size(data)

        # ìµœì  ì „ëµ ì„ íƒ
        strategy = self.select_optimal_strategy(
            data_size, kwargs.get("operation_type", "general")
        )

        # ì „ëµë³„ ì‹¤í–‰
        if strategy.strategy_type == "gpu":
            return self._execute_gpu_computation(func, data, strategy, **kwargs)
        elif strategy.strategy_type == "multithread":
            return self._execute_multithread_computation(func, data, strategy, **kwargs)
        else:
            return self._execute_cpu_computation(func, data, strategy, **kwargs)

    def _estimate_data_size(self, data: Any) -> int:
        """ë°ì´í„° í¬ê¸° ì¶”ì •"""
        if hasattr(data, "__len__"):
            return len(data)
        elif isinstance(data, np.ndarray):
            return data.size
        elif TORCH_AVAILABLE and isinstance(data, torch.Tensor):
            return data.numel()
        else:
            return 1

    def _execute_gpu_computation(
        self, func: Callable, data: Any, strategy: ComputationStrategy, **kwargs
    ) -> Any:
        """GPU ì—°ì‚° ì‹¤í–‰"""
        try:
            device = torch.device(strategy.device)

            # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
            if isinstance(data, (list, tuple)):
                # ë¦¬ìŠ¤íŠ¸/íŠœí”Œ ë°ì´í„° ì²˜ë¦¬
                if all(isinstance(item, (int, float)) for item in data):
                    gpu_data = torch.tensor(data, device=device)
                else:
                    gpu_data = data  # ë³µí•© ë°ì´í„°ëŠ” í•¨ìˆ˜ ë‚´ì—ì„œ ì²˜ë¦¬
            elif isinstance(data, np.ndarray):
                gpu_data = torch.from_numpy(data).to(device)
            elif TORCH_AVAILABLE and isinstance(data, torch.Tensor):
                gpu_data = data.to(device)
            else:
                gpu_data = data

            # AMP ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            if strategy.use_amp:
                with torch.cuda.amp.autocast():
                    result = func(gpu_data, **kwargs)
            else:
                result = func(gpu_data, **kwargs)

            # ê²°ê³¼ë¥¼ CPUë¡œ ì´ë™ (í•„ìš”ì‹œ)
            if TORCH_AVAILABLE and isinstance(result, torch.Tensor) and result.is_cuda:
                result = result.cpu()

            return result

        except Exception as e:
            self.logger.error(f"GPU ì—°ì‚° ì‹¤íŒ¨: {e}")
            # GPU ì‹¤íŒ¨ ì‹œ ë©€í‹°ì“°ë ˆë“œë¡œ í´ë°±
            fallback_strategy = ComputationStrategy("multithread")
            return self._execute_multithread_computation(
                func, data, fallback_strategy, **kwargs
            )

    def _execute_multithread_computation(
        self, func: Callable, data: Any, strategy: ComputationStrategy, **kwargs
    ) -> Any:
        """ë©€í‹°ì“°ë ˆë“œ ì—°ì‚° ì‹¤í–‰"""
        try:
            workers = strategy.workers or 1
            if hasattr(data, "__len__") and len(data) > workers:
                # ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í• 
                chunk_size = len(data) // workers
                chunks = [
                    data[i : i + chunk_size] for i in range(0, len(data), chunk_size)
                ]

                # ë©€í‹°ì“°ë ˆë“œ ì‹¤í–‰
                with ThreadPoolExecutor(max_workers=workers) as executor:
                    futures = [
                        executor.submit(func, chunk, **kwargs) for chunk in chunks
                    ]
                    results = [future.result() for future in as_completed(futures)]

                # ê²°ê³¼ ë³‘í•©
                if isinstance(results[0], (list, tuple)):
                    merged_result = []
                    for result in results:
                        merged_result.extend(result)
                    return merged_result
                elif isinstance(results[0], np.ndarray):
                    return np.concatenate(results)
                else:
                    return results
            else:
                # ì‘ì€ ë°ì´í„°ëŠ” ë‹¨ì¼ ìŠ¤ë ˆë“œë¡œ ì²˜ë¦¬
                return func(data, **kwargs)

        except Exception as e:
            self.logger.error(f"ë©€í‹°ì“°ë ˆë“œ ì—°ì‚° ì‹¤íŒ¨: {e}")
            # ë©€í‹°ì“°ë ˆë“œ ì‹¤íŒ¨ ì‹œ CPUë¡œ í´ë°±
            fallback_strategy = ComputationStrategy("cpu")
            return self._execute_cpu_computation(
                func, data, fallback_strategy, **kwargs
            )

    def _execute_cpu_computation(
        self, func: Callable, data: Any, strategy: ComputationStrategy, **kwargs
    ) -> Any:
        """CPU ì—°ì‚° ì‹¤í–‰"""
        try:
            return func(data, **kwargs)
        except Exception as e:
            self.logger.error(f"CPU ì—°ì‚° ì‹¤íŒ¨: {e}")
            raise


# ì „ì—­ ìŠ¤ë§ˆíŠ¸ ì—°ì‚° ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
_smart_computation_engine = None


def get_smart_computation_engine() -> SmartComputationEngine:
    """ìŠ¤ë§ˆíŠ¸ ì—°ì‚° ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _smart_computation_engine
    if _smart_computation_engine is None:
        _smart_computation_engine = SmartComputationEngine()
    return _smart_computation_engine


def smart_compute(func: Callable, data: Any, **kwargs) -> Any:
    """ìŠ¤ë§ˆíŠ¸ ì—°ì‚° ì‹¤í–‰ (GPU > ë©€í‹°ì“°ë ˆë“œ > CPU ìˆœ)"""
    engine = get_smart_computation_engine()
    return engine.execute_computation(func, data, **kwargs)


def optimize_computation(
    data: Any, use_gpu: bool = True, use_multithread: bool = True
) -> Dict[str, Any]:
    """ì—°ì‚° ìµœì í™” ì •ë³´ ë°˜í™˜"""
    engine = get_smart_computation_engine()
    data_size = engine._estimate_data_size(data)
    strategy = engine.select_optimal_strategy(data_size)

    return {
        "data_size": data_size,
        "selected_strategy": strategy.strategy_type,
        "device": strategy.device,
        "workers": strategy.workers,
        "gpu_available": TORCH_AVAILABLE and torch.cuda.is_available(),
        "cpu_count": multiprocessing.cpu_count(),
        "memory_efficient": strategy.memory_efficient,
        "use_amp": strategy.use_amp,
    }
