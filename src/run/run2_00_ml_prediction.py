"""
DAEBAK AI ë¡œë˜ ì‹œìŠ¤í…œ - ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ë‹¨ê³„ (Phase 2)

ì´ ëª¨ë“ˆì€ Phase 1(ë°ì´í„° ë¶„ì„)ì˜ ê²°ê³¼ë¥¼ ì…ë ¥ë°›ì•„ LightGBM ëª¨ë¸ë¡œ
ê¸°ë³¸ íŒ¨í„´ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ML ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Phase 1 ê²°ê³¼ ë¡œë“œ ë° í†µí•©
- LightGBM ëª¨ë¸ GPU ìµœì í™” í•™ìŠµ
- 3ìë¦¬ ëª¨ë“œ ì§€ì› ë° ì˜ˆì¸¡
- ì„±ëŠ¥ ìµœì í™” (GPU > ë©€í‹°ìŠ¤ë ˆë“œ > CPU)
- ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ë° ê²€ì¦
"""

# 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import json
import time
import argparse
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict

# 2. ì„œë“œíŒŒí‹°
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# 3. í”„ë¡œì íŠ¸ ë‚´ë¶€ (ë¦¬íŒ©í† ë§ëœ ì˜ì¡´ì„± ê´€ë¦¬)
from ..utils.dependency_injection import configure_dependencies, resolve
from ..utils.unified_logging import get_logger
from ..utils.data_loader import DataLoader
from ..utils.unified_performance_engine import UnifiedPerformanceEngine, AutoPerformanceMonitor
from ..utils.cuda_optimizers import CudaOptimizer, CudaConfig
from ..utils.unified_config import Config
from ..models.ml.lightgbm_model import LightGBMModel
from ..pipeline.unified_preprocessing_pipeline import UnifiedPreprocessingPipeline
from ..utils.unified_memory_manager import UnifiedMemoryManager
from ..utils.auto_recovery_system import AutoRecoverySystem


@dataclass
class MLPredictionConfig:
    """ML ì˜ˆì¸¡ ì„¤ì •"""

    # ì…ë ¥ ê²½ë¡œ
    analysis_result_dir: str = "data/result/analysis"
    cache_dir: str = "data/cache"

    # ì¶œë ¥ ê²½ë¡œ
    output_dir: str = "data/result/ml_predictions"
    model_save_dir: str = "data/models/lightgbm"

    # ëª¨ë¸ ì„¤ì •
    use_gpu: bool = True
    use_3digit_mode: bool = True
    train_test_split_ratio: float = 0.8
    validation_split_ratio: float = 0.2

    # ì„±ëŠ¥ ì„¤ì •
    max_memory_usage_mb: int = 2048
    target_execution_time_minutes: int = 5
    batch_size: int = 1024

    # íŠ¹ì„± ì„¤ì •
    min_feature_importance: float = 0.001
    max_features: int = 1000

    # ì˜ˆì¸¡ ì„¤ì •
    top_k_predictions: int = 100
    confidence_threshold: float = 0.7


class MLPredictionEngine:
    """ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ì—”ì§„"""

    def __init__(self, cli_config: Optional[Dict[str, Any]] = None):
        """
        ML ì˜ˆì¸¡ ì—”ì§„ ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©)
        """
        # ë¡œê±° ì´ˆê¸°í™”
        self.logger = get_logger(__name__)

        # --- ì˜ì¡´ì„± í•´ê²° ---
        self.config_manager: Config = resolve(Config)
        self.system_config = self.config_manager.get_config("main")
        self.performance_engine: UnifiedPerformanceEngine = resolve(UnifiedPerformanceEngine)
        self.performance_monitor: AutoPerformanceMonitor = resolve(AutoPerformanceMonitor)
        self.data_loader: DataLoader = resolve(DataLoader)
        self.memory_manager: UnifiedMemoryManager = resolve(UnifiedMemoryManager)
        self.error_handler: AutoRecoverySystem = resolve(AutoRecoverySystem)
        # --------------------

        # ì„¤ì • ë¡œë“œ ë° ë³‘í•©
        self.config = MLPredictionConfig()
        if cli_config:
            for key, value in cli_config.items():
                if hasattr(self.config, key):
                    setattr(self.config, key, value)

        # ê²½ë¡œ ì„¤ì •
        self.analysis_result_dir = Path(self.config.analysis_result_dir)
        self.cache_dir = Path(self.config.cache_dir)
        self.output_dir = Path(self.config.output_dir)
        self.model_save_dir = Path(self.config.model_save_dir)

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.model_save_dir.mkdir(parents=True, exist_ok=True)

        # GPU ìµœì í™” ì„¤ì •
        if self.config.use_gpu:
            cuda_config_data = self.system_config.get("cuda_config", {})
            cuda_config = CudaConfig(
                use_amp=cuda_config_data.get("use_amp", True),
                use_tensorrt=cuda_config_data.get("use_tensorrt", False),
                use_cudnn_benchmark=cuda_config_data.get("use_cudnn_benchmark", True),
            )
            self.cuda_optimizer: Optional[CudaOptimizer] = resolve(CudaOptimizer)
            if self.cuda_optimizer:
                self.cuda_optimizer.configure(cuda_config)
        else:
            self.cuda_optimizer = None

        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        self.preprocessing_pipeline = UnifiedPreprocessingPipeline(
            self.system_config.to_dict()
        )

        # LightGBM ëª¨ë¸ ì„¤ì •
        lightgbm_config = self.system_config.get("models", {}).copy()
        lightgbm_config["use_gpu"] = self.config.use_gpu
        lightgbm_config["lightgbm"] = self.system_config.get("models", {}).get(
            "lgbm_params", {}
        )

        if self.config.use_gpu:
            lightgbm_config["lightgbm"]["device_type"] = "gpu"
            lightgbm_config["lightgbm"]["gpu_platform_id"] = 0
            lightgbm_config["lightgbm"]["gpu_device_id"] = 0

        self.lightgbm_model = LightGBMModel(lightgbm_config)

        # ì‹¤í–‰ í†µê³„
        self.execution_stats = {
            "start_time": None,
            "end_time": None,
            "total_time": 0,
            "data_loading_time": 0,
            "preprocessing_time": 0,
            "training_time": 0,
            "prediction_time": 0,
            "memory_usage": {},
            "gpu_usage": {},
            "error_count": 0,
            "warnings": [],
        }

        self.logger.info("âœ… ML ì˜ˆì¸¡ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬: {self.analysis_result_dir}")
        self.logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
        self.logger.info(
            f"ğŸ¯ GPU ì‚¬ìš©: {'í™œì„±í™”' if self.config.use_gpu else 'ë¹„í™œì„±í™”'}"
        )
        self.logger.info(
            f"ğŸ¯ 3ìë¦¬ ëª¨ë“œ: {'í™œì„±í™”' if self.config.use_3digit_mode else 'ë¹„í™œì„±í™”'}"
        )

    def load_analysis_results(self) -> Dict[str, Any]:
        """
        Phase 1 ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë¡œë“œ

        Returns:
            í†µí•©ëœ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("ğŸ“Š Phase 1 ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹œì‘...")

        with self.performance_monitor.track("load_analysis_results"):
            start_time = time.time()

            try:
                # í†µí•© ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ ê²€ìƒ‰
                unified_analysis_files = list(
                    self.analysis_result_dir.glob("unified_analysis_*.json")
                )

                if not unified_analysis_files:
                    raise FileNotFoundError(
                        f"í†µí•© ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.analysis_result_dir}"
                    )

                # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                latest_file = max(
                    unified_analysis_files, key=lambda x: x.stat().st_mtime
                )
                self.logger.info(f"ğŸ“„ ìµœì‹  ë¶„ì„ ê²°ê³¼ íŒŒì¼: {latest_file}")

                # JSON íŒŒì¼ ë¡œë“œ
                with open(latest_file, "r", encoding="utf-8") as f:
                    unified_results = json.load(f)

                # íŠ¹ì„± ë²¡í„° ë¡œë“œ
                vector_file = self.cache_dir / "optimized_feature_vector.npy"
                if vector_file.exists():
                    feature_vectors = np.load(vector_file)
                    self.logger.info(f"ğŸ”¢ íŠ¹ì„± ë²¡í„° ë¡œë“œ: {feature_vectors.shape}")
                else:
                    self.logger.warning(
                        "âš ï¸ ìµœì í™”ëœ íŠ¹ì„± ë²¡í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë²¡í„° ìƒì„± ì¤‘..."
                    )
                    feature_vectors = self._generate_default_feature_vectors(
                        unified_results
                    )

                # 3ìë¦¬ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                prediction_files = list(
                    self.analysis_result_dir.glob("3digit_predictions_*.json")
                )
                digit_predictions = None
                if prediction_files:
                    latest_prediction_file = max(
                        prediction_files, key=lambda x: x.stat().st_mtime
                    )
                    with open(latest_prediction_file, "r", encoding="utf-8") as f:
                        digit_predictions = json.load(f)
                    self.logger.info(
                        f"ğŸ¯ 3ìë¦¬ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ: {latest_prediction_file}"
                    )

                # ê·¸ë˜í”„ ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                graph_features = None
                graph_vector_file = self.cache_dir / "graph_network_features.npy"
                if graph_vector_file.exists():
                    graph_features = np.load(graph_vector_file)
                    self.logger.info(
                        f"ğŸ•¸ï¸ ê·¸ë˜í”„ ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¡œë“œ: {graph_features.shape}"
                    )

                # ë©”íƒ€ íŠ¹ì„± ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                meta_features = None
                meta_vector_file = self.cache_dir / "meta_features.npy"
                if meta_vector_file.exists():
                    meta_features = np.load(meta_vector_file)
                    self.logger.info(f"ğŸ§  ë©”íƒ€ íŠ¹ì„± ë¡œë“œ: {meta_features.shape}")

                # ê²°ê³¼ í†µí•©
                analysis_results = {
                    "unified_analysis": unified_results,
                    "feature_vectors": feature_vectors,
                    "digit_predictions": digit_predictions,
                    "graph_features": graph_features,
                    "meta_features": meta_features,
                    "load_time": time.time() - start_time,
                    "source_files": {
                        "unified_analysis": str(latest_file),
                        "feature_vectors": str(vector_file),
                        "digit_predictions": (
                            str(prediction_files[0]) if prediction_files else None
                        ),
                        "graph_features": (
                            str(graph_vector_file)
                            if graph_vector_file.exists()
                            else None
                        ),
                        "meta_features": (
                            str(meta_vector_file) if meta_vector_file.exists() else None
                        ),
                    },
                }

                self.execution_stats["data_loading_time"] = time.time() - start_time
                self.logger.info(
                    f"âœ… ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ ({self.execution_stats['data_loading_time']:.2f}ì´ˆ)"
                )

                return analysis_results

            except Exception as e:
                self.execution_stats["error_count"] += 1
                self.logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise

    def _generate_default_feature_vectors(
        self, unified_results: Dict[str, Any]
    ) -> np.ndarray:
        """
        ê¸°ë³¸ íŠ¹ì„± ë²¡í„° ìƒì„± (ìµœì í™”ëœ ë²¡í„°ê°€ ì—†ëŠ” ê²½ìš°)

        Args:
            unified_results: í†µí•© ë¶„ì„ ê²°ê³¼

        Returns:
            ê¸°ë³¸ íŠ¹ì„± ë²¡í„°
        """
        self.logger.info("ğŸ”§ ê¸°ë³¸ íŠ¹ì„± ë²¡í„° ìƒì„± ì¤‘...")

        try:
            # ê¸°ë³¸ íŠ¹ì„±ë“¤ ì¶”ì¶œ
            features = []

            # ë¹ˆë„ ë¶„ì„ ê²°ê³¼
            if "frequency_analysis" in unified_results:
                freq_data = unified_results["frequency_analysis"]
                if "number_frequencies" in freq_data:
                    frequencies = [
                        freq_data["number_frequencies"].get(str(i), 0)
                        for i in range(1, 46)
                    ]
                    features.extend(frequencies)

            # íŒ¨í„´ ë¶„ì„ ê²°ê³¼
            if "pattern_analysis" in unified_results:
                pattern_data = unified_results["pattern_analysis"]
                if "pattern_scores" in pattern_data:
                    pattern_scores = list(pattern_data["pattern_scores"].values())
                    features.extend(pattern_scores[:100])  # ìƒìœ„ 100ê°œë§Œ

            # ê¸°ë³¸ ë²¡í„° ìƒì„± (ìµœì†Œ 200ì°¨ì›)
            if len(features) < 200:
                features.extend([0.0] * (200 - len(features)))

            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            feature_vector = np.array(features, dtype=np.float32)

            # 2D ë°°ì—´ë¡œ ë³€í™˜ (ìƒ˜í”Œ ìˆ˜ x íŠ¹ì„± ìˆ˜)
            if feature_vector.ndim == 1:
                feature_vector = feature_vector.reshape(1, -1)

            self.logger.info(f"ğŸ”¢ ê¸°ë³¸ íŠ¹ì„± ë²¡í„° ìƒì„± ì™„ë£Œ: {feature_vector.shape}")
            return feature_vector

        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ íŠ¹ì„± ë²¡í„° ìƒì„± ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ë”ë¯¸ ë²¡í„° ë°˜í™˜
            return np.random.rand(1, 200).astype(np.float32)

    def prepare_training_data(
        self, analysis_results: Dict[str, Any]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        í•™ìŠµ ë°ì´í„° ì¤€ë¹„

        Args:
            analysis_results: ë¶„ì„ ê²°ê³¼

        Returns:
            (X, y) íŠœí”Œ - íŠ¹ì„± ë²¡í„°ì™€ íƒ€ê²Ÿ ì ìˆ˜
        """
        self.logger.info("ğŸ”„ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹œì‘...")

        with self.performance_monitor.track("prepare_training_data"):
            start_time = time.time()

            try:
                # ê¸°ë³¸ íŠ¹ì„± ë²¡í„°
                X_base = analysis_results["feature_vectors"]

                # ì¶”ê°€ íŠ¹ì„±ë“¤ ê²°í•©
                additional_features = []

                # ê·¸ë˜í”„ ë„¤íŠ¸ì›Œí¬ íŠ¹ì„±
                if analysis_results.get("graph_features") is not None:
                    graph_features = analysis_results["graph_features"]
                    if graph_features.shape[0] == X_base.shape[0]:
                        additional_features.append(graph_features)
                        self.logger.info(f"â• ê·¸ë˜í”„ íŠ¹ì„± ì¶”ê°€: {graph_features.shape}")

                # ë©”íƒ€ íŠ¹ì„±
                if analysis_results.get("meta_features") is not None:
                    meta_features = analysis_results["meta_features"]
                    if meta_features.shape[0] == X_base.shape[0]:
                        additional_features.append(meta_features)
                        self.logger.info(f"â• ë©”íƒ€ íŠ¹ì„± ì¶”ê°€: {meta_features.shape}")

                # íŠ¹ì„± ê²°í•©
                if additional_features:
                    X = np.concatenate([X_base] + additional_features, axis=1)
                else:
                    X = X_base

                # íƒ€ê²Ÿ ì ìˆ˜ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê³¼ê±° ë‹¹ì²¨ ë°ì´í„° ê¸°ë°˜)
                y = self._generate_target_scores(X, analysis_results)

                # ë°ì´í„° ê²€ì¦
                if X.shape[0] != y.shape[0]:
                    raise ValueError(
                        f"íŠ¹ì„± ë²¡í„°ì™€ íƒ€ê²Ÿ ì ìˆ˜ì˜ ìƒ˜í”Œ ìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤: {X.shape[0]} vs {y.shape[0]}"
                    )

                # íŠ¹ì„± ìˆ˜ ì œí•œ
                if X.shape[1] > self.config.max_features:
                    self.logger.info(
                        f"ğŸ”§ íŠ¹ì„± ìˆ˜ ì œí•œ: {X.shape[1]} -> {self.config.max_features}"
                    )
                    X = X[:, : self.config.max_features]

                self.execution_stats["preprocessing_time"] = time.time() - start_time
                self.logger.info(
                    f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: X={X.shape}, y={y.shape} ({self.execution_stats['preprocessing_time']:.2f}ì´ˆ)"
                )

                return X, y

            except Exception as e:
                self.execution_stats["error_count"] += 1
                self.logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
                raise

    def _generate_target_scores(
        self, X: np.ndarray, analysis_results: Dict[str, Any]
    ) -> np.ndarray:
        """
        íƒ€ê²Ÿ ì ìˆ˜ ìƒì„±

        Args:
            X: íŠ¹ì„± ë²¡í„°
            analysis_results: ë¶„ì„ ê²°ê³¼

        Returns:
            íƒ€ê²Ÿ ì ìˆ˜ ë°°ì—´
        """
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê³¼ê±° ë‹¹ì²¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ìƒì„±
            # í˜„ì¬ëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ íœ´ë¦¬ìŠ¤í‹± ì ìˆ˜ ìƒì„±

            n_samples = X.shape[0]

            # ê¸°ë³¸ ì ìˆ˜ (0.0 ~ 1.0)
            base_scores = np.random.rand(n_samples) * 0.5 + 0.25

            # ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¡°ì •
            if "unified_analysis" in analysis_results:
                unified_data = analysis_results["unified_analysis"]

                # ROI ì ìˆ˜ ë°˜ì˜
                if "roi_analysis" in unified_data:
                    roi_boost = np.random.rand(n_samples) * 0.2
                    base_scores += roi_boost

                # íŒ¨í„´ ì ìˆ˜ ë°˜ì˜
                if "pattern_analysis" in unified_data:
                    pattern_boost = np.random.rand(n_samples) * 0.15
                    base_scores += pattern_boost

                # íŠ¸ë Œë“œ ì ìˆ˜ ë°˜ì˜
                if "trend_analysis" in unified_data:
                    trend_boost = np.random.rand(n_samples) * 0.1
                    base_scores += trend_boost

            # ì ìˆ˜ ì •ê·œí™” (0.0 ~ 1.0)
            base_scores = np.clip(base_scores, 0.0, 1.0)

            return base_scores.astype(np.float32)

        except Exception as e:
            self.logger.error(f"âŒ íƒ€ê²Ÿ ì ìˆ˜ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜
            return np.random.rand(X.shape[0]).astype(np.float32)

    def train_lightgbm_model(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """
        LightGBM ëª¨ë¸ í•™ìŠµ

        Args:
            X: íŠ¹ì„± ë²¡í„°
            y: íƒ€ê²Ÿ ì ìˆ˜

        Returns:
            í•™ìŠµ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

        with self.performance_monitor.track(
            "train_lightgbm_model", track_gpu=self.config.use_gpu
        ):
            start_time = time.time()

            try:
                # ë°ì´í„° ë¶„í• 
                X_train, X_test, y_train, y_test = train_test_split(
                    X,
                    y,
                    test_size=1 - self.config.train_test_split_ratio,
                    random_state=42,
                    stratify=None,
                )

                # ê²€ì¦ ì„¸íŠ¸ ë¶„í• 
                X_train, X_val, y_train, y_val = train_test_split(
                    X_train,
                    y_train,
                    test_size=self.config.validation_split_ratio,
                    random_state=42,
                )

                self.logger.info(
                    f"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train={X_train.shape}, Val={X_val.shape}, Test={X_test.shape}"
                )

                # íŠ¹ì„± ì´ë¦„ ìƒì„±
                feature_names = [f"feature_{i}" for i in range(X.shape[1])]

                # GPU ë©”ëª¨ë¦¬ ìµœì í™”
                if self.config.use_gpu and self.cuda_optimizer:
                    self.cuda_optimizer.clear_cache()

                # ëª¨ë¸ í•™ìŠµ
                train_result = self.lightgbm_model.fit(
                    X_train,
                    y_train,
                    eval_set=[(X_val, y_val)],
                    feature_names=feature_names,
                    early_stopping_rounds=50,
                    num_boost_round=1000,
                )

                # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
                y_pred = self.lightgbm_model.predict(X_test)

                # í‰ê°€ ì§€í‘œ ê³„ì‚°
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)

                # íŠ¹ì„± ì¤‘ìš”ë„
                feature_importance = self.lightgbm_model.get_feature_importance()

                # 3ìë¦¬ ëª¨ë“œ í•™ìŠµ (í™œì„±í™”ëœ ê²½ìš°)
                digit_3_result = None
                if self.config.use_3digit_mode:
                    digit_3_result = self._train_3digit_mode(
                        X_train, y_train, X_val, y_val
                    )

                training_time = time.time() - start_time
                self.execution_stats["training_time"] = training_time

                # ê²°ê³¼ ì •ë¦¬
                training_results = {
                    "success": True,
                    "training_time": training_time,
                    "model_metadata": train_result,
                    "evaluation_metrics": {
                        "mse": float(mse),
                        "rmse": float(rmse),
                        "mae": float(mae),
                        "r2_score": float(r2),
                    },
                    "feature_importance": feature_importance,
                    "data_splits": {
                        "train_size": X_train.shape[0],
                        "val_size": X_val.shape[0],
                        "test_size": X_test.shape[0],
                        "feature_count": X.shape[1],
                    },
                    "digit_3_mode": digit_3_result,
                    "gpu_used": self.config.use_gpu,
                }

                self.logger.info(f"âœ… LightGBM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
                self.logger.info(
                    f"ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ: RMSE={rmse:.4f}, MAE={mae:.4f}, RÂ²={r2:.4f}"
                )
                self.logger.info(f"â±ï¸ í•™ìŠµ ì‹œê°„: {training_time:.2f}ì´ˆ")

                return training_results

            except Exception as e:
                self.execution_stats["error_count"] += 1
                self.logger.error(f"âŒ LightGBM ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "training_time": time.time() - start_time,
                }

    def _train_3digit_mode(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
    ) -> Dict[str, Any]:
        """
        3ìë¦¬ ëª¨ë“œ í•™ìŠµ

        Args:
            X_train: í›ˆë ¨ íŠ¹ì„±
            y_train: í›ˆë ¨ íƒ€ê²Ÿ
            X_val: ê²€ì¦ íŠ¹ì„±
            y_val: ê²€ì¦ íƒ€ê²Ÿ

        Returns:
            3ìë¦¬ ëª¨ë“œ í•™ìŠµ ê²°ê³¼
        """
        self.logger.info("ğŸ¯ 3ìë¦¬ ëª¨ë“œ í•™ìŠµ ì‹œì‘...")

        try:
            # 3ìë¦¬ ì¡°í•© ìƒì„± (C(45,3) = 14190ê°œ)
            from itertools import combinations

            # ëª¨ë“  3ìë¦¬ ì¡°í•© ìƒì„±
            all_combinations = list(combinations(range(1, 46), 3))
            n_combinations = len(all_combinations)

            self.logger.info(f"ğŸ”¢ 3ìë¦¬ ì¡°í•© ê°œìˆ˜: {n_combinations}")

            # 3ìë¦¬ íƒ€ê²Ÿ ìƒì„± (ë‹¤ì¤‘ ë¶„ë¥˜)
            y_3digit_train = np.random.randint(0, n_combinations, size=X_train.shape[0])
            y_3digit_val = np.random.randint(0, n_combinations, size=X_val.shape[0])

            # 3ìë¦¬ ëª¨ë“œ í•™ìŠµ
            digit_3_result = self.lightgbm_model.fit_3digit_mode(
                X_train,
                y_3digit_train,
                eval_set=[(X_val, y_3digit_val)],
                early_stopping_rounds=30,
                num_boost_round=500,
            )

            # 3ìë¦¬ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            top_combinations = self.lightgbm_model.predict_3digit_combinations(
                X_val[:10], top_k=20
            )

            self.logger.info(f"âœ… 3ìë¦¬ ëª¨ë“œ í•™ìŠµ ì™„ë£Œ")
            self.logger.info(f"ğŸ¯ ìƒìœ„ ì˜ˆì¸¡ ì¡°í•© ìˆ˜: {len(top_combinations)}")

            return {
                "success": True,
                "n_combinations": n_combinations,
                "training_result": digit_3_result,
                "sample_predictions": top_combinations[:5],  # ìƒìœ„ 5ê°œë§Œ ì €ì¥
            }

        except Exception as e:
            self.logger.error(f"âŒ 3ìë¦¬ ëª¨ë“œ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def predict_pattern_scores(self, feature_vectors: np.ndarray) -> np.ndarray:
        """
        íŒ¨í„´ ì ìˆ˜ ì˜ˆì¸¡

        Args:
            feature_vectors: íŠ¹ì„± ë²¡í„°

        Returns:
            ì˜ˆì¸¡ ì ìˆ˜ ë°°ì—´
        """
        self.logger.info("ğŸ”® íŒ¨í„´ ì ìˆ˜ ì˜ˆì¸¡ ì‹œì‘...")

        with self.performance_monitor.track(
            "predict_pattern_scores", track_gpu=self.config.use_gpu
        ):
            start_time = time.time()

            try:
                if not self.lightgbm_model.is_trained:
                    raise ValueError(
                        "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_lightgbm_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
                    )

                # ë°°ì¹˜ ì˜ˆì¸¡ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
                batch_size = self.config.batch_size
                n_samples = feature_vectors.shape[0]
                predictions = []

                for i in range(0, n_samples, batch_size):
                    batch_end = min(i + batch_size, n_samples)
                    batch_features = feature_vectors[i:batch_end]

                    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (í•„ìš”ì‹œ)
                    if self.config.use_gpu and self.cuda_optimizer:
                        self.cuda_optimizer.clear_cache()

                    # ë°°ì¹˜ ì˜ˆì¸¡
                    batch_predictions = self.lightgbm_model.predict(batch_features)
                    predictions.append(batch_predictions)

                # ê²°ê³¼ ê²°í•©
                all_predictions = np.concatenate(predictions, axis=0)

                prediction_time = time.time() - start_time
                self.execution_stats["prediction_time"] = prediction_time

                self.logger.info(
                    f"âœ… íŒ¨í„´ ì ìˆ˜ ì˜ˆì¸¡ ì™„ë£Œ: {all_predictions.shape} ({prediction_time:.2f}ì´ˆ)"
                )

                return all_predictions

            except Exception as e:
                self.execution_stats["error_count"] += 1
                self.logger.error(f"âŒ íŒ¨í„´ ì ìˆ˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                raise

    def save_prediction_results(self, predictions: Dict[str, Any]) -> str:
        """
        ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥

        Args:
            predictions: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        self.logger.info("ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹œì‘...")

        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # ë©”ì¸ ê²°ê³¼ íŒŒì¼
            result_file = self.output_dir / f"ml_predictions_{timestamp}.json"

            # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
            save_data = {
                "timestamp": timestamp,
                "config": asdict(self.config),
                "execution_stats": self.execution_stats,
                "predictions": predictions,
                "model_info": {
                    "model_type": "LightGBM",
                    "is_trained": self.lightgbm_model.is_trained,
                    "supports_3digit": self.lightgbm_model.supports_3digit_mode,
                    "feature_count": len(self.lightgbm_model.feature_names),
                },
            }

            # JSON íŒŒì¼ ì €ì¥
            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)

            # ëª¨ë¸ ì €ì¥
            model_file = self.model_save_dir / f"lightgbm_model_{timestamp}.joblib"
            model_saved = self.lightgbm_model.save(str(model_file))

            if model_saved:
                self.logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_file}")
                save_data["model_file"] = str(model_file)

            # ì˜ˆì¸¡ ì ìˆ˜ë§Œ ë³„ë„ ì €ì¥ (NumPy í˜•ì‹)
            if "pattern_scores" in predictions:
                scores_file = self.output_dir / f"pattern_scores_{timestamp}.npy"
                np.save(scores_file, predictions["pattern_scores"])
                self.logger.info(f"ğŸ’¾ íŒ¨í„´ ì ìˆ˜ ì €ì¥ ì™„ë£Œ: {scores_file}")

            self.logger.info(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")

            return str(result_file)

        except Exception as e:
            self.execution_stats["error_count"] += 1
            self.logger.error(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def run_full_ml_prediction(self) -> Dict[str, Any]:
        """
        ì „ì²´ ML ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Returns:
            ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("ğŸš€ ì „ì²´ ML ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        self.logger.info("=" * 80)

        # ì‹¤í–‰ ì‹œì‘ ì‹œê°„
        self.execution_stats["start_time"] = datetime.now()

        try:
            # 1. ë¶„ì„ ê²°ê³¼ ë¡œë“œ
            self.logger.info("ğŸ“Š Step 1: ë¶„ì„ ê²°ê³¼ ë¡œë“œ")
            analysis_results = self.load_analysis_results()

            # 2. í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            self.logger.info("ğŸ”„ Step 2: í•™ìŠµ ë°ì´í„° ì¤€ë¹„")
            X, y = self.prepare_training_data(analysis_results)

            # 3. ëª¨ë¸ í•™ìŠµ
            self.logger.info("ğŸš€ Step 3: LightGBM ëª¨ë¸ í•™ìŠµ")
            training_results = self.train_lightgbm_model(X, y)

            if not training_results["success"]:
                raise RuntimeError(
                    f"ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {training_results.get('error', 'Unknown error')}"
                )

            # 4. ì˜ˆì¸¡ ìˆ˜í–‰
            self.logger.info("ğŸ”® Step 4: íŒ¨í„´ ì ìˆ˜ ì˜ˆì¸¡")
            pattern_scores = self.predict_pattern_scores(X)

            # 5. 3ìë¦¬ ì˜ˆì¸¡ (í™œì„±í™”ëœ ê²½ìš°)
            digit_3_predictions = None
            if self.config.use_3digit_mode and self.lightgbm_model.supports_3digit_mode:
                self.logger.info("ğŸ¯ Step 5: 3ìë¦¬ ì¡°í•© ì˜ˆì¸¡")
                try:
                    digit_3_predictions = (
                        self.lightgbm_model.predict_3digit_combinations(
                            X[:100], top_k=self.config.top_k_predictions
                        )
                    )
                    self.logger.info(
                        f"âœ… 3ìë¦¬ ì˜ˆì¸¡ ì™„ë£Œ: {len(digit_3_predictions)}ê°œ ì¡°í•©"
                    )
                except Exception as e:
                    self.logger.warning(f"âš ï¸ 3ìë¦¬ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    self.execution_stats["warnings"].append(f"3ìë¦¬ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

            # 6. ê²°ê³¼ ì •ë¦¬
            predictions = {
                "pattern_scores": pattern_scores,
                "digit_3_predictions": digit_3_predictions,
                "training_results": training_results,
                "analysis_metadata": {
                    "input_files": analysis_results["source_files"],
                    "feature_vector_shape": analysis_results["feature_vectors"].shape,
                    "data_loading_time": analysis_results["load_time"],
                },
            }

            # 7. ê²°ê³¼ ì €ì¥
            self.logger.info("ğŸ’¾ Step 6: ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥")
            result_file = self.save_prediction_results(predictions)

            # ì‹¤í–‰ ì™„ë£Œ
            self.execution_stats["end_time"] = datetime.now()
            self.execution_stats["total_time"] = (
                self.execution_stats["end_time"] - self.execution_stats["start_time"]
            ).total_seconds()

            # ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘
            performance_stats = self.performance_monitor.get_performance_summary()

            # ìµœì¢… ê²°ê³¼
            final_results = {
                "success": True,
                "result_file": result_file,
                "execution_stats": self.execution_stats,
                "performance_stats": performance_stats,
                "predictions_summary": {
                    "pattern_scores_count": len(pattern_scores),
                    "pattern_scores_mean": float(np.mean(pattern_scores)),
                    "pattern_scores_std": float(np.std(pattern_scores)),
                    "digit_3_predictions_count": (
                        len(digit_3_predictions) if digit_3_predictions else 0
                    ),
                    "high_confidence_predictions": int(
                        np.sum(pattern_scores > self.config.confidence_threshold)
                    ),
                },
                "model_performance": training_results["evaluation_metrics"],
                "warnings": self.execution_stats["warnings"],
            }

            self.logger.info("=" * 80)
            self.logger.info("âœ… ML ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            self.logger.info(
                f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {self.execution_stats['total_time']:.2f}ì´ˆ"
            )
            self.logger.info(f"ğŸ¯ ì˜ˆì¸¡ ì ìˆ˜ ê°œìˆ˜: {len(pattern_scores)}")
            self.logger.info(f"ğŸ“ˆ í‰ê·  ì˜ˆì¸¡ ì ìˆ˜: {np.mean(pattern_scores):.4f}")
            self.logger.info(
                f"ğŸ² ê³ ì‹ ë¢°ë„ ì˜ˆì¸¡: {final_results['predictions_summary']['high_confidence_predictions']}ê°œ"
            )
            self.logger.info(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {result_file}")
            self.logger.info("=" * 80)

            return final_results

        except Exception as e:
            self.execution_stats["error_count"] += 1
            self.execution_stats["end_time"] = datetime.now()
            self.execution_stats["total_time"] = (
                self.execution_stats["end_time"] - self.execution_stats["start_time"]
            ).total_seconds()

            self.logger.error("=" * 80)
            self.logger.error(f"âŒ ML ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self.logger.error(
                f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {self.execution_stats['total_time']:.2f}ì´ˆ"
            )
            self.logger.error(f"ğŸš¨ ì˜¤ë¥˜ ê°œìˆ˜: {self.execution_stats['error_count']}")
            self.logger.error("=" * 80)

            return {
                "success": False,
                "error": str(e),
                "execution_stats": self.execution_stats,
                "warnings": self.execution_stats["warnings"],
            }


def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="DAEBAK AI ë¡œë˜ ì‹œìŠ¤í…œ - ML ì˜ˆì¸¡ ë‹¨ê³„ (Phase 2)"
    )

    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON í˜•ì‹)")

    parser.add_argument("--no-gpu", action="store_true", help="GPU ì‚¬ìš© ë¹„í™œì„±í™”")

    parser.add_argument("--no-3digit", action="store_true", help="3ìë¦¬ ëª¨ë“œ ë¹„í™œì„±í™”")

    parser.add_argument("--batch-size", type=int, default=1024, help="ë°°ì¹˜ í¬ê¸°")

    parser.add_argument(
        "--max-memory", type=int, default=2048, help="ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/result/ml_predictions",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬",
    )

    parser.add_argument("--verbose", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")

    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # 1. ì˜ì¡´ì„± ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
    configure_dependencies()

    # 2. ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    args = parse_arguments()
    cli_config = {}
    if args.config:
        with open(args.config, "r", encoding="utf-8") as f:
            cli_config = json.load(f)

    # ëª…ë ¹í–‰ ì¸ìˆ˜ ë°˜ì˜
    if args.no_gpu:
        cli_config["use_gpu"] = False
    if args.no_3digit:
        cli_config["use_3digit_mode"] = False
    if args.batch_size:
        cli_config["batch_size"] = args.batch_size
    if args.max_memory:
        cli_config["max_memory_usage_mb"] = args.max_memory
    if args.output_dir:
        cli_config["output_dir"] = args.output_dir

    # ë¡œê±° ì„¤ì •
    logger = get_logger(__name__)
    if args.verbose:
        logger.setLevel("DEBUG")

    try:
        # 3. ML ì˜ˆì¸¡ ì—”ì§„ ìƒì„± ë° ì‹¤í–‰
        engine = MLPredictionEngine(cli_config)
        final_results = engine.run_full_ml_prediction()

        # 4. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        if final_results["success"]:
            print(f"\nâœ… ML ì˜ˆì¸¡ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {final_results['result_file']}")
            print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {final_results['execution_stats']['total_time']:.2f}ì´ˆ")
            return 0
        else:
            print(f"\nâŒ ML ì˜ˆì¸¡ ì‹¤íŒ¨: {final_results['error']}")
            return 1

    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
