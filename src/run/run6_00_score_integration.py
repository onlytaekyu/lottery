"""
DAEBAK_AI ë¡œë˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ - 6ë‹¨ê³„: ì ìˆ˜ í†µí•© ì‹œìŠ¤í…œ
Enhanced Meta Weight Layer + ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ë¡œ ìµœì¢… ì ìˆ˜ í†µí•©
"""

import json
import time
import numpy as np
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
from collections import defaultdict
from dataclasses import dataclass, asdict

# 3. í”„ë¡œì íŠ¸ ë‚´ë¶€ (ë¦¬íŒ©í† ë§ëœ ì˜ì¡´ì„± ê´€ë¦¬)
from ..utils.dependency_injection import configure_dependencies, resolve
from ..utils.unified_logging import get_logger
from ..utils.unified_memory_manager import UnifiedMemoryManager
from ..utils.unified_performance_engine import AutoPerformanceMonitor
from ..utils.unified_config import Config
from ..pipeline.enhanced_meta_weight_layer import EnhancedMetaWeightLayer, MetaWeightConfig
from ..models.unified_model_manager import UnifiedModelManager
from ..utils.config_validator import ConfigValidator
from ..pipeline.model_performance_benchmark import ModelPerformanceBenchmark
from ..models.adaptive_weight_system import AdaptiveWeightSystem


@dataclass
class ScoreIntegrationConfig:
    """ì ìˆ˜ í†µí•© ì„¤ì •"""
    # ê°€ì¤‘ì¹˜ ì„¤ì •
    stage_weights: Dict[str, float] = None
    roi_weight: float = 0.3
    diversity_weight: float = 0.2
    performance_weight: float = 0.5
    
    # Meta Weight Layer ì„¤ì •
    meta_config: MetaWeightConfig = None
    
    # ì•™ìƒë¸” ì„¤ì •
    ensemble_size: int = 100
    top_k_candidates: int = 50
    confidence_threshold: float = 0.6
    
    def __post_init__(self):
        if self.stage_weights is None:
            self.stage_weights = {
                "run1_analysis": 0.25,      # íŒ¨í„´ ë¶„ì„
                "run2_predictions": 0.25,   # LightGBM 
                "run3_anomaly": 0.2,        # AutoEncoder
                "run4_trend": 0.2,          # TCN
                "run5_risk": 0.1            # RandomForest
            }
        
        if self.meta_config is None:
            self.meta_config = MetaWeightConfig(
                num_models=5,  # 5ë‹¨ê³„ ê²°ê³¼
                adaptation_rate=0.01,
                momentum=0.9,
                confidence_threshold=0.7,
                roi_weight=self.roi_weight,
                diversity_weight=self.diversity_weight,
                performance_weight=self.performance_weight
            )


class ScoreIntegrationEngine:
    """ì ìˆ˜ í†µí•© ì—”ì§„"""
    
    def __init__(self):
        """
        ì ìˆ˜ í†µí•© ì—”ì§„ ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©)
        """
        self.logger = get_logger(__name__)

        # --- ì˜ì¡´ì„± í•´ê²° ---
        self.config_manager: Config = resolve(Config)
        self.config = self.config_manager.get_config("main")
        self.paths = self.config_manager.get_paths()
        self.memory_manager: UnifiedMemoryManager = resolve(UnifiedMemoryManager)
        self.performance_monitor: AutoPerformanceMonitor = resolve(AutoPerformanceMonitor)
        self.validator: ConfigValidator = resolve(ConfigValidator)
        # --------------------
        
        # ì ìˆ˜ í†µí•© ì„¤ì •
        self.integration_config = ScoreIntegrationConfig()
        
        # Enhanced Meta Weight Layer ì´ˆê¸°í™”
        self.meta_weight_layer = EnhancedMetaWeightLayer(self.config)
        
        # í†µí•© ëª¨ë¸ ë§¤ë‹ˆì €
        self.model_manager = resolve(UnifiedModelManager)
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.result_dir = Path(self.paths.result_dir) / "score_integration"
        self.result_dir.mkdir(parents=True, exist_ok=True)
        
        # ìºì‹œ ë””ë ‰í† ë¦¬
        self.cache_dir = Path(self.paths.cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.adaptive_weight_system = AdaptiveWeightSystem(self.config)
        self.benchmark = ModelPerformanceBenchmark(self.config)
        
        self.logger.info("âœ… ì ìˆ˜ í†µí•© ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

    def load_all_stage_results(self) -> Dict[str, Any]:
        """
        ì´ì „ 5ë‹¨ê³„ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Returns:
            Dict[str, Any]: í†µí•©ëœ ëª¨ë“  ë‹¨ê³„ ê²°ê³¼
        """
        try:
            self.logger.info("ğŸ“Š ì´ì „ 5ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì‹œì‘...")
            
            with self.performance_monitor.track("load_all_stage_results"):
                results = {
                    "run1_analysis": {},
                    "run2_predictions": {},
                    "run3_anomaly": {},
                    "run4_trend": {},
                    "run5_risk": {},
                    "metadata": {}
                }
                
                # run1 ë¶„ì„ ê²°ê³¼ ë¡œë“œ
                analysis_dir = Path(self.paths.result_dir) / "analysis"
                if analysis_dir.exists():
                    for file_path in analysis_dir.glob("*.json"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                results["run1_analysis"][file_path.stem] = data
                        except Exception as e:
                            self.logger.warning(f"run1 íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
                
                # run2 ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ  
                predictions_dir = Path(self.paths.predictions_dir)
                if predictions_dir.exists():
                    for file_path in predictions_dir.glob("*.json"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                results["run2_predictions"][file_path.stem] = data
                        except Exception as e:
                            self.logger.warning(f"run2 íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
                
                # run3 ì´ìƒê°ì§€ ê²°ê³¼ ë¡œë“œ
                anomaly_dir = Path(self.paths.result_dir) / "anomaly_detection"
                if anomaly_dir.exists():
                    for file_path in anomaly_dir.glob("*.json"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                results["run3_anomaly"][file_path.stem] = data
                        except Exception as e:
                            self.logger.warning(f"run3 íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
                
                # run4 íŠ¸ë Œë“œ ë³´ì • ê²°ê³¼ ë¡œë“œ
                trend_dir = Path(self.paths.result_dir) / "trend_correction"
                if trend_dir.exists():
                    for file_path in trend_dir.glob("*.json"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                results["run4_trend"][file_path.stem] = data
                        except Exception as e:
                            self.logger.warning(f"run4 íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
                
                # run5 ë¦¬ìŠ¤í¬ í•„í„° ê²°ê³¼ ë¡œë“œ
                risk_dir = Path(self.paths.result_dir) / "risk_filter"
                if risk_dir.exists():
                    for file_path in risk_dir.glob("*.json"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                results["run5_risk"][file_path.stem] = data
                        except Exception as e:
                            self.logger.warning(f"run5 íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
                
                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                results["metadata"] = {
                    "load_timestamp": datetime.now().isoformat(),
                    "run1_files": len(results["run1_analysis"]),
                    "run2_files": len(results["run2_predictions"]),
                    "run3_files": len(results["run3_anomaly"]),
                    "run4_files": len(results["run4_trend"]),
                    "run5_files": len(results["run5_risk"]),
                    "total_files": sum([
                        len(results["run1_analysis"]),
                        len(results["run2_predictions"]),
                        len(results["run3_anomaly"]),
                        len(results["run4_trend"]),
                        len(results["run5_risk"])
                    ])
                }
            
            self.logger.info(f"âœ… ì „ì²´ ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: "
                           f"run1({len(results['run1_analysis'])}), "
                           f"run2({len(results['run2_predictions'])}), "
                           f"run3({len(results['run3_anomaly'])}), "
                           f"run4({len(results['run4_trend'])}), "
                           f"run5({len(results['run5_risk'])})")
            
            return results
            
        except Exception as e:
            self.logger.error(f"ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def integrate_stage_scores(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        5ë‹¨ê³„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            all_results: ëª¨ë“  ë‹¨ê³„ ê²°ê³¼
            
        Returns:
            Dict[str, Any]: í†µí•©ëœ ì ìˆ˜ ì •ë³´
        """
        try:
            self.logger.info("ğŸ”„ ë‹¨ê³„ë³„ ì ìˆ˜ í†µí•© ì‹œì‘...")
            
            with self.performance_monitor.track("integrate_stage_scores"):
                # 1. ê° ë‹¨ê³„ë³„ ì ìˆ˜ ì¶”ì¶œ
                stage_scores = self._extract_stage_scores(all_results)
                
                # 2. Meta Weight Layerë¥¼ ìœ„í•œ ëª¨ë¸ ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
                model_predictions = self._build_model_predictions_matrix(stage_scores)
                
                # 3. ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
                roi_weights = self._calculate_roi_weights(all_results)
                
                # 4. Enhanced Meta Weight Layerë¡œ ì•™ìƒë¸” ì˜ˆì¸¡
                ensemble_prediction, meta_metadata = self.meta_weight_layer.compute_ensemble_prediction(
                    model_predictions, 
                    historical_roi=roi_weights
                )
                
                # 5. ìµœì¢… í†µí•© ì ìˆ˜ ê³„ì‚°
                integrated_scores = self._compute_final_scores(
                    ensemble_prediction, stage_scores, meta_metadata
                )
                
                # 6. ë‹¤ì–‘ì„± ë° ì„±ëŠ¥ ê¸°ë°˜ ì¡°ì •
                adjusted_scores = self._apply_diversity_performance_adjustment(
                    integrated_scores, all_results
                )
                
                # 7. ìµœì¢… ìˆœìœ„í™” ë° í›„ë³´ ì¡°í•© ìƒì„±
                final_recommendations = self._generate_final_recommendations(
                    adjusted_scores, all_results
                )
                
                integration_result = {
                    "stage_scores": stage_scores,
                    "model_predictions": {k: v.tolist() for k, v in model_predictions.items()},
                    "roi_weights": roi_weights,
                    "ensemble_prediction": ensemble_prediction.tolist(),
                    "integrated_scores": integrated_scores,
                    "adjusted_scores": adjusted_scores,
                    "final_recommendations": final_recommendations,
                    "meta_metadata": meta_metadata,
                    "integration_config": asdict(self.integration_config)
                }
                
            self.logger.info("âœ… ë‹¨ê³„ë³„ ì ìˆ˜ í†µí•© ì™„ë£Œ")
            return integration_result
            
        except Exception as e:
            self.logger.error(f"ì ìˆ˜ í†µí•© ì‹¤íŒ¨: {e}")
            raise

    def _extract_stage_scores(self, all_results: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
        """ê° ë‹¨ê³„ë³„ ì ìˆ˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        stage_scores = {}
        
        # run1 ë¶„ì„ ì ìˆ˜ ì¶”ì¶œ
        stage_scores["run1_analysis"] = {}
        for name, data in all_results["run1_analysis"].items():
            if "unified_analysis" in name and "comprehensive_scores" in data:
                scores = data["comprehensive_scores"]
                for num in range(1, 46):
                    stage_scores["run1_analysis"][str(num)] = scores.get(str(num), 0.0)
                break
        
        # run2 ML ì˜ˆì¸¡ ì ìˆ˜ ì¶”ì¶œ
        stage_scores["run2_predictions"] = {}
        for name, data in all_results["run2_predictions"].items():
            if "ml_predictions" in name and "predictions" in data:
                predictions = data["predictions"]
                for num in range(1, 46):
                    stage_scores["run2_predictions"][str(num)] = predictions.get(str(num), 0.0)
                break
        
        # run3 ì´ìƒê°ì§€ ì ìˆ˜ ì¶”ì¶œ (ì´ìƒë„ê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        stage_scores["run3_anomaly"] = {}
        for name, data in all_results["run3_anomaly"].items():
            if "anomaly_detection" in name and "anomaly_scores" in data:
                anomaly_scores = data["anomaly_scores"]
                for num in range(1, 46):
                    anomaly_score = anomaly_scores.get(str(num), 0.5)
                    stage_scores["run3_anomaly"][str(num)] = 1.0 - anomaly_score  # ì—­ë³€í™˜
                break
        
        # run4 íŠ¸ë Œë“œ ë³´ì • ì ìˆ˜ ì¶”ì¶œ
        stage_scores["run4_trend"] = {}
        for name, data in all_results["run4_trend"].items():
            if "trend_correction_scores" in data:
                trend_scores = data["trend_correction_scores"]
                for num in range(1, 46):
                    stage_scores["run4_trend"][str(num)] = trend_scores.get(str(num), 0.0)
                break
        
        # run5 ë¦¬ìŠ¤í¬ í•„í„° ì ìˆ˜ ì¶”ì¶œ (í•„í„°ë§ í›„ ë‚¨ì€ ì¡°í•©ë“¤ì˜ ì ìˆ˜)
        stage_scores["run5_risk"] = {}
        for name, data in all_results["run5_risk"].items():
            if "risk_filtered_combinations" in data:
                # ë¦¬ìŠ¤í¬ í•„í„°ì—ì„œëŠ” ì¡°í•©ë³„ ì ìˆ˜ê°€ ìˆìœ¼ë¯€ë¡œ ë²ˆí˜¸ë³„ë¡œ ì§‘ê³„
                combinations = data["risk_filtered_combinations"]
                number_scores = defaultdict(list)
                
                for combo_data in combinations.values():
                    if "numbers" in combo_data and "confidence" in combo_data:
                        numbers = combo_data["numbers"]
                        confidence = combo_data["confidence"]
                        for num in numbers:
                            number_scores[num].append(confidence)
                
                # ë²ˆí˜¸ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
                for num in range(1, 46):
                    if num in number_scores:
                        stage_scores["run5_risk"][str(num)] = float(np.mean(number_scores[num]))
                    else:
                        stage_scores["run5_risk"][str(num)] = 0.0
                break
        
        # ëˆ„ë½ëœ ë‹¨ê³„ ê¸°ë³¸ê°’ ì„¤ì •
        for stage in ["run1_analysis", "run2_predictions", "run3_anomaly", "run4_trend", "run5_risk"]:
            if stage not in stage_scores or not stage_scores[stage]:
                stage_scores[stage] = {str(num): 0.0 for num in range(1, 46)}
        
        return stage_scores

    def _build_model_predictions_matrix(self, stage_scores: Dict[str, Dict[str, float]]) -> Dict[str, np.ndarray]:
        """Meta Weight Layerë¥¼ ìœ„í•œ ëª¨ë¸ ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        model_predictions = {}
        
        for stage_name, scores in stage_scores.items():
            # ë²ˆí˜¸ë³„ ì ìˆ˜ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            score_array = np.array([scores[str(num)] for num in range(1, 46)])
            
            # ì •ê·œí™” (0-1 ë²”ìœ„)
            if score_array.max() > 0:
                score_array = score_array / score_array.max()
            
            model_predictions[stage_name] = score_array
        
        return model_predictions

    def _calculate_roi_weights(self, all_results: Dict[str, Any]) -> Dict[str, List[float]]:
        """ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        roi_weights = {}
        
        # ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ê¸°ë°˜ ROI ì¶”ì •
        for stage in ["run1_analysis", "run2_predictions", "run3_anomaly", "run4_trend", "run5_risk"]:
            stage_data = all_results.get(stage, {})
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ì´ ìˆëŠ” ê²½ìš° í™œìš©
            performance_roi = []
            
            for name, data in stage_data.items():
                if "performance_summary" in data:
                    perf_summary = data["performance_summary"]
                    # ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ íš¨ìœ¨ì„± ê³„ì‚°
                    exec_time = perf_summary.get("execution_time_seconds", 1.0)
                    efficiency = 1.0 / (1.0 + exec_time / 60.0)  # ë¶„ ë‹¨ìœ„ë¡œ ì •ê·œí™”
                    performance_roi.append(efficiency)
                elif "execution_stats" in data:
                    exec_stats = data["execution_stats"]
                    total_time = exec_stats.get("total_time", 1.0)
                    efficiency = 1.0 / (1.0 + total_time / 60.0)
                    performance_roi.append(efficiency)
                elif "performance_metrics" in data:
                    # ë¶„ì„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™œìš©
                    perf_metrics = data["performance_metrics"]
                    if isinstance(perf_metrics, dict) and "execution_time" in perf_metrics:
                        exec_time = perf_metrics["execution_time"]
                        efficiency = 1.0 / (1.0 + exec_time / 60.0)
                        performance_roi.append(efficiency)
            
            # ê¸°ë³¸ ROI ê°’ ì„¤ì •
            if not performance_roi:
                performance_roi = [0.5, 0.6, 0.7, 0.8, 0.9]  # ê¸°ë³¸ ì„±ëŠ¥ ê³¡ì„ 
            
            roi_weights[stage] = performance_roi
        
        return roi_weights

    def _compute_final_scores(self, ensemble_prediction: np.ndarray, 
                            stage_scores: Dict[str, Dict[str, float]], 
                            meta_metadata: Dict[str, Any]) -> Dict[str, float]:
        """ìµœì¢… í†µí•© ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        final_scores = {}
        
        # Meta Weight Layerì—ì„œ ë‚˜ì˜¨ ì•™ìƒë¸” ì˜ˆì¸¡ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        for i in range(45):
            num = str(i + 1)
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ ì ìˆ˜
            ensemble_score = float(ensemble_prediction[i])
            
            # ë‹¨ê³„ë³„ ê°€ì¤‘ ì ìˆ˜ ì¶”ê°€
            weighted_stage_score = 0.0
            for stage_name, weight in self.integration_config.stage_weights.items():
                stage_score = stage_scores.get(stage_name, {}).get(num, 0.0)
                weighted_stage_score += stage_score * weight
            
            # ìµœì¢… ì ìˆ˜ = ì•™ìƒë¸” ì ìˆ˜ 70% + ê°€ì¤‘ ë‹¨ê³„ ì ìˆ˜ 30%
            final_score = ensemble_score * 0.7 + weighted_stage_score * 0.3
            
            final_scores[num] = float(final_score)
        
        return final_scores

    def _apply_diversity_performance_adjustment(self, integrated_scores: Dict[str, float], 
                                              all_results: Dict[str, Any]) -> Dict[str, float]:
        """ë‹¤ì–‘ì„± ë° ì„±ëŠ¥ ê¸°ë°˜ ì¡°ì •ì„ ì ìš©í•©ë‹ˆë‹¤."""
        adjusted_scores = integrated_scores.copy()
        
        # 1. ë‹¤ì–‘ì„± ë³´ì¥ ì¡°ì •
        # í™€ì§ ê· í˜• ì¡°ì •
        odd_numbers = [num for num in range(1, 46, 2)]
        even_numbers = [num for num in range(2, 46, 2)]
        
        odd_avg = np.mean([adjusted_scores[str(num)] for num in odd_numbers])
        even_avg = np.mean([adjusted_scores[str(num)] for num in even_numbers])
        
        # ë¶ˆê· í˜• ì‹œ ì¡°ì •
        if abs(odd_avg - even_avg) > 0.1:
            adjustment_factor = 0.05
            if odd_avg > even_avg:
                for num in even_numbers:
                    adjusted_scores[str(num)] += adjustment_factor
            else:
                for num in odd_numbers:
                    adjusted_scores[str(num)] += adjustment_factor
        
        # 2. êµ¬ê°„ë³„ ê· í˜• ì¡°ì •
        segments = [
            list(range(1, 10)),    # 1-9
            list(range(10, 19)),   # 10-18
            list(range(19, 28)),   # 19-27
            list(range(28, 37)),   # 28-36
            list(range(37, 46))    # 37-45
        ]
        
        segment_avgs = []
        for segment in segments:
            segment_avg = np.mean([adjusted_scores[str(num)] for num in segment])
            segment_avgs.append(segment_avg)
        
        # êµ¬ê°„ë³„ ê· í˜• ì¡°ì •
        overall_avg = np.mean(segment_avgs)
        for i, segment in enumerate(segments):
            if segment_avgs[i] < overall_avg * 0.8:  # ë„ˆë¬´ ë‚®ì€ êµ¬ê°„ ìƒí–¥ ì¡°ì •
                adjustment = (overall_avg * 0.8 - segment_avgs[i]) * 0.5
                for num in segment:
                    adjusted_scores[str(num)] += adjustment
        
        return adjusted_scores

    def _generate_final_recommendations(self, adjusted_scores: Dict[str, float], 
                                      all_results: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ì¶”ì²œ ì¡°í•©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # 1. ìƒìœ„ ì ìˆ˜ ë²ˆí˜¸ë“¤ ì„ ë³„
            sorted_numbers = sorted(adjusted_scores.items(), key=lambda x: x[1], reverse=True)
            top_numbers = [int(num) for num, score in sorted_numbers[:self.integration_config.top_k_candidates]]
            
            # 2. ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ì¡°í•© ìƒì„±
            recommendations = {
                "top_score_combinations": self._generate_top_score_combinations(top_numbers, adjusted_scores),
                "balanced_combinations": self._generate_balanced_combinations(adjusted_scores),
                "diversity_combinations": self._generate_diversity_combinations(adjusted_scores),
                "meta_weight_combinations": self._generate_meta_weight_combinations(adjusted_scores, all_results)
            }
            
            # 3. ê° ì „ëµë³„ ìµœê³  ì¡°í•© ì„ ì •
            final_recommendations = {}
            for strategy, combos in recommendations.items():
                if combos:
                    final_recommendations[strategy] = combos[:5]  # ìƒìœ„ 5ê°œ
            
            # 4. í†µí•© ìµœì¢… ì¶”ì²œ (ëª¨ë“  ì „ëµ ê³ ë ¤)
            all_combinations = []
            for strategy_combos in recommendations.values():
                all_combinations.extend(strategy_combos)
            
            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            unique_combinations = {}
            for combo in all_combinations:
                combo_key = tuple(sorted(combo["numbers"]))
                if combo_key not in unique_combinations or combo["total_score"] > unique_combinations[combo_key]["total_score"]:
                    unique_combinations[combo_key] = combo
            
            final_top_combinations = sorted(
                unique_combinations.values(), 
                key=lambda x: x["total_score"], 
                reverse=True
            )[:self.integration_config.ensemble_size]
            
            return {
                "strategy_recommendations": final_recommendations,
                "final_top_combinations": final_top_combinations,
                "recommendation_summary": {
                    "total_combinations_generated": len(all_combinations),
                    "unique_combinations": len(unique_combinations),
                    "final_count": len(final_top_combinations),
                    "avg_confidence": np.mean([combo["confidence"] for combo in final_top_combinations]),
                    "top_score": final_top_combinations[0]["total_score"] if final_top_combinations else 0.0
                }
            }
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _generate_top_score_combinations(self, top_numbers: List[int], scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """ìµœê³  ì ìˆ˜ ê¸°ë°˜ ì¡°í•© ìƒì„±"""
        from itertools import combinations
        
        combinations_list = []
        for combo in combinations(top_numbers[:20], 6):  # ìƒìœ„ 20ê°œ ì¤‘ 6ê°œ ì¡°í•©
            combo_list = list(combo)
            total_score = sum(scores[str(num)] for num in combo_list)
            avg_score = total_score / 6
            
            combinations_list.append({
                "numbers": combo_list,
                "total_score": total_score,
                "avg_score": avg_score,
                "confidence": min(avg_score, 1.0),
                "strategy": "top_score"
            })
        
        return sorted(combinations_list, key=lambda x: x["total_score"], reverse=True)[:20]

    def _generate_balanced_combinations(self, scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """ê· í˜•ì¡íŒ ì¡°í•© ìƒì„± (êµ¬ê°„ë³„ ê· í˜•)"""
        from itertools import combinations
        
        # êµ¬ê°„ë³„ ìƒìœ„ ë²ˆí˜¸ ì„ ì •
        segments = {
            "low": list(range(1, 10)),      # 1-9
            "mid_low": list(range(10, 19)), # 10-18  
            "mid": list(range(19, 28)),     # 19-27
            "mid_high": list(range(28, 37)), # 28-36
            "high": list(range(37, 46))     # 37-45
        }
        
        segment_tops = {}
        for segment_name, numbers in segments.items():
            segment_scores = [(num, scores[str(num)]) for num in numbers]
            segment_scores.sort(key=lambda x: x[1], reverse=True)
            segment_tops[segment_name] = [num for num, score in segment_scores[:4]]
        
        combinations_list = []
        
        # ê° êµ¬ê°„ì—ì„œ 1-2ê°œì”© ì„ íƒí•˜ì—¬ ì¡°í•© ìƒì„±
        for combo in combinations(
            segment_tops["low"][:2] + segment_tops["mid_low"][:2] + 
            segment_tops["mid"][:2] + segment_tops["mid_high"][:2] + 
            segment_tops["high"][:2], 6
        ):
            combo_list = list(combo)
            
            # êµ¬ê°„ë³„ ë¶„í¬ í™•ì¸
            segment_count = {name: 0 for name in segments}
            for num in combo_list:
                for segment_name, segment_nums in segments.items():
                    if num in segment_nums:
                        segment_count[segment_name] += 1
                        break
            
            # ê· í˜• ì ìˆ˜ ê³„ì‚° (ê° êµ¬ê°„ì— ìµœì†Œ 1ê°œì”© ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤)
            balance_bonus = 0.1 if all(count > 0 for count in segment_count.values()) else 0.0
            
            total_score = sum(scores[str(num)] for num in combo_list) + balance_bonus
            avg_score = total_score / 6
            
            combinations_list.append({
                "numbers": combo_list,
                "total_score": total_score,
                "avg_score": avg_score,
                "confidence": min(avg_score, 1.0),
                "strategy": "balanced",
                "segment_distribution": segment_count
            })
        
        return sorted(combinations_list, key=lambda x: x["total_score"], reverse=True)[:15]

    def _generate_diversity_combinations(self, scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """ë‹¤ì–‘ì„± ê¸°ë°˜ ì¡°í•© ìƒì„±"""
        from itertools import combinations
        
        # í™€ìˆ˜/ì§ìˆ˜ ë¶„ë¥˜
        odd_numbers = [(num, scores[str(num)]) for num in range(1, 46, 2)]
        even_numbers = [(num, scores[str(num)]) for num in range(2, 46, 2)]
        
        odd_numbers.sort(key=lambda x: x[1], reverse=True)
        even_numbers.sort(key=lambda x: x[1], reverse=True)
        
        combinations_list = []
        
        # í™€ì§ ê· í˜• ì¡°í•© (3:3 ë˜ëŠ” 4:2, 2:4)
        for odd_count in [2, 3, 4]:
            even_count = 6 - odd_count
            
            if even_count < 2 or even_count > 4:
                continue
                
            top_odds = [num for num, score in odd_numbers[:min(8, len(odd_numbers))]]
            top_evens = [num for num, score in even_numbers[:min(8, len(even_numbers))]]
            
            for odd_combo in combinations(top_odds, odd_count):
                for even_combo in combinations(top_evens, even_count):
                    combo_list = list(odd_combo) + list(even_combo)
                    combo_list.sort()
                    
                    # ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ ê³„ì‚°
                    diversity_bonus = 0.05 if abs(odd_count - even_count) <= 1 else 0.0
                    
                    total_score = sum(scores[str(num)] for num in combo_list) + diversity_bonus
                    avg_score = total_score / 6
                    
                    combinations_list.append({
                        "numbers": combo_list,
                        "total_score": total_score,
                        "avg_score": avg_score,
                        "confidence": min(avg_score, 1.0),
                        "strategy": "diversity",
                        "odd_count": odd_count,
                        "even_count": even_count
                    })
        
        return sorted(combinations_list, key=lambda x: x["total_score"], reverse=True)[:15]

    def _generate_meta_weight_combinations(self, scores: Dict[str, float], all_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Meta Weight Layer ê¸°ë°˜ ì¡°í•© ìƒì„±"""
        from itertools import combinations
        
        # Meta Weightì—ì„œ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ í™œìš©
        meta_weights = self.meta_weight_layer.get_weight_analysis().get("current_weights", {})
        
        combinations_list = []
        
        # ê° ë‹¨ê³„ë³„ ìƒìœ„ ë²ˆí˜¸ í™œìš©í•˜ì—¬ ì¡°í•© ìƒì„±
        stage_top_numbers = {}
        for stage_name in ["run1_analysis", "run2_predictions", "run3_anomaly", "run4_trend", "run5_risk"]:
            stage_scores = [(num, score) for num, score in scores.items()]
            stage_scores.sort(key=lambda x: x[1], reverse=True)
            stage_top_numbers[stage_name] = [int(num) for num, score in stage_scores[:10]]
        
        # Meta Weight ê¸°ë°˜ ë²ˆí˜¸ í’€ êµ¬ì„±
        weighted_numbers = set()
        for stage_name, numbers in stage_top_numbers.items():
            weight = meta_weights.get(stage_name, 0.2)
            # ê°€ì¤‘ì¹˜ê°€ ë†’ì€ ë‹¨ê³„ì—ì„œ ë” ë§ì€ ë²ˆí˜¸ ì„ íƒ
            count = max(2, int(weight * 20))
            weighted_numbers.update(numbers[:count])
        
        # ì¡°í•© ìƒì„±
        for combo in combinations(list(weighted_numbers)[:25], 6):
            combo_list = list(combo)
            
            # Meta Weight ë³´ë„ˆìŠ¤ ê³„ì‚°
            meta_bonus = 0.0
            for num in combo_list:
                for stage_name, numbers in stage_top_numbers.items():
                    if num in numbers[:5]:  # ìƒìœ„ 5ê°œì— ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤
                        weight = meta_weights.get(stage_name, 0.2)
                        meta_bonus += weight * 0.05
            
            total_score = sum(scores[str(num)] for num in combo_list) + meta_bonus
            avg_score = total_score / 6
            
            combinations_list.append({
                "numbers": combo_list,
                "total_score": total_score,
                "avg_score": avg_score,
                "confidence": min(avg_score, 1.0),
                "strategy": "meta_weight",
                "meta_bonus": meta_bonus
            })
        
        return sorted(combinations_list, key=lambda x: x["total_score"], reverse=True)[:15]

    def save_integration_results(self, integration_result: Dict[str, Any]) -> str:
        """í†µí•© ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = self.result_dir / f"score_integration_{timestamp}.json"
            
            # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
            save_data = {
                "timestamp": timestamp,
                "config": asdict(self.integration_config),
                "integration_result": integration_result,
                "system_info": {
                    "cuda_available": torch.cuda.is_available(),
                    "memory_manager_stats": self.memory_manager.get_stats(),
                }
            }
            
            # JSON íŒŒì¼ ì €ì¥
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"âœ… ì ìˆ˜ í†µí•© ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")
            return str(result_file)
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def run_full_score_integration(self) -> Dict[str, Any]:
        """ì „ì²´ ì ìˆ˜ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ì ìˆ˜ í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
        self.logger.info("=" * 80)
        
        start_time = time.time()
        
        try:
            # 1. ì´ì „ ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ
            self.logger.info("ğŸ“Š 1ë‹¨ê³„: ì´ì „ ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ")
            all_results = self.load_all_stage_results()
            
            # 2. ì ìˆ˜ í†µí•© ì‹¤í–‰
            self.logger.info("ğŸ”„ 2ë‹¨ê³„: ì ìˆ˜ í†µí•© ì‹¤í–‰")
            integration_result = self.integrate_stage_scores(all_results)
            
            # 3. ê²°ê³¼ ì €ì¥
            self.logger.info("ğŸ’¾ 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥")
            saved_path = self.save_integration_results(integration_result)
            
            # 4. ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘
            end_time = time.time()
            execution_time = end_time - start_time
            
            performance_summary = {
                "execution_time_seconds": execution_time,
                "performance_monitor": self.performance_monitor.get_performance_summary(),
                "memory_manager_stats": self.memory_manager.get_stats(),
            }
            
            # 5. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            final_result = {
                "integration_result": integration_result,
                "saved_path": saved_path,
                "performance_summary": performance_summary,
                "execution_timestamp": datetime.now().isoformat(),
                "system_config": {
                    "cuda_available": torch.cuda.is_available(),
                    "integration_config": asdict(self.integration_config)
                }
            }
            
            self.logger.info(f"âœ… ì ìˆ˜ í†µí•© ì‹œìŠ¤í…œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {execution_time:.2f}ì´ˆ)")
            return final_result
            
        except Exception as e:
            self.logger.error(f"ì ìˆ˜ í†µí•© ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # 1. ë¡œê±° ì´ˆê¸°í™”
    logger = get_logger(__name__)

    # 2. ì˜ì¡´ì„± ì„¤ì •
    configure_dependencies()

    logger.info("=" * 80)
    logger.info("ğŸš€ 6ë‹¨ê³„: ì ìˆ˜ í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
    logger.info("=" * 80)
    
    start_time = time.time()

    try:
        # ì ìˆ˜ í†µí•© ì—”ì§„ ìƒì„± (ì„¤ì • ì œê±°)
        engine = ScoreIntegrationEngine()
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        final_results = engine.run_full_score_integration()

        total_time = time.time() - start_time
        logger.info(f"âœ… ì ìˆ˜ í†µí•© ì™„ë£Œ! ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“ ìµœì¢… ê²°ê³¼ íŒŒì¼: {final_results.get('saved_path')}")
        
    except Exception as e:
        logger.error(f"âŒ ì ìˆ˜ í†µí•© ì‹¤íŒ¨: {e}", exc_info=True)
        return 1

    return 0


if __name__ == "__main__":
    main()
