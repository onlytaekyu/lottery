#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DAEBAK AI ë¡œë˜ ë°ì´í„° ë¶„ì„ ë° ìµœì í™”ëœ ì „ì²˜ë¦¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒˆë¡œ êµ¬í˜„ëœ ê³ ê¸‰ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í†µí•©í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤:
- Phase 1: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ í•µì‹¬ ìµœì í™” (Smart Feature Selection, Outlier Handling)
- Phase 2: ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (Feature Interactions, Meta Features)
- ëª¨ë¸ë³„ íŠ¹í™” ì „ì²˜ë¦¬ (LightGBM, AutoEncoder, TCN, RandomForest)
"""

import sys
import os
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ì„¤ì •
os.environ["PYTHONPATH"] = str(project_root)

from src.utils.unified_logging import get_logger
from src.utils.unified_config import get_config
from src.utils.memory_manager import get_memory_manager
from src.utils.unified_performance import performance_monitor
from src.utils.cache_paths import get_cache_dir

# ìƒˆë¡œ êµ¬í˜„ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ë“¤
from src.pipeline.preprocessing_manager import PreprocessingManager
from src.pipeline.advanced_preprocessing_pipeline import AdvancedPreprocessingPipeline
from src.pipeline.feature_engineering_pipeline import FeatureEngineeringPipeline
from src.pipeline.model_specific_preprocessors import create_model_preprocessor

# ê¸°ì¡´ ë¶„ì„ íŒŒì´í”„ë¼ì¸
from src.pipeline.optimized_data_analysis_pipeline import (
    run_optimized_data_analysis,
    clear_analysis_cache,
)

logger = get_logger(__name__)


class IntegratedDataAnalysisRunner:
    """í†µí•© ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì‹¤í–‰ê¸°"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """ì´ˆê¸°í™”"""
        self.config = get_config("main") if config is None else get_config("main")
        self.logger = get_logger(__name__)
        self.memory_manager = get_memory_manager()

        # ì „ì²˜ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.preprocessing_manager = PreprocessingManager(config)

        # ê²°ê³¼ ì €ì¥ ê²½ë¡œë“¤
        self.cache_dir = get_cache_dir()
        self.result_dir = Path("data/result/analysis")
        self.performance_dir = Path("data/result/performance_reports")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        for directory in [self.cache_dir, self.result_dir, self.performance_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        self.logger.info("í†µí•© ë°ì´í„° ë¶„ì„ ì‹¤í–‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def run_complete_analysis(
        self,
        clear_cache: bool = False,
        enable_preprocessing: bool = True,
        preprocessing_phase: str = "both",  # "phase1", "phase2", "both"
        target_models: List[str] = None,
    ) -> bool:
        """
        ì™„ì „í•œ ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì‹¤í–‰

        Args:
            clear_cache: ìºì‹œ ì‚­ì œ ì—¬ë¶€
            enable_preprocessing: ì „ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
            preprocessing_phase: ì „ì²˜ë¦¬ ë‹¨ê³„ ("phase1", "phase2", "both")
            target_models: ëŒ€ìƒ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        start_time = datetime.now()
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ DAEBAK AI í†µí•© ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì‹œì‘")
        self.logger.info("=" * 80)

        if target_models is None:
            target_models = ["lightgbm", "autoencoder", "tcn", "random_forest"]

        try:
            # 1. ìºì‹œ ì •ë¦¬ (ì„ íƒì )
            if clear_cache:
                self.logger.info("ğŸ§¹ ìºì‹œ ì •ë¦¬ ì¤‘...")
                clear_analysis_cache()

            # 2. ê¸°ë³¸ ë°ì´í„° ë¶„ì„ ì‹¤í–‰
            self.logger.info("ğŸ“Š ê¸°ë³¸ ë°ì´í„° ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            basic_success = run_optimized_data_analysis()

            if not basic_success:
                self.logger.error("ê¸°ë³¸ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨")
                return False

            # 3. ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤í–‰ (ì„ íƒì )
            if enable_preprocessing:
                preprocessing_success = self._run_advanced_preprocessing(
                    preprocessing_phase, target_models
                )

                if not preprocessing_success:
                    self.logger.error("ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
                    return False

            # 4. ê²°ê³¼ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±
            validation_success = self._validate_and_report_results()

            if not validation_success:
                self.logger.warning("ê²°ê³¼ ê²€ì¦ì—ì„œ ì¼ë¶€ ë¬¸ì œ ë°œê²¬")

            # 5. ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            total_time = (datetime.now() - start_time).total_seconds()
            self._print_performance_summary(total_time)

            self.logger.info("=" * 80)
            self.logger.info("âœ… í†µí•© ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì™„ë£Œ")
            self.logger.info("=" * 80)

            return True

        except Exception as e:
            self.logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def _run_advanced_preprocessing(self, phase: str, target_models: List[str]) -> bool:
        """ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤í–‰"""
        self.logger.info(f"ğŸ”§ ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤í–‰ ì¤‘... (Phase: {phase})")

        try:
            # ê¸°ë³¸ íŠ¹ì„± ë²¡í„° ë¡œë“œ
            feature_vector_path = self.cache_dir / "feature_vector_full.npy"
            feature_names_path = self.cache_dir / "feature_vector_full.names.json"

            if not feature_vector_path.exists():
                self.logger.error(f"íŠ¹ì„± ë²¡í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {feature_vector_path}")
                return False

            # ë°ì´í„° ë¡œë“œ
            X = np.load(feature_vector_path)

            import json

            if feature_names_path.exists():
                with open(feature_names_path, "r", encoding="utf-8") as f:
                    feature_names = json.load(f)
            else:
                feature_names = [f"feature_{i}" for i in range(X.shape[1])]

            self.logger.info(
                f"ì›ë³¸ ë°ì´í„° ë¡œë“œ: {X.shape}, íŠ¹ì„±ëª…: {len(feature_names)}ê°œ"
            )

            # ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ë¶„ì„
            recommendations = (
                self.preprocessing_manager.get_preprocessing_recommendations(
                    X, feature_names
                )
            )
            self._save_preprocessing_recommendations(recommendations)

            # ëª¨ë¸ë³„ ì „ì²˜ë¦¬ ì‹¤í–‰
            preprocessing_results = {}

            for model_type in target_models:
                self.logger.info(f"ğŸ“‹ {model_type} ëª¨ë¸ ì „ì²˜ë¦¬ ì¤‘...")

                try:
                    result = self.preprocessing_manager.preprocess_for_model(
                        X=X,
                        feature_names=feature_names,
                        model_type=model_type,
                        y=None,  # ë¹„ì§€ë„ í•™ìŠµ
                        phase=phase,
                        use_cache=True,
                    )

                    preprocessing_results[model_type] = result

                    # ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥
                    self._save_model_preprocessing_result(model_type, result)

                    self.logger.info(
                        f"âœ“ {model_type}: {X.shape} â†’ {result.X_processed.shape} "
                        f"({result.processing_time:.2f}ì´ˆ)"
                    )

                except Exception as e:
                    self.logger.error(f"âŒ {model_type} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue

            # ì „ì²˜ë¦¬ ê²°ê³¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
            self._generate_preprocessing_report(preprocessing_results, phase)

            self.logger.info(
                f"ğŸ¯ ê³ ê¸‰ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(preprocessing_results)}ê°œ ëª¨ë¸"
            )
            return len(preprocessing_results) > 0

        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _save_model_preprocessing_result(self, model_type: str, result) -> None:
        """ëª¨ë¸ë³„ ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥"""
        try:
            # ì „ì²˜ë¦¬ëœ íŠ¹ì„± ë²¡í„° ì €ì¥
            model_cache_dir = self.cache_dir / "preprocessed" / model_type
            model_cache_dir.mkdir(parents=True, exist_ok=True)

            # íŠ¹ì„± ë²¡í„° ì €ì¥
            vector_path = model_cache_dir / "feature_vector_preprocessed.npy"
            np.save(vector_path, result.X_processed)

            # íŠ¹ì„± ì´ë¦„ ì €ì¥
            names_path = model_cache_dir / "feature_names_preprocessed.json"
            import json

            with open(names_path, "w", encoding="utf-8") as f:
                json.dump(result.feature_names, f, ensure_ascii=False, indent=2)

            # ì „ì²˜ë¦¬ í†µê³„ ì €ì¥
            stats_path = model_cache_dir / "preprocessing_stats.json"
            with open(stats_path, "w", encoding="utf-8") as f:
                json.dump(result.preprocessing_stats, f, ensure_ascii=False, indent=2)

            self.logger.info(f"ğŸ“ {model_type} ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            self.logger.warning(f"ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({model_type}): {e}")

    def _save_preprocessing_recommendations(
        self, recommendations: Dict[str, Any]
    ) -> None:
        """ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ì €ì¥"""
        try:
            recommendations_path = (
                self.result_dir / "preprocessing_recommendations.json"
            )

            import json

            with open(recommendations_path, "w", encoding="utf-8") as f:
                json.dump(recommendations, f, ensure_ascii=False, indent=2)

            self.logger.info(f"ğŸ“‹ ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ì €ì¥: {recommendations_path}")

        except Exception as e:
            self.logger.warning(f"ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _generate_preprocessing_report(
        self, results: Dict[str, Any], phase: str
    ) -> None:
        """ì „ì²˜ë¦¬ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            report = {
                "timestamp": datetime.now().isoformat(),
                "phase": phase,
                "total_models": len(results),
                "successful_models": len(results),
                "models": {},
                "summary": {
                    "average_processing_time": 0.0,
                    "average_feature_reduction": 0.0,
                    "total_cache_hits": self.preprocessing_manager.performance_stats[
                        "cache_hits"
                    ],
                    "total_processed": self.preprocessing_manager.performance_stats[
                        "total_processed"
                    ],
                },
            }

            processing_times = []
            feature_reductions = []

            for model_type, result in results.items():
                model_report = {
                    "original_shape": result.preprocessing_stats.get(
                        "original_shape", [0, 0]
                    ),
                    "final_shape": result.X_processed.shape,
                    "processing_time": result.processing_time,
                    "feature_reduction_ratio": result.preprocessing_stats.get(
                        "total_feature_reduction", 0.0
                    ),
                    "cache_key": result.cache_key,
                    "feature_count": len(result.feature_names),
                }

                report["models"][model_type] = model_report
                processing_times.append(result.processing_time)

                reduction_ratio = result.preprocessing_stats.get(
                    "total_feature_reduction", 0.0
                )
                feature_reductions.append(reduction_ratio)

            # í‰ê·  í†µê³„ ê³„ì‚°
            if processing_times:
                report["summary"]["average_processing_time"] = np.mean(processing_times)
            if feature_reductions:
                report["summary"]["average_feature_reduction"] = np.mean(
                    feature_reductions
                )

            # ë¦¬í¬íŠ¸ ì €ì¥
            report_path = (
                self.performance_dir
                / f"preprocessing_report_{phase}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )

            import json

            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            self.logger.info(f"ğŸ“Š ì „ì²˜ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±: {report_path}")

        except Exception as e:
            self.logger.warning(f"ì „ì²˜ë¦¬ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

    def _validate_and_report_results(self) -> bool:
        """ê²°ê³¼ ê²€ì¦ ë° ë¦¬í¬íŠ¸"""
        self.logger.info("ğŸ” ê²°ê³¼ ê²€ì¦ ì¤‘...")

        validation_results = {
            "basic_analysis": False,
            "preprocessing_results": {},
            "file_checks": {},
        }

        # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ í™•ì¸
        basic_files = [
            "data/cache/feature_vector_full.npy",
            "data/cache/feature_vector_full.names.json",
            "data/result/analysis/optimized_analysis_result.json",
        ]

        for file_path in basic_files:
            exists = os.path.exists(file_path)
            validation_results["file_checks"][file_path] = {
                "exists": exists,
                "size": os.path.getsize(file_path) if exists else 0,
            }

        validation_results["basic_analysis"] = all(
            result["exists"] for result in validation_results["file_checks"].values()
        )

        # ì „ì²˜ë¦¬ ê²°ê³¼ íŒŒì¼ í™•ì¸
        preprocessed_dir = self.cache_dir / "preprocessed"
        if preprocessed_dir.exists():
            for model_dir in preprocessed_dir.iterdir():
                if model_dir.is_dir():
                    model_type = model_dir.name
                    model_files = [
                        model_dir / "feature_vector_preprocessed.npy",
                        model_dir / "feature_names_preprocessed.json",
                        model_dir / "preprocessing_stats.json",
                    ]

                    model_validation = {
                        "files_exist": all(f.exists() for f in model_files),
                        "file_sizes": {
                            f.name: f.stat().st_size if f.exists() else 0
                            for f in model_files
                        },
                    }

                    validation_results["preprocessing_results"][
                        model_type
                    ] = model_validation

        # ê²€ì¦ ê²°ê³¼ ì €ì¥
        validation_path = self.result_dir / "validation_results.json"
        import json

        with open(validation_path, "w", encoding="utf-8") as f:
            json.dump(validation_results, f, ensure_ascii=False, indent=2)

        # ê²°ê³¼ ì¶œë ¥
        self.logger.info("ğŸ“‹ ê²€ì¦ ê²°ê³¼:")
        self.logger.info(
            f"  ê¸°ë³¸ ë¶„ì„: {'âœ“' if validation_results['basic_analysis'] else 'âœ—'}"
        )

        for model_type, result in validation_results["preprocessing_results"].items():
            status = "âœ“" if result["files_exist"] else "âœ—"
            self.logger.info(f"  {model_type} ì „ì²˜ë¦¬: {status}")

        return validation_results["basic_analysis"]

    def _print_performance_summary(self, total_time: float) -> None:
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        self.logger.info("ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½:")
        self.logger.info(f"  ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")

        # ì „ì²˜ë¦¬ ë§¤ë‹ˆì € í†µê³„
        stats = self.preprocessing_manager.performance_stats
        self.logger.info(f"  ì „ì²˜ë¦¬ í†µê³„:")
        self.logger.info(f"    - ì´ ì²˜ë¦¬ ê±´ìˆ˜: {stats['total_processed']}")
        self.logger.info(f"    - ìºì‹œ íˆíŠ¸: {stats['cache_hits']}")

        if stats["processing_times"]:
            avg_time = np.mean(stats["processing_times"])
            self.logger.info(f"    - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")

        if stats["feature_reduction_ratios"]:
            avg_reduction = np.mean(stats["feature_reduction_ratios"])
            self.logger.info(f"    - í‰ê·  íŠ¹ì„± ê°ì†Œìœ¨: {avg_reduction:.2%}")

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_info = self.memory_manager.get_memory_info()
        self.logger.info(
            f"  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.get('current_usage', 0):.2f}MB"
        )


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("=" * 80)
    logger.info("ğŸš€ DAEBAK AI í†µí•© ë°ì´í„° ë¶„ì„ ë° ìµœì í™”ëœ ì „ì²˜ë¦¬ ì‹œì‘")
    logger.info("=" * 80)

    try:
        # í†µí•© ì‹¤í–‰ê¸° ì´ˆê¸°í™”
        runner = IntegratedDataAnalysisRunner()

        # ì‹¤í–‰ ì˜µì…˜ ì„¤ì •
        execution_options = {
            "clear_cache": False,  # Trueë¡œ ì„¤ì •í•˜ë©´ ìºì‹œ ì‚­ì œ í›„ ì‹¤í–‰
            "enable_preprocessing": True,  # ê³ ê¸‰ ì „ì²˜ë¦¬ í™œì„±í™”
            "preprocessing_phase": "both",  # "phase1", "phase2", "both"
            "target_models": ["lightgbm", "autoencoder", "tcn", "random_forest"],
        }

        logger.info("âš™ï¸ ì‹¤í–‰ ì˜µì…˜:")
        for key, value in execution_options.items():
            logger.info(f"  {key}: {value}")

        # í†µí•© ë¶„ì„ ì‹¤í–‰
        success = runner.run_complete_analysis(**execution_options)

        if success:
            logger.info("=" * 80)
            logger.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("=" * 80)

            logger.info("ğŸ“ ìƒì„±ëœ ì£¼ìš” íŒŒì¼ë“¤:")

            # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
            basic_files = [
                "data/cache/feature_vector_full.npy",
                "data/cache/feature_vector_full.names.json",
                "data/result/analysis/optimized_analysis_result.json",
            ]

            for file_path in basic_files:
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path)
                    logger.info(f"  âœ“ {file_path} ({file_size:,} bytes)")
                else:
                    logger.warning(f"  âœ— {file_path} (íŒŒì¼ ì—†ìŒ)")

            # ì „ì²˜ë¦¬ ê²°ê³¼ (ê° ëª¨ë¸ë³„)
            preprocessed_dir = Path("data/cache/preprocessed")
            if preprocessed_dir.exists():
                logger.info("  ğŸ“‹ ëª¨ë¸ë³„ ì „ì²˜ë¦¬ ê²°ê³¼:")
                for model_dir in preprocessed_dir.iterdir():
                    if model_dir.is_dir():
                        model_type = model_dir.name
                        vector_file = model_dir / "feature_vector_preprocessed.npy"
                        if vector_file.exists():
                            vector_shape = np.load(vector_file).shape
                            logger.info(f"    âœ“ {model_type}: {vector_shape}")

            return True
        else:
            logger.error("âŒ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return False

    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
