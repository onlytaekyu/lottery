#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DAEBAK AI ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ML í•™ìŠµì„ ìœ„í•œ ì™„ì „í•œ ë°ì´í„° ì¤€ë¹„ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤:
- Phase 1: ë°ì´í„° ë¶„ì„ (íšŒì°¨ë³„ êµ¬ì¡°/í†µê³„/íŠ¸ë Œë“œ íŠ¹ì„± ì¶”ì¶œ)
- Phase 2: ë²¡í„°í™” (150~200ì°¨ì› ìµœì  íŠ¹ì„± ë²¡í„° ìƒì„±)
- Phase 3: Negative ìƒ˜í”Œë§ (ML í•™ìŠµìš© ë¹„ë‹¹ì²¨ ì¡°í•© ìƒì„±)

3ë‹¨ê³„ë¥¼ ì—°ì†ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
"""

import sys
import os
import numpy as np
import pandas as pd
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any, Set
import time
import gc

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ì„¤ì •
os.environ["PYTHONPATH"] = str(project_root)

# í•µì‹¬ ìœ í‹¸ë¦¬í‹°ë“¤
from src.utils.unified_logging import get_logger
from src.utils.unified_config import get_config
from src.utils.memory_manager import get_memory_manager
from src.utils.unified_performance import performance_monitor
from src.utils.cache_paths import get_cache_dir
from src.utils.data_loader import load_draw_history

# ë¶„ì„ ê´€ë ¨ ëª¨ë“ˆë“¤ (ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ê²ƒë§Œ)
from src.analysis.enhanced_pattern_vectorizer import EnhancedPatternVectorizer
from src.analysis.negative_sample_generator import NegativeSampleGenerator

# íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ìë“¤
from src.pipeline.unified_preprocessing_pipeline import UnifiedPreprocessingPipeline

# ì„±ëŠ¥ ìµœì í™” ë„êµ¬
from src.utils.performance_optimizer import launch_max_performance

# ê³µìœ  íƒ€ì…ë“¤
from src.shared.types import LotteryNumber

logger = get_logger(__name__)


class DataPreparationPipeline:
    """ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """ì´ˆê¸°í™”"""
        self.config = get_config("main") if config is None else config
        self.logger = get_logger(__name__)
        self.memory_manager = get_memory_manager()

        # ê²°ê³¼ ì €ì¥ ê²½ë¡œë“¤
        self.cache_dir = get_cache_dir()
        self.result_dir = Path("data/result/analysis")
        self.performance_dir = Path("data/result/performance_reports")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        for directory in [self.cache_dir, self.result_dir, self.performance_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        # ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™” (ì§€ì—° ì´ˆê¸°í™”)
        self._vectorizer = None
        self._negative_generator = None

        # ì‹¤í–‰ ì˜µì…˜
        self.execution_options = {
            "enable_caching": True,
            "parallel_processing": True,
            "chunk_size": 10000,
            "memory_limit_ratio": 0.8,
            "vector_dimensions": [150, 200],
            "negative_sample_ratio": 3.0,
            "max_memory_usage_mb": 1024,  # 1GB ì œí•œ
            "performance_monitoring": True,
        }

        self.preproc_manager = UnifiedPreprocessingPipeline(self.config)

        self.logger.info("ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def execute_full_pipeline(
        self,
        clear_cache: bool = False,
        steps: List[str] = None,
        debug: bool = False,
        verbose: bool = False,
    ) -> Dict[str, Any]:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            clear_cache: ìºì‹œ ì‚­ì œ ì—¬ë¶€
            steps: ì‹¤í–‰í•  ë‹¨ê³„ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ëª¨ë“  ë‹¨ê³„)
            debug: ë””ë²„ê·¸ ëª¨ë“œ
            verbose: ìƒì„¸ ë¡œê¹…

        Returns:
            Dict[str, Any]: ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
        """
        start_time = time.time()

        if steps is None:
            steps = ["analysis", "vectorization", "negative_sampling"]

        # ë¡œê¹… ë ˆë²¨ ì„¤ì •
        if verbose:
            self.logger.setLevel("DEBUG")

        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ DAEBAK AI ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        self.logger.info(f"ğŸ“‹ ì‹¤í–‰ ë‹¨ê³„: {', '.join(steps)}")
        self.logger.info(
            f"ğŸ’¾ ë©”ëª¨ë¦¬ ì œí•œ: {self.execution_options['max_memory_usage_mb']}MB"
        )
        self.logger.info(
            f"ğŸ¯ ë²¡í„° ì°¨ì› ëª©í‘œ: {self.execution_options['vector_dimensions']}"
        )
        self.logger.info("=" * 80)

        # ì‹¤í–‰ ê²°ê³¼ ì¶”ì 
        pipeline_results = {
            "start_time": datetime.now().isoformat(),
            "steps_executed": [],
            "steps_failed": [],
            "performance_metrics": {},
            "output_files": {},
            "warnings": [],
        }

        try:
            # ìºì‹œ ì •ë¦¬ (ì„ íƒì )
            if clear_cache:
                self.logger.info("ğŸ§¹ ìºì‹œ ì •ë¦¬ ì¤‘...")
                self._clear_pipeline_cache()

            # 1. ë°ì´í„° ë¶„ì„ ë‹¨ê³„
            if "analysis" in steps:
                self.logger.info("ğŸ“Š Phase 1: ë°ì´í„° ë¶„ì„ ì‹¤í–‰ ì¤‘...")
                analysis_result = self.run_data_analysis()

                if analysis_result["success"]:
                    pipeline_results["steps_executed"].append("analysis")
                    pipeline_results["performance_metrics"]["analysis"] = (
                        analysis_result["metrics"]
                    )
                    pipeline_results["output_files"].update(
                        analysis_result["output_files"]
                    )
                    self.logger.info("âœ… ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
                else:
                    pipeline_results["steps_failed"].append("analysis")
                    self.logger.error("âŒ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨")
                    if not debug:
                        return pipeline_results

            # 2. ë²¡í„°í™” ë‹¨ê³„
            if "vectorization" in steps:
                self.logger.info("ğŸ”¢ Phase 2: ë²¡í„°í™” ì‹¤í–‰ ì¤‘...")

                # ë¶„ì„ ê²°ê³¼ê°€ í•„ìš”í•œ ê²½ìš° ë¡œë“œ
                if "analysis" not in steps:
                    analysis_result = self._load_analysis_result()

                vectorization_result = self.run_vectorization(analysis_result)

                if vectorization_result["success"]:
                    pipeline_results["steps_executed"].append("vectorization")
                    pipeline_results["performance_metrics"]["vectorization"] = (
                        vectorization_result["metrics"]
                    )
                    pipeline_results["output_files"].update(
                        vectorization_result["output_files"]
                    )
                    self.logger.info("âœ… ë²¡í„°í™” ì™„ë£Œ")
                else:
                    pipeline_results["steps_failed"].append("vectorization")
                    self.logger.error("âŒ ë²¡í„°í™” ì‹¤íŒ¨")
                    if not debug:
                        return pipeline_results

            # 3. Negative ìƒ˜í”Œë§ ë‹¨ê³„
            if "negative_sampling" in steps:
                self.logger.info("ğŸ¯ Phase 3: Negative ìƒ˜í”Œë§ ì‹¤í–‰ ì¤‘...")

                # ë²¡í„°í™” ê²°ê³¼ê°€ í•„ìš”í•œ ê²½ìš° ë¡œë“œ
                if "vectorization" not in steps:
                    vectorization_result = self._load_vectorization_result()

                negative_sampling_result = self.run_negative_sampling(
                    vectorization_result
                )

                if negative_sampling_result["success"]:
                    pipeline_results["steps_executed"].append("negative_sampling")
                    pipeline_results["performance_metrics"]["negative_sampling"] = (
                        negative_sampling_result["metrics"]
                    )
                    pipeline_results["output_files"].update(
                        negative_sampling_result["output_files"]
                    )
                    self.logger.info("âœ… Negative ìƒ˜í”Œë§ ì™„ë£Œ")
                else:
                    pipeline_results["steps_failed"].append("negative_sampling")
                    self.logger.error("âŒ Negative ìƒ˜í”Œë§ ì‹¤íŒ¨")
                    if not debug:
                        return pipeline_results

            # 4. ê²°ê³¼ ê²€ì¦ ë° ì €ì¥
            validation_result = self.validate_and_save_results(pipeline_results)
            pipeline_results["validation"] = validation_result

            # 5. ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            total_time = time.time() - start_time
            pipeline_results["total_execution_time"] = total_time
            pipeline_results["end_time"] = datetime.now().isoformat()

            self._print_performance_summary(pipeline_results)

            # 6. ì¢…í•© ë³´ê³ ì„œ ì €ì¥
            self._save_pipeline_report(pipeline_results)

            self.logger.info("=" * 80)
            self.logger.info("âœ… ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            self.logger.info("=" * 80)

            return pipeline_results

        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            pipeline_results["error"] = str(e)
            pipeline_results["end_time"] = datetime.now().isoformat()
            return pipeline_results
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()

    def run_data_analysis(self) -> Dict[str, Any]:
        """ë°ì´í„° ë¶„ì„ ë‹¨ê³„ (ê¸°ì¡´ ì½”ë“œ í™œìš©)"""
        start_time = time.time()

        try:
            # ê¸°ì¡´ ìµœì í™”ëœ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í™œìš©
            success = run_optimized_data_analysis()

            if not success:
                return {
                    "success": False,
                    "error": "ê¸°ì¡´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨",
                    "metrics": {},
                    "output_files": {},
                }

            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸
            output_files = self._check_analysis_output_files()

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            execution_time = time.time() - start_time
            metrics = {
                "execution_time": execution_time,
                "memory_usage": self.memory_manager.get_memory_usage(),
                "output_files_count": len(output_files),
            }

            self.logger.info(
                f"ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {execution_time:.2f}ì´ˆ, {len(output_files)}ê°œ íŒŒì¼ ìƒì„±"
            )

            return {"success": True, "metrics": metrics, "output_files": output_files}

        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "metrics": {},
                "output_files": {},
            }

    def run_vectorization(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë²¡í„°í™” ë‹¨ê³„ (150~200ì°¨ì›)"""
        start_time = time.time()

        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            memory_usage = self.memory_manager.get_memory_usage()
            if memory_usage > 0.8:
                self.logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {memory_usage:.1%}")
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()

            # ë²¡í„°í™”ê¸° ì´ˆê¸°í™”
            if self._vectorizer is None:
                self._vectorizer = EnhancedPatternVectorizer(self.config)

            # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
            analysis_data = self._load_unified_analysis()

            if not analysis_data:
                self.logger.error("ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {
                    "success": False,
                    "error": "ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "metrics": {},
                    "output_files": {},
                }

            self.logger.info(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(analysis_data)} í•­ëª©")

            # ë²¡í„°í™” ì‹¤í–‰
            feature_vector = self._vectorizer.vectorize_full_analysis_enhanced(
                analysis_data
            )

            # ë²¡í„° ê²€ì¦
            if feature_vector is None or len(feature_vector) == 0:
                self.logger.error("ë²¡í„°í™” ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return {
                    "success": False,
                    "error": "ë²¡í„°í™” ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤",
                    "metrics": {},
                    "output_files": {},
                }

            feature_names = self._vectorizer.get_feature_names()

            # ì°¨ì› ê²€ì¦ (150~200 ë²”ìœ„)
            vector_dim = len(feature_vector)
            target_range = self.execution_options["vector_dimensions"]

            if not (target_range[0] <= vector_dim <= target_range[1]):
                self.logger.warning(
                    f"ë²¡í„° ì°¨ì› {vector_dim}ì´ ëª©í‘œ ë²”ìœ„ {target_range} ë°–ì…ë‹ˆë‹¤"
                )

            # ë²¡í„° í’ˆì§ˆ ê²€ì¦
            quality_metrics = self._validate_vector_quality(
                feature_vector, feature_names
            )

            # ê²°ê³¼ ì €ì¥
            output_files = {}

            # íŠ¹ì„± ë²¡í„° ì €ì¥
            vector_path = self.cache_dir / "feature_vector_full.npy"
            try:
                np.save(vector_path, feature_vector)
                output_files["feature_vector"] = str(vector_path)
                self.logger.info(f"íŠ¹ì„± ë²¡í„° ì €ì¥: {vector_path}")
            except Exception as e:
                self.logger.error(f"íŠ¹ì„± ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {e}")

            # íŠ¹ì„± ì´ë¦„ ì €ì¥
            names_path = self.cache_dir / "feature_vector_full.names.json"
            try:
                with open(names_path, "w", encoding="utf-8") as f:
                    json.dump(feature_names, f, ensure_ascii=False, indent=2)
                output_files["feature_names"] = str(names_path)
                self.logger.info(f"íŠ¹ì„± ì´ë¦„ ì €ì¥: {names_path}")
            except Exception as e:
                self.logger.error(f"íŠ¹ì„± ì´ë¦„ ì €ì¥ ì‹¤íŒ¨: {e}")

            # ë²¡í„° ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                "vector_dimension": vector_dim,
                "feature_count": len(feature_names),
                "quality_metrics": quality_metrics,
                "generated_at": datetime.now().isoformat(),
                "config": self.execution_options,
            }

            metadata_path = self.cache_dir / "feature_vector_metadata.json"
            try:
                with open(metadata_path, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                output_files["metadata"] = str(metadata_path)
                self.logger.info(f"ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
            except Exception as e:
                self.logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            execution_time = time.time() - start_time
            metrics = {
                "execution_time": execution_time,
                "vector_dimension": vector_dim,
                "feature_count": len(feature_names),
                "memory_usage": self.memory_manager.get_memory_usage(),
                "quality_score": quality_metrics.get("overall_score", 0.0),
            }

            self.logger.info(
                f"ë²¡í„°í™” ì™„ë£Œ: {vector_dim}ì°¨ì›, í’ˆì§ˆì ìˆ˜: {quality_metrics.get('overall_score', 0.0):.3f}"
            )

            return {
                "success": True,
                "metrics": metrics,
                "output_files": output_files,
                "vector_data": {
                    "vector": feature_vector,
                    "names": feature_names,
                    "metadata": metadata,
                },
            }

        except Exception as e:
            self.logger.error(f"ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "metrics": {},
                "output_files": {},
            }

    def run_negative_sampling(
        self, vectorization_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Negative ìƒ˜í”Œë§ ë‹¨ê³„"""
        start_time = time.time()

        try:
            # Negative ìƒ˜í”Œ ìƒì„±ê¸° ì´ˆê¸°í™”
            if self._negative_generator is None:
                self._negative_generator = NegativeSampleGenerator(self.config)

            # ê³¼ê±° ë°ì´í„° ë¡œë“œ
            historical_data = load_draw_history()
            if not historical_data:
                return {
                    "success": False,
                    "error": "ê³¼ê±° ë‹¹ì²¨ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "metrics": {},
                    "output_files": {},
                }

            # íŠ¹ì„± ë²¡í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if "vector_data" in vectorization_result:
                feature_vector = vectorization_result["vector_data"]["vector"]
                vector_dim = len(feature_vector)
            else:
                # íŒŒì¼ì—ì„œ ë¡œë“œ
                vector_path = self.cache_dir / "feature_vector_full.npy"
                if vector_path.exists():
                    feature_vector = np.load(vector_path)
                    vector_dim = len(feature_vector)
                else:
                    return {
                        "success": False,
                        "error": "íŠ¹ì„± ë²¡í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                        "metrics": {},
                        "output_files": {},
                    }

            # ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
            positive_count = len(historical_data)
            negative_count = int(
                positive_count * self.execution_options["negative_sample_ratio"]
            )

            self.logger.info(
                f"Negative ìƒ˜í”Œ ìƒì„±: ì–‘ì„± {positive_count}ê°œ â†’ ìŒì„± {negative_count}ê°œ"
            )

            # Negative ìƒ˜í”Œ ìƒì„±
            negative_result = self._negative_generator.generate_samples(
                historical_data, sample_size=negative_count
            )

            if not negative_result.get("success", False):
                self.logger.error(
                    f"Negative ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨: {negative_result.get('error', 'Unknown error')}"
                )
                return {
                    "success": False,
                    "error": f"Negative ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨: {negative_result.get('error', 'Unknown error')}",
                    "metrics": {},
                    "output_files": {},
                }

            # ê²°ê³¼ íŒŒì¼ë“¤ ì •ë¦¬
            output_files = {}

            # ìƒì„±ëœ ìƒ˜í”Œ íŒŒì¼ë“¤ í™•ì¸
            if "raw_path" in negative_result:
                output_files["raw_samples"] = negative_result["raw_path"]
            if "vector_path" in negative_result:
                output_files["vector_samples"] = negative_result["vector_path"]
            if "report_path" in negative_result:
                output_files["performance_report"] = negative_result["report_path"]

            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            sample_count = negative_result.get("sample_count", 0)
            self.logger.info(f"ìƒì„±ëœ Negative ìƒ˜í”Œ ìˆ˜: {sample_count:,}ê°œ")

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                "total_negative_samples": sample_count,
                "positive_samples": positive_count,
                "negative_ratio": self.execution_options["negative_sample_ratio"],
                "vector_dimension": vector_dim,
                "generated_at": datetime.now().isoformat(),
                "generation_config": self.execution_options,
                "generation_time": negative_result.get("elapsed_time", 0),
                "memory_used_mb": negative_result.get("memory_used_mb", 0),
            }

            metadata_path = self.cache_dir / "negative_sampling_metadata.json"
            try:
                with open(metadata_path, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                output_files["metadata"] = str(metadata_path)
                self.logger.info(f"ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
            except Exception as e:
                self.logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            execution_time = time.time() - start_time
            metrics = {
                "execution_time": execution_time,
                "total_samples": sample_count,
                "memory_usage": self.memory_manager.get_memory_usage(),
                "generation_rate": (
                    sample_count / execution_time if execution_time > 0 else 0
                ),
                "generation_time": negative_result.get("elapsed_time", 0),
                "memory_used_mb": negative_result.get("memory_used_mb", 0),
            }

            self.logger.info(
                f"Negative ìƒ˜í”Œë§ ì™„ë£Œ: {sample_count:,}ê°œ ìƒì„± ({execution_time:.2f}ì´ˆ)"
            )

            return {
                "success": True,
                "metrics": metrics,
                "output_files": output_files,
                "sample_data": {
                    "total_count": sample_count,
                    "metadata": metadata,
                },
            }

        except Exception as e:
            self.logger.error(f"Negative ìƒ˜í”Œë§ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "metrics": {},
                "output_files": {},
            }

    def validate_and_save_results(
        self, pipeline_results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ê²°ê³¼ ê²€ì¦ ë° ì €ì¥"""
        validation_result = {
            "success": True,
            "checks_passed": [],
            "checks_failed": [],
            "warnings": [],
        }

        try:
            # 1. í•„ìˆ˜ ì¶œë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
            required_files = [
                "feature_vector_full.npy",
                "feature_vector_full.names.json",
            ]

            for filename in required_files:
                file_path = self.cache_dir / filename
                if file_path.exists():
                    validation_result["checks_passed"].append(f"íŒŒì¼ ì¡´ì¬: {filename}")
                else:
                    validation_result["checks_failed"].append(f"íŒŒì¼ ëˆ„ë½: {filename}")
                    validation_result["success"] = False

            # 2. ë²¡í„° ì°¨ì› ê²€ì¦
            vector_path = self.cache_dir / "feature_vector_full.npy"
            if vector_path.exists():
                vector = np.load(vector_path)
                vector_dim = len(vector)
                target_range = self.execution_options["vector_dimensions"]

                if target_range[0] <= vector_dim <= target_range[1]:
                    validation_result["checks_passed"].append(
                        f"ë²¡í„° ì°¨ì› ì í•©: {vector_dim}"
                    )
                else:
                    validation_result["warnings"].append(
                        f"ë²¡í„° ì°¨ì› ë²”ìœ„ ì™¸: {vector_dim} (ëª©í‘œ: {target_range})"
                    )

            # 3. Negative ìƒ˜í”Œ ê²€ì¦ (ì„ íƒì )
            negative_train_path = self.cache_dir / "negative_samples_train.npy"
            if negative_train_path.exists():
                train_samples = np.load(negative_train_path)
                validation_result["checks_passed"].append(
                    f"Negative ìƒ˜í”Œ ìƒì„±: {len(train_samples)}ê°œ"
                )

            # 4. ì „ì²´ ìš”ì•½ ì €ì¥
            summary_path = self.cache_dir / "data_preparation_summary.json"
            summary = {
                "pipeline_execution": pipeline_results,
                "validation": validation_result,
                "generated_at": datetime.now().isoformat(),
            }

            with open(summary_path, "w", encoding="utf-8") as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)

            validation_result["summary_file"] = str(summary_path)

            self.logger.info(
                f"ê²€ì¦ ì™„ë£Œ: {len(validation_result['checks_passed'])}ê°œ í†µê³¼, {len(validation_result['checks_failed'])}ê°œ ì‹¤íŒ¨"
            )

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            validation_result["success"] = False
            validation_result["error"] = str(e)

        return validation_result

    # ========== ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤ ==========

    def _clear_pipeline_cache(self):
        """íŒŒì´í”„ë¼ì¸ ìºì‹œ ì •ë¦¬"""
        cache_files = [
            "feature_vector_full.npy",
            "feature_vector_full.names.json",
            "feature_vector_metadata.json",
            "negative_samples_train.npy",
            "negative_samples_test.npy",
            "negative_sampling_metadata.json",
            "data_preparation_summary.json",
        ]

        for filename in cache_files:
            file_path = self.cache_dir / filename
            if file_path.exists():
                file_path.unlink()
                self.logger.debug(f"ìºì‹œ íŒŒì¼ ì‚­ì œ: {filename}")

    def _check_analysis_output_files(self) -> Dict[str, str]:
        """ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸"""
        output_files = {}

        # ì£¼ìš” ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤
        analysis_files = [
            "unified_analysis.json",
            "pattern_analysis.json",
            "pair_analysis.json",
            "distribution_analysis.json",
            "roi_analysis.json",
        ]

        for filename in analysis_files:
            file_path = self.result_dir / filename
            if file_path.exists():
                output_files[filename.replace(".json", "")] = str(file_path)

        return output_files

    def _load_analysis_result(self) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ë¡œë“œ (ìºì‹œì—ì„œ)"""
        try:
            unified_path = self.result_dir / "unified_analysis.json"
            if unified_path.exists():
                with open(unified_path, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return {}

    def _load_vectorization_result(self) -> Dict[str, Any]:
        """ë²¡í„°í™” ê²°ê³¼ ë¡œë“œ (ìºì‹œì—ì„œ)"""
        try:
            metadata_path = self.cache_dir / "feature_vector_metadata.json"
            if metadata_path.exists():
                with open(metadata_path, "r", encoding="utf-8") as f:
                    metadata = json.load(f)

                # ë²¡í„° ë°ì´í„° ë¡œë“œ
                vector_path = self.cache_dir / "feature_vector_full.npy"
                names_path = self.cache_dir / "feature_vector_full.names.json"

                if vector_path.exists() and names_path.exists():
                    vector = np.load(vector_path)
                    with open(names_path, "r", encoding="utf-8") as f:
                        names = json.load(f)

                    return {
                        "success": True,
                        "vector_data": {
                            "vector": vector,
                            "names": names,
                            "metadata": metadata,
                        },
                    }
        except Exception as e:
            self.logger.warning(f"ë²¡í„°í™” ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return {"success": False}

    def _load_unified_analysis(self) -> Dict[str, Any]:
        """í†µí•© ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            unified_path = self.result_dir / "unified_analysis.json"
            if unified_path.exists():
                with open(unified_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if not data:
                        self.logger.warning("í†µí•© ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                        return {}
                    self.logger.info(f"í†µí•© ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)} í•­ëª©")
                    return data
            else:
                self.logger.warning(
                    "í†µí•© ë¶„ì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤."
                )
                # ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„
                alternative_paths = [
                    self.result_dir / "optimized_analysis_result.json",
                    self.result_dir / "analysis_results.json",
                    Path("data/result/analysis/analysis_results.json"),
                    Path("data/result/analysis/optimized_analysis_result.json"),
                    Path("data/result/unified_analysis.json"),
                ]

                for alt_path in alternative_paths:
                    if alt_path.exists():
                        self.logger.info(f"ëŒ€ì²´ ë¶„ì„ íŒŒì¼ ì‚¬ìš©: {alt_path}")
                        with open(alt_path, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            if data:
                                return data

                self.logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
        except Exception as e:
            self.logger.error(f"í†µí•© ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def _validate_vector_quality(
        self, vector: np.ndarray, names: List[str]
    ) -> Dict[str, Any]:
        """ë²¡í„° í’ˆì§ˆ ê²€ì¦"""
        quality_metrics = {}

        try:
            # ê¸°ë³¸ í†µê³„
            quality_metrics["mean"] = float(np.mean(vector))
            quality_metrics["std"] = float(np.std(vector))
            quality_metrics["min"] = float(np.min(vector))
            quality_metrics["max"] = float(np.max(vector))

            # 0ê°’ ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            zero_ratio = np.sum(vector == 0) / len(vector)
            quality_metrics["zero_ratio"] = float(zero_ratio)

            # ì—”íŠ¸ë¡œí”¼ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            hist, _ = np.histogram(vector, bins=50)
            hist = hist[hist > 0]  # 0ì´ ì•„ë‹Œ ë¹ˆë„ë§Œ
            if len(hist) > 0:
                prob = hist / hist.sum()
                entropy = -np.sum(prob * np.log2(prob))
                quality_metrics["entropy"] = float(entropy)
            else:
                quality_metrics["entropy"] = 0.0

            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (0~1)
            entropy_score = min(
                quality_metrics["entropy"] / 6.0, 1.0
            )  # 6ì€ ëŒ€ëµì ì¸ ìµœëŒ€ ì—”íŠ¸ë¡œí”¼
            zero_score = 1.0 - zero_ratio  # 0ê°’ì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            variance_score = min(
                (
                    quality_metrics["std"] / quality_metrics["mean"]
                    if quality_metrics["mean"] > 0
                    else 0
                ),
                1.0,
            )

            overall_score = (entropy_score + zero_score + variance_score) / 3.0
            quality_metrics["overall_score"] = float(overall_score)

        except Exception as e:
            self.logger.warning(f"ë²¡í„° í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            quality_metrics["overall_score"] = 0.0

        return quality_metrics

    def _print_performance_summary(self, results: Dict[str, Any]):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìš”ì•½")
        self.logger.info("=" * 60)

        # ì‹¤í–‰ëœ ë‹¨ê³„
        executed = results.get("steps_executed", [])
        failed = results.get("steps_failed", [])

        self.logger.info(
            f"âœ… ì„±ê³µí•œ ë‹¨ê³„: {', '.join(executed) if executed else 'ì—†ìŒ'}"
        )
        if failed:
            self.logger.info(f"âŒ ì‹¤íŒ¨í•œ ë‹¨ê³„: {', '.join(failed)}")

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        metrics = results.get("performance_metrics", {})
        total_time = results.get("total_execution_time", 0)

        self.logger.info(f"â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")

        for step, step_metrics in metrics.items():
            execution_time = step_metrics.get("execution_time", 0)
            self.logger.info(f"   - {step}: {execution_time:.2f}ì´ˆ")

        # ì¶œë ¥ íŒŒì¼ ìš”ì•½
        output_files = results.get("output_files", {})
        if output_files:
            self.logger.info(f"ğŸ“ ìƒì„±ëœ íŒŒì¼: {len(output_files)}ê°œ")
            for category, path in output_files.items():
                self.logger.info(f"   - {category}: {Path(path).name}")

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_usage = self.memory_manager.get_memory_usage()
        self.logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f}MB")

        self.logger.info("=" * 60)

    def _save_pipeline_report(self, results: Dict[str, Any]):
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë³´ê³ ì„œ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_path = self.performance_dir / f"pipeline_report_{timestamp}.json"

            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)

            self.logger.info(f"ì‹¤í–‰ ë³´ê³ ì„œ ì €ì¥: {report_path}")

        except Exception as e:
            self.logger.warning(f"ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")


def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="DAEBAK AI ë°ì´í„° ì¤€ë¹„ í†µí•© íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--clear-cache", action="store_true", help="ìºì‹œ ì´ˆê¸°í™” í›„ ì‹¤í–‰"
    )

    parser.add_argument(
        "--steps",
        type=str,
        default="analysis,vectorization,negative_sampling",
        help="ì‹¤í–‰í•  ë‹¨ê³„ (ì‰¼í‘œë¡œ êµ¬ë¶„): analysis, vectorization, negative_sampling",
    )

    parser.add_argument(
        "--debug", action="store_true", help="ë””ë²„ê·¸ ëª¨ë“œ (ì˜¤ë¥˜ ì‹œì—ë„ ê³„ì† ì§„í–‰)"
    )

    parser.add_argument("--verbose", action="store_true", help="ìƒì„¸ ë¡œê¹… í™œì„±í™”")

    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()

    # ìµœëŒ€ ì„±ëŠ¥ ìµœì í™” ëª¨ë“œ ì‹œì‘
    optimizer = launch_max_performance()

    try:
        pipeline = DataPreparationPipeline()

        # CLI ì¸ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ ì˜µì…˜ ì„¤ì •
        steps = args.steps.split(",") if args.steps else None

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline.execute_full_pipeline(
            clear_cache=args.clear_cache,
            steps=steps,
            debug=args.debug,
            verbose=args.verbose,
        )

    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)
    finally:
        if optimizer:
            optimizer.cleanup()


if __name__ == "__main__":
    main()
