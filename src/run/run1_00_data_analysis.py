#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ë°ì´í„° ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¡œë˜ ë°ì´í„°ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ ,
í•„ìš”í•œ ëª¨ë“  íŠ¹ì„± ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import numpy as np
import time
import logging
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

# ë¡œê±° ì„¤ì •
from src.utils.error_handler_refactored import get_logger, log_exception_with_trace

logger = get_logger(__name__)


def main():
    """
    ë°ì´í„° ë¶„ì„ ë° ë²¡í„°í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    try:
        start_time = time.time()
        logger.info("ë°ì´í„° ë¶„ì„ ë° ë²¡í„°í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘")

        # í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
        from src.utils.data_loader import load_draw_history
        from src.utils.config_loader import load_config
        from src.analysis.unified_analyzer import UnifiedAnalyzer
        from src.analysis.pattern_vectorizer import PatternVectorizer
        from src.utils.unified_report import save_analysis_performance_report

        # ğŸ”§ í†µí•© ì„±ëŠ¥ ì¶”ì ê¸° ì‚¬ìš©
        from src.utils.unified_performance import get_profiler
        from src.utils.unified_feature_vector_validator import (
            validate_feature_vector_with_config,
            check_vector_dimensions,
            create_feature_registry,
            check_feature_mapping_consistency,
            sync_vectors_and_names,
            ensure_essential_features,
            safe_float_conversion,
            ESSENTIAL_FEATURES,
            detect_outliers,
            save_outlier_information,
            analyze_vector_statistics,
        )

        # ì„¤ì • ë¡œë“œ
        config = load_config()

        # ì„¤ì • íŒŒì¼ ê²€ì¦ (í•„ìˆ˜ í‚¤ í™•ì¸)
        try:
            # ì¤‘ìš” ì„¤ì • í‚¤ ê²€ì¦
            config.validate_critical_paths()

            # ë¶„ì„ ê´€ë ¨ í•„ìˆ˜ í‚¤ ê²€ì¦
            required_keys = [
                "clustering.n_clusters",
                "clustering.min_silhouette_score",
                "filtering.remove_low_variance_features",
                "filtering.variance_threshold",
                "paths.analysis_result_dir",
                "paths.performance_report_dir",
            ]

            for key in required_keys:
                if not config.has_key(key):
                    logger.warning(f"í•„ìˆ˜ ì„¤ì • í‚¤ ëˆ„ë½: {key}")

            logger.info("ì„¤ì • íŒŒì¼ ê²€ì¦ ì™„ë£Œ: ëª¨ë“  í•„ìˆ˜ í‚¤ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.warning(f"ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.warning("ì¼ë¶€ í•„ìˆ˜ ì„¤ì •ì´ ëˆ„ë½ë˜ì–´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ğŸ”§ í†µí•© ì„±ëŠ¥ ì¶”ì ê¸° ì‚¬ìš©
        profiler = get_profiler()
        profiler.start("total")

        # ë°ì´í„° ë¡œë“œ
        draw_data = load_draw_history()
        logger.info(f"ë¡œë˜ ë‹¹ì²¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(draw_data)}ê°œ íšŒì°¨")

        # í†µí•© ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¶„ì„ ìˆ˜í–‰
        logger.info("í†µí•© ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        profiler.start("unified_analysis")
        unified_analyzer = UnifiedAnalyzer(config)
        analysis_result = unified_analyzer.analyze(draw_data)
        profiler.stop("unified_analysis")
        logger.info(f"í†µí•© ë¶„ì„ ì™„ë£Œ: {len(analysis_result)}ê°œ ë¶„ì„ í•­ëª©")

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        logger.info("ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
        profiler.start("save_analysis")
        result_path = unified_analyzer.save_analysis_results(analysis_result)
        profiler.stop("save_analysis")
        logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_path}")

        # íŒ¨í„´ ë²¡í„°ë¼ì´ì € ì´ˆê¸°í™” ë° ë²¡í„°í™” ìˆ˜í–‰
        pattern_vectorizer = PatternVectorizer(config)

        # ì €ë¶„ì‚° íŠ¹ì„± ì œê±° ì„¤ì •
        if config["filtering"]["remove_low_variance_features"]:
            pattern_vectorizer.remove_low_variance = True
            pattern_vectorizer.variance_threshold = config["filtering"][
                "variance_threshold"
            ]

        logger.info("í™•ì¥ íŠ¹ì„± ë²¡í„°í™” ìˆ˜í–‰ ì¤‘...")
        profiler.start("vectorization")

        # dict ê°’ ì•ˆì „ ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€
        pattern_vectorizer.external_float_conversion = safe_float_conversion

        # ë²¡í„° ìƒì„± - í™•ì¥ íŠ¹ì„± ë²¡í„° ìƒì„± ë°©ì‹ ì‚¬ìš©
        feature_vectors, feature_names = pattern_vectorizer.vectorize_extended_features(
            analysis_result
        )
        profiler.stop("vectorization")
        logger.info(
            f"í™•ì¥ íŠ¹ì„± ë²¡í„°í™” ì™„ë£Œ: ì°¨ì› {feature_vectors.shape}, íŠ¹ì„± ìˆ˜ {len(feature_names)}"
        )

        # ë²¡í„° ë° íŠ¹ì„± ì´ë¦„ì„ ìºì‹œì— ì €ì¥
        cache_dir = Path(project_root) / config["paths"]["cache_dir"]
        cache_dir.mkdir(parents=True, exist_ok=True)

        # ì£¼ìš” ë²¡í„° íŒŒì¼ ê²½ë¡œ
        vector_file = cache_dir / "feature_vectors_full.npy"
        names_file = cache_dir / "feature_vector_full.names.json"

        # ë²¡í„° ë° ì´ë¦„ ì €ì¥
        profiler.start("save_vectors")
        np.save(vector_file, feature_vectors)
        with open(names_file, "w", encoding="utf-8") as f:
            json.dump(feature_names, f, indent=2, ensure_ascii=False)
        profiler.stop("save_vectors")

        logger.info(f"íŠ¹ì„± ë²¡í„° ì €ì¥ ì™„ë£Œ: {vector_file}")
        logger.info(f"íŠ¹ì„± ì´ë¦„ ì €ì¥ ì™„ë£Œ: {names_file}")

        # ë²¡í„° ê²€ì¦ - ìµœì†Œ 70ê°œ ì´ìƒì˜ íŠ¹ì„± í™•ë³´ í™•ì¸
        if len(feature_names) < 70:
            error_msg = f"ìƒì„±ëœ íŠ¹ì„± ë²¡í„° ìˆ˜ê°€ ìµœì†Œ ìš”êµ¬ì‚¬í•­ì¸ 70ê°œë³´ë‹¤ ì ìŠµë‹ˆë‹¤: {len(feature_names)}ê°œ"
            logger.error(error_msg)
            raise ValueError(error_msg)
        else:
            logger.info(
                f"ë²¡í„° ì°¨ì› í™•ì¸: {len(feature_names)}ê°œ (ìµœì†Œ 70ê°œ ì´ìƒ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±)"
            )

        # ë²¡í„° ê²€ì¦ ë° í•„ìˆ˜ íŠ¹ì„± ì¶”ê°€
        profiler.start("vector_validation")
        logger.info("íŠ¹ì„± ë²¡í„° ê²€ì¦ ìˆ˜í–‰ ì¤‘...")

        # ì„¤ì •ì—ì„œ í•„ìˆ˜ íŠ¹ì„± ëª©ë¡ì„ ê°€ì ¸ì™€ ë²¡í„° ê²€ì¦
        names_file_path = str(names_file)
        vector_file_path = str(vector_file)

        # ë²¡í„° ì°¨ì›ê³¼ íŠ¹ì„± ì´ë¦„ ìˆ˜ í™•ì¸ - ë¶ˆì¼ì¹˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
        try:
            dim_check = check_vector_dimensions(
                vector_file_path,
                names_file_path,
                raise_on_mismatch=True,  # ë¶ˆì¼ì¹˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
                allow_mismatch=False,  # ì°¨ì› ë¶ˆì¼ì¹˜ í—ˆìš© ì•ˆí•¨
            )
            logger.info("ë²¡í„° ì°¨ì›ê³¼ íŠ¹ì„± ì´ë¦„ ìˆ˜ ì¼ì¹˜ í™•ì¸ë¨")
        except ValueError as e:
            logger.error(f"ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜ ì˜¤ë¥˜: {str(e)}")
            raise

        # ROI íŠ¹ì„± ë²¡í„° í™•ì¸
        roi_features = analysis_result.get("roi_features", {})
        if roi_features:
            logger.info("ROI íŠ¹ì„±ì´ ë¶„ì„ ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            logger.info(
                f"ROI ê·¸ë£¹ ì ìˆ˜ í•­ëª© ìˆ˜: {len(roi_features.get('roi_group_score', {}))}"
            )
            logger.info(
                f"ROI í´ëŸ¬ìŠ¤í„° í•­ëª© ìˆ˜: {len(roi_features.get('roi_cluster_score', {}).get('cluster_assignments', {}))}"
            )
            logger.info(
                f"ì €ìœ„í—˜ ë³´ë„ˆìŠ¤ í”Œë˜ê·¸ í•­ëª© ìˆ˜: {len(roi_features.get('low_risk_bonus_flag', {}).get('low_risk_bonus_flag', {}))}"
            )
            logger.info(
                f"ROI íŒ¨í„´ ê·¸ë£¹ ID í•­ëª© ìˆ˜: {len(roi_features.get('roi_pattern_group_id', {}))}"
            )

            # íŠ¹ì„± ì´ë¦„ì— roi_features ê´€ë ¨ í•­ëª©ì´ ìˆëŠ”ì§€ í™•ì¸
            roi_feature_count = sum(
                1 for name in feature_names if name.startswith("roi_")
            )
            if roi_feature_count > 0:
                logger.info(
                    f"ROI ê´€ë ¨ íŠ¹ì„± {roi_feature_count}ê°œê°€ ë²¡í„°ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                )
            else:
                logger.warning("ë²¡í„°ì— ROI íŠ¹ì„±ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            logger.warning(
                "ë¶„ì„ ê²°ê³¼ì— ROI íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ROI ë¶„ì„ê¸°ê°€ ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )

        # í•„ìˆ˜ íŠ¹ì„± í™•ì¸
        missing_features = validate_feature_vector_with_config(config, names_file_path)
        if missing_features:
            logger.error(f"í•„ìˆ˜ íŠ¹ì„± ëˆ„ë½: {missing_features}")
            # í•„ìˆ˜ íŠ¹ì„±ì´ ëˆ„ë½ëœ ê²½ìš° ë³´ê³ ì„œì— ê¸°ë¡í•˜ê¸° ìœ„í•´ ì €ì¥
            missing_features_file = cache_dir / "missing_features.json"
            with open(missing_features_file, "w", encoding="utf-8") as f:
                json.dump(missing_features, f, indent=2, ensure_ascii=False)
        else:
            logger.info("ëª¨ë“  í•„ìˆ˜ íŠ¹ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        # íŠ¹ì„± ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„± ë° ì €ì¥
        try:
            registry_file = cache_dir / "feature_registry.json"
            feature_registry = create_feature_registry(config, str(registry_file))
            logger.info(f"íŠ¹ì„± ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥ ì™„ë£Œ: {registry_file}")

            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ íŠ¹ì„± ì´ë¦„ì˜ ì¼ê´€ì„± ê²€ì‚¬
            with open(names_file_path, "r", encoding="utf-8") as f:
                updated_feature_names = json.load(f)

            inconsistencies = check_feature_mapping_consistency(
                updated_feature_names, feature_registry
            )
            if inconsistencies:
                logger.warning(
                    f"ì¼ë¶€ íŠ¹ì„±({len(inconsistencies)}ê°œ)ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
        except Exception as e:
            logger.error(f"íŠ¹ì„± ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„± ë° ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ì´ìƒì¹˜ íƒì§€ ë° ì €ì¥
        profiler.start("outlier_detection")
        logger.info("ì´ìƒì¹˜ íƒì§€ ìˆ˜í–‰ ì¤‘...")

        try:
            # Z-score ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ (ì„ê³„ê°’: 2.5)
            outlier_mask, outlier_indices = detect_outliers(
                vector_file_path, names_file_path, z_threshold=2.5
            )

            # ì´ìƒì¹˜ ì •ë³´ ì €ì¥
            if len(outlier_indices) > 0:
                mask_path, indices_path = save_outlier_information(
                    vector_file_path, outlier_mask, outlier_indices
                )
                logger.info(f"ì´ìƒì¹˜ ì •ë³´ ì €ì¥ ì™„ë£Œ: {len(outlier_indices)}ê°œ í•­ëª©")
            else:
                logger.info("ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"ì´ìƒì¹˜ íƒì§€ ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        profiler.stop("outlier_detection")

        # ë²¡í„° í†µê³„ ë¶„ì„
        profiler.start("vector_statistics")
        logger.info("ë²¡í„° í†µê³„ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")

        try:
            vector_stats = analyze_vector_statistics(vector_file_path, names_file_path)

            # í†µê³„ ì •ë³´ ì €ì¥
            stats_file = cache_dir / "vector_statistics.json"
            with open(stats_file, "w", encoding="utf-8") as f:
                json.dump(vector_stats, f, indent=2, ensure_ascii=False)

            logger.info(f"ë²¡í„° í†µê³„ ì •ë³´ ì €ì¥ ì™„ë£Œ: {stats_file}")

            # ì£¼ìš” í†µê³„ ì¶œë ¥
            logger.info(
                f"ë²¡í„° í†µê³„: ì—”íŠ¸ë¡œí”¼ ì ìˆ˜={vector_stats.get('feature_entropy_score', 0):.4f}, "
                f"NaN ë¹„ìœ¨={vector_stats.get('nan_rate', 0):.6f}, "
                f"íŠ¹ì„± í¬ê¸° í‰ê· ={vector_stats.get('vector_scale_mean', 0):.4f}"
            )

        except Exception as e:
            logger.error(f"ë²¡í„° í†µê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        profiler.stop("vector_statistics")

        logger.info("íŠ¹ì„± ë²¡í„° ê²€ì¦ ì™„ë£Œ")
        profiler.stop("vector_validation")

        # í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ
        profiler.stop("total")

        # ì„±ëŠ¥ ë³´ê³ ì„œ ì €ì¥ - í™•ì¥ëœ ë©”íŠ¸ë¦­ í¬í•¨
        data_metrics = {
            "record_count": len(draw_data),
            "vector_shape": list(feature_vectors.shape),
            "features_count": len(feature_names),
            "essential_features_count": len(ESSENTIAL_FEATURES),
            "missing_features_count": len(missing_features) if missing_features else 0,
            "low_variance_features_removed": len(
                pattern_vectorizer.removed_low_variance_features
            ),
            "vector_dim": feature_vectors.shape[1],
            "vector_nan_rate": float(np.isnan(feature_vectors).sum())
            / feature_vectors.size,
            # ğŸ”§ í†µí•© ì„±ëŠ¥ ì¶”ì ê¸° ì‚¬ìš©
            "cache_hit_rate": profiler.get_cache_hit_rate(),
            "analysis_time": time.time() - start_time,
            # í™•ì¥ëœ ë©”íŠ¸ë¦­
            "outlier_count": (
                len(outlier_indices) if "outlier_indices" in locals() else 0
            ),
            "vector_scale_mean": float(np.mean(np.abs(feature_vectors))),
            "vector_scale_std": float(np.std(np.abs(feature_vectors))),
            "feature_entropy_score": (
                vector_stats.get("feature_entropy_score", 0.0)
                if "vector_stats" in locals()
                else 0.0
            ),
            "cluster_silhouette_score": analysis_result.get(
                "cluster_embedding_quality", {}
            ).get("silhouette_score", 0.0),
            "vector_diversity_score": (
                vector_stats.get("feature_entropy_score", 0.0)
                if "vector_stats" in locals()
                else 0.0
            ),
        }

        # í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if "cluster_embedding_quality" in analysis_result:
            cluster_metrics = analysis_result["cluster_embedding_quality"]
            for key in [
                "silhouette_score",
                "cluster_score",
                "cohesiveness_score",
                "cluster_entropy_score",
                "balance_score",
            ]:
                if key in cluster_metrics:
                    data_metrics[f"cluster_{key}"] = cluster_metrics[key]

        perf_file = save_analysis_performance_report(
            # ğŸ”§ í†µí•© ì„±ëŠ¥ ì¶”ì ê¸° ì‚¬ìš©
            profiler,
            profiler,
            config,
            "data_analysis",
            data_metrics,
        )
        logger.info(f"ì„±ëŠ¥ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {perf_file}")

        # ë¡œê·¸ ì¶œë ¥
        logger.info(f"ë²¡í„° í˜•íƒœ: {feature_vectors.shape}")
        logger.info(f"íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}")
        logger.info(f"ì „ì²´ ì‹¤í–‰ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
        return 0
    except Exception as e:
        logger.error(f"ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    sys.exit(main())
