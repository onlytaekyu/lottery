"""
Optimized TCN Preprocessor
TCN ìµœì í™” ì „ì²˜ë¦¬ê¸° - ë‹¤ì¤‘ í•´ìƒë„ ìœˆë„ìš°, ì‹œê³„ì—´ ì¦ê°•, Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from sklearn.preprocessing import StandardScaler
from scipy import signal
import warnings

warnings.filterwarnings("ignore")

from ..utils.unified_logging import get_logger
from ..utils.memory_manager import MemoryManager
from ..utils.cuda_singleton_manager import CudaSingletonManager

logger = get_logger(__name__)


@dataclass
class TCNConfig:
    """TCN ì„¤ì •"""

    input_dim: int = 168
    output_dim: int = 64
    num_channels: List[int] = None
    kernel_size: int = 3
    dropout: float = 0.2
    sequence_length: int = 50
    attention_heads: int = 8
    device: str = "cuda"


class TimeSeriesAugmentation:
    """ì‹œê³„ì—´ ì¦ê°•"""

    def __init__(self, augmentation_methods: List[str] = None):
        self.methods = augmentation_methods or [
            "time_warping",
            "magnitude_warping",
            "window_slicing",
        ]

    def augment(
        self, X: np.ndarray, method: str = "time_warping", **kwargs
    ) -> np.ndarray:
        """ì‹œê³„ì—´ ì¦ê°• ì ìš©"""

        if method == "time_warping":
            return self._time_warping(X, **kwargs)
        elif method == "magnitude_warping":
            return self._magnitude_warping(X, **kwargs)
        elif method == "window_slicing":
            return self._window_slicing(X, **kwargs)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¦ê°• ë°©ë²•: {method}")

    def _time_warping(self, X: np.ndarray, sigma: float = 0.2) -> np.ndarray:
        """ì‹œê°„ ì™œê³¡"""

        seq_len = X.shape[0]

        # ì‹œê°„ ì™œê³¡ í•¨ìˆ˜ ìƒì„±
        time_steps = np.arange(seq_len)
        warp_steps = np.random.normal(0, sigma, seq_len)
        warped_time = time_steps + warp_steps

        # ê²½ê³„ ì¡°ê±´ ì²˜ë¦¬
        warped_time = np.clip(warped_time, 0, seq_len - 1)

        # ë³´ê°„ì„ í†µí•œ ì™œê³¡ ì ìš©
        warped_X = np.zeros_like(X)
        for i in range(X.shape[1]):
            warped_X[:, i] = np.interp(time_steps, warped_time, X[:, i])

        return warped_X

    def _magnitude_warping(self, X: np.ndarray, sigma: float = 0.2) -> np.ndarray:
        """í¬ê¸° ì™œê³¡"""

        # ìŠ¤ë¬´ë”© ì»¤ë¸Œ ìƒì„±
        seq_len = X.shape[0]
        warp_curve = np.random.normal(1.0, sigma, seq_len)

        # ê°€ìš°ì‹œì•ˆ í•„í„°ë¡œ ìŠ¤ë¬´ë”©
        warp_curve = signal.gaussian(seq_len, std=seq_len / 5) * warp_curve
        warp_curve = warp_curve / np.mean(warp_curve)  # í‰ê·  1ë¡œ ì •ê·œí™”

        # í¬ê¸° ì™œê³¡ ì ìš©
        warped_X = X * warp_curve.reshape(-1, 1)

        return warped_X

    def _window_slicing(self, X: np.ndarray, slice_ratio: float = 0.8) -> np.ndarray:
        """ìœˆë„ìš° ìŠ¬ë¼ì´ì‹±"""

        seq_len = X.shape[0]
        slice_len = int(seq_len * slice_ratio)

        # ëœë¤ ì‹œì‘ì  ì„ íƒ
        start_idx = np.random.randint(0, seq_len - slice_len + 1)

        # ìŠ¬ë¼ì´ì‹± í›„ ì›ë³¸ ê¸¸ì´ë¡œ ë³µì› (íŒ¨ë”© ë˜ëŠ” ë°˜ë³µ)
        sliced_X = X[start_idx : start_idx + slice_len]

        if slice_len < seq_len:
            # íŒ¨ë”©ìœ¼ë¡œ ì›ë³¸ ê¸¸ì´ ë³µì›
            pad_len = seq_len - slice_len
            pad_X = np.zeros((pad_len, X.shape[1]))
            sliced_X = np.vstack([sliced_X, pad_X])

        return sliced_X


class TemporalAttentionSelector(nn.Module):
    """ì‹œê³„ì—´ Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒê¸°"""

    def __init__(self, config: TCNConfig):
        super().__init__()
        self.config = config
        self.sequence_length = config.sequence_length
        self.attention_heads = config.attention_heads
        self.input_dim = config.input_dim

        # Multi-head attention
        self.attention = nn.MultiheadAttention(
            embed_dim=self.input_dim,
            num_heads=self.attention_heads,
            dropout=config.dropout,
            batch_first=True,
        )

        # Feature importance ê³„ì‚°ìš© ë ˆì´ì–´
        self.feature_importance = nn.Linear(self.input_dim, 1)

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: (batch_size, sequence_length, input_dim)
        Returns:
            attended_features: (batch_size, sequence_length, input_dim)
            attention_weights: (batch_size, sequence_length, sequence_length)
        """

        # Self-attention
        attended_features, attention_weights = self.attention(x, x, x)

        # Feature importance ê³„ì‚°
        feature_importance = torch.sigmoid(self.feature_importance(attended_features))

        # ì¤‘ìš”ë„ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
        selected_features = attended_features * feature_importance

        return selected_features, attention_weights

    def get_feature_importance(self, x: torch.Tensor) -> torch.Tensor:
        """íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜"""

        with torch.no_grad():
            attended_features, _ = self.attention(x, x, x)
            importance = torch.sigmoid(self.feature_importance(attended_features))

        return importance.mean(dim=(0, 1))  # ë°°ì¹˜ì™€ ì‹œí€€ìŠ¤ ì°¨ì›ì—ì„œ í‰ê· 


class OptimizedTCNPreprocessor:
    """ìµœì í™”ëœ TCN ì „ì²˜ë¦¬ê¸°"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = get_logger(__name__)
        self.memory_manager = MemoryManager()
        self.cuda_manager = CudaSingletonManager()

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device(
            "cuda" if self.cuda_manager.is_available() else "cpu"
        )

        # TCN ì„¤ì •
        self.tcn_config = TCNConfig(
            input_dim=config.get("input_dim", 168),
            output_dim=config.get("output_dim", 64),
            num_channels=config.get("num_channels", [100, 100, 100]),
            kernel_size=config.get("kernel_size", 3),
            dropout=config.get("dropout", 0.2),
            sequence_length=config.get("sequence_length", 50),
            attention_heads=config.get("attention_heads", 8),
            device=str(self.device),
        )

        # ë‹¤ì¤‘ í•´ìƒë„ ìœˆë„ìš° ì„¤ì •
        self.multi_resolution_windows = config.get(
            "multi_resolution_windows", [10, 25, 50, 100]
        )

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.time_augmentation = TimeSeriesAugmentation(
            ["time_warping", "magnitude_warping", "window_slicing"]
        )

        self.attention_selector = TemporalAttentionSelector(self.tcn_config).to(
            self.device
        )

        # ìŠ¤ì¼€ì¼ëŸ¬
        self.scaler = StandardScaler()
        self.fitted = False

    def preprocess_for_tcn(
        self, X: np.ndarray, y: Optional[np.ndarray] = None
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        TCN ìµœì í™” ì „ì²˜ë¦¬

        Args:
            X: ì…ë ¥ ë°ì´í„° (samples, features)
            y: íƒ€ê²Ÿ ë°ì´í„° (ì„ íƒì‚¬í•­)

        Returns:
            Tuple[np.ndarray, Dict]: ì „ì²˜ë¦¬ëœ ì‹œê³„ì—´ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°
        """

        try:
            self.logger.info("TCN ìµœì í™” ì „ì²˜ë¦¬ ì‹œì‘")

            with self.memory_manager.get_context("tcn_preprocessing"):
                # 1. ë°ì´í„° ì •ê·œí™”
                self.logger.info("ë°ì´í„° ì •ê·œí™”...")
                X_scaled = self.scaler.fit_transform(X)

                # 2. ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
                self.logger.info("ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±...")
                X_sequences = self._create_sequences(X_scaled)

                # 3. ë‹¤ì¤‘ í•´ìƒë„ íŠ¹ì„± ì¶”ì¶œ
                self.logger.info("ë‹¤ì¤‘ í•´ìƒë„ íŠ¹ì„± ì¶”ì¶œ...")
                X_multi_resolution = self._extract_multi_resolution_features(
                    X_sequences
                )

                # 4. ì‹œê³„ì—´ ì¦ê°•
                self.logger.info("ì‹œê³„ì—´ ì¦ê°•...")
                X_augmented = self._apply_time_series_augmentation(X_multi_resolution)

                # 5. Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
                self.logger.info("Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ...")
                X_selected, attention_weights = self._apply_attention_selection(
                    X_augmented
                )

                # 6. ìµœì¢… ì‹œí€€ìŠ¤ í˜•íƒœë¡œ ë³€í™˜
                X_final = self._format_for_tcn(X_selected)

                # ë©”íƒ€ë°ì´í„° ìƒì„±
                metadata = {
                    "sequence_length": self.tcn_config.sequence_length,
                    "input_dim": X_final.shape[-1],
                    "multi_resolution_windows": self.multi_resolution_windows,
                    "attention_heads": self.tcn_config.attention_heads,
                    "augmentation_methods": self.time_augmentation.methods,
                    "compression_ratio": X.shape[1] / X_final.shape[-1],
                }

                self.fitted = True
                self.logger.info(
                    f"TCN ì „ì²˜ë¦¬ ì™„ë£Œ - ì‹œí€€ìŠ¤ ê¸¸ì´: {X_final.shape[1]}, íŠ¹ì„± ìˆ˜: {X_final.shape[2]}"
                )

                return X_final, metadata

        except Exception as e:
            self.logger.error(f"TCN ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def _create_sequences(self, X: np.ndarray) -> np.ndarray:
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""

        sequence_length = self.tcn_config.sequence_length

        if len(X) < sequence_length:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒ¨ë”©
            pad_length = sequence_length - len(X)
            X_padded = np.pad(X, ((0, pad_length), (0, 0)), mode="edge")
            sequences = X_padded.reshape(1, sequence_length, -1)
        else:
            # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
            sequences = []
            for i in range(len(X) - sequence_length + 1):
                sequences.append(X[i : i + sequence_length])
            sequences = np.array(sequences)

        return sequences

    def _extract_multi_resolution_features(self, X_sequences: np.ndarray) -> np.ndarray:
        """ë‹¤ì¤‘ í•´ìƒë„ íŠ¹ì„± ì¶”ì¶œ"""

        multi_resolution_features = []

        for window_size in self.multi_resolution_windows:
            if window_size <= X_sequences.shape[1]:
                # ì§€ì •ëœ ìœˆë„ìš° í¬ê¸°ë¡œ ë‹¤ìš´ìƒ˜í”Œë§
                step = max(1, X_sequences.shape[1] // window_size)
                downsampled = X_sequences[:, ::step, :]

                # ê³ ì • ê¸¸ì´ë¡œ ë§ì¶¤
                if downsampled.shape[1] > window_size:
                    downsampled = downsampled[:, :window_size, :]
                elif downsampled.shape[1] < window_size:
                    # íŒ¨ë”©
                    pad_length = window_size - downsampled.shape[1]
                    downsampled = np.pad(
                        downsampled, ((0, 0), (0, pad_length), (0, 0)), mode="edge"
                    )

                multi_resolution_features.append(downsampled)

        # ëª¨ë“  í•´ìƒë„ íŠ¹ì„± ì—°ê²°
        if multi_resolution_features:
            # ì‹œí€€ìŠ¤ ì°¨ì›ì—ì„œ ì—°ê²°
            combined_features = np.concatenate(multi_resolution_features, axis=1)
        else:
            combined_features = X_sequences

        return combined_features

    def _apply_time_series_augmentation(self, X: np.ndarray) -> np.ndarray:
        """ì‹œê³„ì—´ ì¦ê°• ì ìš©"""

        augmented_sequences = []

        for i, sequence in enumerate(X):
            # ì›ë³¸ ì‹œí€€ìŠ¤ ì¶”ê°€
            augmented_sequences.append(sequence)

            # ê° ì¦ê°• ë°©ë²• ì ìš© (50% í™•ë¥ )
            for method in self.time_augmentation.methods:
                if np.random.random() < 0.5:
                    try:
                        augmented_seq = self.time_augmentation.augment(sequence, method)
                        augmented_sequences.append(augmented_seq)
                    except Exception as e:
                        self.logger.warning(f"ì¦ê°• ë°©ë²• {method} ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")

        return np.array(augmented_sequences)

    def _apply_attention_selection(
        self, X: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ"""

        # PyTorch í…ì„œë¡œ ë³€í™˜
        X_tensor = torch.FloatTensor(X).to(self.device)

        # Attention ì ìš©
        self.attention_selector.eval()
        with torch.no_grad():
            selected_features, attention_weights = self.attention_selector(X_tensor)

        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        selected_features = selected_features.cpu().numpy()
        attention_weights = attention_weights.cpu().numpy()

        return selected_features, attention_weights

    def _format_for_tcn(self, X: np.ndarray) -> np.ndarray:
        """TCN ì…ë ¥ í˜•íƒœë¡œ í¬ë§·íŒ…"""

        # TCNì€ (batch_size, sequence_length, input_dim) í˜•íƒœë¥¼ ê¸°ëŒ€
        if len(X.shape) == 3:
            return X
        else:
            # 2D ë°°ì—´ì¸ ê²½ìš° ì‹œí€€ìŠ¤ ì°¨ì› ì¶”ê°€
            return X.reshape(X.shape[0], 1, -1)

    def transform_new_data(self, X: np.ndarray) -> np.ndarray:
        """ìƒˆë¡œìš´ ë°ì´í„° ë³€í™˜"""

        if not self.fitted:
            raise ValueError("ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ì •ê·œí™”
        X_scaled = self.scaler.transform(X)

        # ì‹œí€€ìŠ¤ ìƒì„±
        X_sequences = self._create_sequences(X_scaled)

        # ë‹¤ì¤‘ í•´ìƒë„ íŠ¹ì„± ì¶”ì¶œ
        X_multi_resolution = self._extract_multi_resolution_features(X_sequences)

        # Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ (ì¦ê°• ì œì™¸)
        X_selected, _ = self._apply_attention_selection(X_multi_resolution)

        # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
        X_final = self._format_for_tcn(X_selected)

        return X_final

    def get_temporal_patterns(self, X: np.ndarray) -> Dict[str, np.ndarray]:
        """ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„"""

        if not self.fitted:
            raise ValueError("ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ë³€í™˜
        X_transformed = self.transform_new_data(X)

        # íŒ¨í„´ ë¶„ì„
        patterns = {}

        # 1. ì‹œê³„ì—´ íŠ¸ë Œë“œ
        patterns["trend"] = np.mean(X_transformed, axis=0)

        # 2. ë³€ë™ì„±
        patterns["volatility"] = np.std(X_transformed, axis=0)

        # 3. ìê¸°ìƒê´€
        patterns["autocorrelation"] = []
        for i in range(X_transformed.shape[2]):
            feature_series = X_transformed[:, :, i].flatten()
            autocorr = np.correlate(feature_series, feature_series, mode="full")
            patterns["autocorrelation"].append(autocorr)

        patterns["autocorrelation"] = np.array(patterns["autocorrelation"])

        return patterns

    def get_attention_analysis(self, X: np.ndarray) -> Dict[str, Any]:
        """Attention ë¶„ì„"""

        if not self.fitted:
            raise ValueError("ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ì „ì²˜ë¦¬
        X_scaled = self.scaler.transform(X)
        X_sequences = self._create_sequences(X_scaled)
        X_multi_resolution = self._extract_multi_resolution_features(X_sequences)

        # Attention ê°€ì¤‘ì¹˜ ì¶”ì¶œ
        X_tensor = torch.FloatTensor(X_multi_resolution).to(self.device)

        self.attention_selector.eval()
        with torch.no_grad():
            _, attention_weights = self.attention_selector(X_tensor)
            feature_importance = self.attention_selector.get_feature_importance(
                X_tensor
            )

        analysis = {
            "attention_weights": attention_weights.cpu().numpy(),
            "feature_importance": feature_importance.cpu().numpy(),
            "top_features": torch.topk(
                feature_importance, k=min(20, len(feature_importance))
            )
            .indices.cpu()
            .numpy(),
        }

        return analysis

    def print_optimization_summary(self, metadata: Dict[str, Any]):
        """ìµœì í™” ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""

        print("=" * 60)
        print("â° TCN ìµœì í™” ê²°ê³¼")
        print("=" * 60)

        print(f"ğŸ“Š ì‹œê³„ì—´ êµ¬ì„±:")
        print(f"  â€¢ ì‹œí€€ìŠ¤ ê¸¸ì´: {metadata['sequence_length']}")
        print(f"  â€¢ ì…ë ¥ ì°¨ì›: {metadata['input_dim']}")
        print(f"  â€¢ ë‹¤ì¤‘ í•´ìƒë„ ìœˆë„ìš°: {metadata['multi_resolution_windows']}")
        print(f"  â€¢ Attention í—¤ë“œ: {metadata['attention_heads']}")

        print(f"\nğŸ”§ ì ìš©ëœ ìµœì í™” ê¸°ë²•:")
        print(
            f"  â€¢ ë‹¤ì¤‘ í•´ìƒë„ ìœˆë„ìš°: {len(metadata['multi_resolution_windows'])}ê°œ í•´ìƒë„"
        )
        print(f"  â€¢ ì‹œê³„ì—´ ì¦ê°•: {', '.join(metadata['augmentation_methods'])}")
        print(f"  â€¢ Attention ê¸°ë°˜ íŠ¹ì„± ì„ íƒ: {metadata['attention_heads']}í—¤ë“œ")
        print(f"  â€¢ GPU ê°€ì†: {'í™œì„±í™”' if self.device.type == 'cuda' else 'ë¹„í™œì„±í™”'}")

        print(f"\nğŸ“ˆ ì••ì¶• íš¨ìœ¨:")
        print(f"  â€¢ íŠ¹ì„± ì••ì¶•ë¥ : {metadata['compression_ratio']:.2f}x")

        print("=" * 60)
