"""
Enhanced Meta Weight Layer
ê°•í™”ëœ ë©”íƒ€ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ - ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµ, ì‹ ë¢°ë„ ê¸°ë°˜ ì•™ìƒë¸”, ROI ì¡°ì •
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import warnings

warnings.filterwarnings("ignore")

from ..utils.unified_logging import get_logger
from ..utils.memory_manager import MemoryManager
from ..utils.cuda_singleton_manager import CudaSingletonManager

logger = get_logger(__name__)


@dataclass
class MetaWeightConfig:
    """ë©”íƒ€ ê°€ì¤‘ì¹˜ ì„¤ì •"""

    num_models: int = 4  # LightGBM, AutoEncoder, TCN, RandomForest
    adaptation_rate: float = 0.01
    momentum: float = 0.9
    confidence_threshold: float = 0.7
    roi_weight: float = 0.3
    diversity_weight: float = 0.2
    performance_weight: float = 0.5
    device: str = "cuda"


class DynamicWeightLearner(nn.Module):
    """ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµê¸°"""

    def __init__(self, config: MetaWeightConfig):
        super().__init__()
        self.config = config
        self.num_models = config.num_models
        self.adaptation_rate = config.adaptation_rate
        self.momentum = config.momentum

        # ê°€ì¤‘ì¹˜ ë„¤íŠ¸ì›Œí¬
        self.weight_network = nn.Sequential(
            nn.Linear(self.num_models * 3, 64),  # ì„±ëŠ¥, ì‹ ë¢°ë„, ë‹¤ì–‘ì„± ë©”íŠ¸ë¦­
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, self.num_models),
            nn.Softmax(dim=-1),
        )

        # ì´ë™ í‰ê·  ê°€ì¤‘ì¹˜
        self.register_buffer(
            "moving_weights", torch.ones(self.num_models) / self.num_models
        )

    def forward(self, model_metrics: torch.Tensor) -> torch.Tensor:
        """
        Args:
            model_metrics: (batch_size, num_models, 3) - ì„±ëŠ¥, ì‹ ë¢°ë„, ë‹¤ì–‘ì„±
        Returns:
            weights: (batch_size, num_models) - ë™ì  ê°€ì¤‘ì¹˜
        """

        # ë©”íŠ¸ë¦­ í‰íƒ„í™”
        flattened_metrics = model_metrics.view(model_metrics.size(0), -1)

        # ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        dynamic_weights = self.weight_network(flattened_metrics)

        # ì´ë™ í‰ê·  ì—…ë°ì´íŠ¸
        batch_mean_weights = dynamic_weights.mean(dim=0)
        self.moving_weights = (
            self.momentum * self.moving_weights
            + (1 - self.momentum) * batch_mean_weights
        )

        return dynamic_weights

    def get_stable_weights(self) -> torch.Tensor:
        """ì•ˆì •í™”ëœ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        return self.moving_weights.clone()


class ConfidenceEstimator:
    """ì‹ ë¢°ë„ ì¶”ì •ê¸°"""

    def __init__(self, uncertainty_method: str = "monte_carlo_dropout"):
        self.uncertainty_method = uncertainty_method

    def estimate_confidence(
        self,
        model_predictions: Dict[str, np.ndarray],
        model_objects: Dict[str, Any] = None,
    ) -> Dict[str, float]:
        """
        ëª¨ë¸ë³„ ì‹ ë¢°ë„ ì¶”ì •

        Args:
            model_predictions: ëª¨ë¸ë³„ ì˜ˆì¸¡ ê²°ê³¼
            model_objects: ëª¨ë¸ ê°ì²´ë“¤ (MC Dropoutìš©)

        Returns:
            Dict[str, float]: ëª¨ë¸ë³„ ì‹ ë¢°ë„ ì ìˆ˜
        """

        confidence_scores = {}

        for model_name, predictions in model_predictions.items():
            if self.uncertainty_method == "monte_carlo_dropout":
                confidence = self._monte_carlo_confidence(
                    predictions, model_objects.get(model_name)
                )
            elif self.uncertainty_method == "prediction_variance":
                confidence = self._prediction_variance_confidence(predictions)
            elif self.uncertainty_method == "entropy_based":
                confidence = self._entropy_based_confidence(predictions)
            else:
                confidence = 0.5  # ê¸°ë³¸ê°’

            confidence_scores[model_name] = confidence

        return confidence_scores

    def _monte_carlo_confidence(self, predictions: np.ndarray, model: Any) -> float:
        """Monte Carlo Dropout ê¸°ë°˜ ì‹ ë¢°ë„"""

        if model is None:
            return 0.5

        try:
            # ë‹¤ì¤‘ ìƒ˜í”Œë§ (ëª¨ë¸ì´ dropoutì„ ì§€ì›í•˜ëŠ” ê²½ìš°)
            if hasattr(model, "enable_dropout"):
                model.enable_dropout()
                samples = []
                for _ in range(10):  # 10íšŒ ìƒ˜í”Œë§
                    sample_pred = model.predict(predictions)
                    samples.append(sample_pred)

                # ì˜ˆì¸¡ ë¶„ì‚° ê³„ì‚°
                samples = np.array(samples)
                prediction_variance = np.var(samples, axis=0)
                confidence = 1.0 / (1.0 + np.mean(prediction_variance))

                model.disable_dropout()
            else:
                # ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ€ê°’ì„ ì‹ ë¢°ë„ë¡œ ì‚¬ìš©
                if len(predictions.shape) > 1:
                    confidence = np.mean(np.max(predictions, axis=1))
                else:
                    confidence = 0.7  # ê¸°ë³¸ê°’

        except Exception as e:
            logger.warning(f"Monte Carlo ì‹ ë¢°ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            confidence = 0.5

        return float(confidence)

    def _prediction_variance_confidence(self, predictions: np.ndarray) -> float:
        """ì˜ˆì¸¡ ë¶„ì‚° ê¸°ë°˜ ì‹ ë¢°ë„"""

        if len(predictions.shape) > 1:
            # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì˜ˆì¸¡ì˜ ê²½ìš°
            prediction_variance = np.var(predictions, axis=1)
            confidence = 1.0 / (1.0 + np.mean(prediction_variance))
        else:
            # ë‹¨ì¼ ì˜ˆì¸¡ì˜ ê²½ìš°
            confidence = 1.0 / (1.0 + np.var(predictions))

        return float(confidence)

    def _entropy_based_confidence(self, predictions: np.ndarray) -> float:
        """ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ì‹ ë¢°ë„"""

        if len(predictions.shape) > 1:
            # í™•ë¥  ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            entropy = -np.sum(predictions * np.log(predictions + 1e-8), axis=1)
            max_entropy = np.log(predictions.shape[1])
            confidence = 1.0 - np.mean(entropy) / max_entropy
        else:
            # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš°
            prob = np.clip(predictions, 0.01, 0.99)
            entropy = -prob * np.log(prob) - (1 - prob) * np.log(1 - prob)
            confidence = 1.0 - np.mean(entropy) / np.log(2)

        return float(confidence)


class ROIBasedWeightAdjuster:
    """ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •ê¸°"""

    def __init__(self, target_metric: str = "profit_ratio"):
        self.target_metric = target_metric
        self.roi_history = {}
        self.performance_history = {}

    def calculate_roi_weights(
        self,
        model_predictions: Dict[str, np.ndarray],
        actual_results: Optional[np.ndarray] = None,
        historical_roi: Optional[Dict[str, List[float]]] = None,
    ) -> Dict[str, float]:
        """
        ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°

        Args:
            model_predictions: ëª¨ë¸ë³„ ì˜ˆì¸¡ ê²°ê³¼
            actual_results: ì‹¤ì œ ê²°ê³¼ (ì„ íƒì‚¬í•­)
            historical_roi: ëª¨ë¸ë³„ ê³¼ê±° ROI ë°ì´í„°

        Returns:
            Dict[str, float]: ëª¨ë¸ë³„ ROI ê°€ì¤‘ì¹˜
        """

        roi_weights = {}

        # ê³¼ê±° ROI ë°ì´í„° ì—…ë°ì´íŠ¸
        if historical_roi:
            self.roi_history.update(historical_roi)

        # ê° ëª¨ë¸ì˜ ROI ì„±ëŠ¥ í‰ê°€
        for model_name, predictions in model_predictions.items():
            if model_name in self.roi_history and self.roi_history[model_name]:
                # ê³¼ê±° ROI í‰ê·  ê³„ì‚°
                avg_roi = np.mean(self.roi_history[model_name][-10:])  # ìµœê·¼ 10íšŒ
                roi_weights[model_name] = max(0.1, avg_roi)  # ìµœì†Œ 0.1 ë³´ì¥
            else:
                # ê¸°ë³¸ ê°€ì¤‘ì¹˜
                roi_weights[model_name] = 0.5

        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(roi_weights.values())
        if total_weight > 0:
            roi_weights = {k: v / total_weight for k, v in roi_weights.items()}

        return roi_weights

    def update_roi_history(self, model_name: str, roi_value: float):
        """ROI íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""

        if model_name not in self.roi_history:
            self.roi_history[model_name] = []

        self.roi_history[model_name].append(roi_value)

        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœëŒ€ 50ê°œ)
        if len(self.roi_history[model_name]) > 50:
            self.roi_history[model_name] = self.roi_history[model_name][-50:]

    def get_roi_analysis(self) -> Dict[str, Any]:
        """ROI ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""

        analysis = {}

        for model_name, roi_values in self.roi_history.items():
            if roi_values:
                analysis[model_name] = {
                    "mean_roi": np.mean(roi_values),
                    "std_roi": np.std(roi_values),
                    "max_roi": np.max(roi_values),
                    "min_roi": np.min(roi_values),
                    "recent_trend": (
                        np.mean(roi_values[-5:])
                        if len(roi_values) >= 5
                        else np.mean(roi_values)
                    ),
                    "stability": 1.0 / (1.0 + np.std(roi_values)),
                }

        return analysis


class EnhancedMetaWeightLayer:
    """ê°•í™”ëœ ë©”íƒ€ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = get_logger(__name__)
        self.memory_manager = MemoryManager()
        self.cuda_manager = CudaSingletonManager()

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device(
            "cuda" if self.cuda_manager.is_available() else "cpu"
        )

        # ë©”íƒ€ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.meta_config = MetaWeightConfig(
            num_models=config.get("num_models", 4),
            adaptation_rate=config.get("adaptation_rate", 0.01),
            momentum=config.get("momentum", 0.9),
            confidence_threshold=config.get("confidence_threshold", 0.7),
            roi_weight=config.get("roi_weight", 0.3),
            diversity_weight=config.get("diversity_weight", 0.2),
            performance_weight=config.get("performance_weight", 0.5),
            device=str(self.device),
        )

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.dynamic_weights = DynamicWeightLearner(self.meta_config).to(self.device)
        self.confidence_estimator = ConfidenceEstimator(
            uncertainty_method=config.get("uncertainty_method", "monte_carlo_dropout")
        )
        self.roi_adjuster = ROIBasedWeightAdjuster(
            target_metric=config.get("target_metric", "profit_ratio")
        )

        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer = optim.Adam(
            self.dynamic_weights.parameters(), lr=self.meta_config.adaptation_rate
        )

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
        self.performance_history = []
        self.model_names = ["lightgbm", "autoencoder", "tcn", "randomforest"]

    def compute_ensemble_prediction(
        self,
        model_predictions: Dict[str, np.ndarray],
        model_objects: Optional[Dict[str, Any]] = None,
        historical_roi: Optional[Dict[str, List[float]]] = None,
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚°

        Args:
            model_predictions: ëª¨ë¸ë³„ ì˜ˆì¸¡ ê²°ê³¼
            model_objects: ëª¨ë¸ ê°ì²´ë“¤ (ì‹ ë¢°ë„ ê³„ì‚°ìš©)
            historical_roi: ëª¨ë¸ë³„ ê³¼ê±° ROI ë°ì´í„°

        Returns:
            Tuple[np.ndarray, Dict]: ì•™ìƒë¸” ì˜ˆì¸¡ê³¼ ë©”íƒ€ë°ì´í„°
        """

        try:
            self.logger.info("ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚° ì‹œì‘")

            with self.memory_manager.get_context("meta_weight_ensemble"):
                # 1. ì‹ ë¢°ë„ ì¶”ì •
                confidence_scores = self.confidence_estimator.estimate_confidence(
                    model_predictions, model_objects
                )

                # 2. ROI ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
                roi_weights = self.roi_adjuster.calculate_roi_weights(
                    model_predictions, historical_roi=historical_roi
                )

                # 3. ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°
                diversity_scores = self._calculate_diversity_scores(model_predictions)

                # 4. ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
                performance_scores = self._calculate_performance_scores(
                    model_predictions
                )

                # 5. ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
                dynamic_weights = self._compute_dynamic_weights(
                    performance_scores, confidence_scores, diversity_scores
                )

                # 6. ìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡
                ensemble_prediction = self._weighted_ensemble_prediction(
                    model_predictions, dynamic_weights
                )

                # ë©”íƒ€ë°ì´í„° ìƒì„±
                metadata = {
                    "dynamic_weights": dynamic_weights,
                    "confidence_scores": confidence_scores,
                    "roi_weights": roi_weights,
                    "diversity_scores": diversity_scores,
                    "performance_scores": performance_scores,
                    "ensemble_confidence": np.mean(list(confidence_scores.values())),
                    "weight_entropy": self._calculate_weight_entropy(dynamic_weights),
                }

                self.logger.info("ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚° ì™„ë£Œ")

                return ensemble_prediction, metadata

        except Exception as e:
            self.logger.error(f"ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def _calculate_diversity_scores(
        self, model_predictions: Dict[str, np.ndarray]
    ) -> Dict[str, float]:
        """ëª¨ë¸ ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°"""

        diversity_scores = {}
        predictions_array = np.array(list(model_predictions.values()))

        for i, model_name in enumerate(model_predictions.keys()):
            # ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
            other_predictions = np.delete(predictions_array, i, axis=0)
            correlations = []

            for other_pred in other_predictions:
                if len(model_predictions[model_name].shape) > 1:
                    # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì˜ˆì¸¡
                    corr = np.corrcoef(
                        model_predictions[model_name].flatten(), other_pred.flatten()
                    )[0, 1]
                else:
                    # ë‹¨ì¼ ì˜ˆì¸¡
                    corr = np.corrcoef(model_predictions[model_name], other_pred)[0, 1]

                if not np.isnan(corr):
                    correlations.append(abs(corr))

            # ë‹¤ì–‘ì„± ì ìˆ˜ = 1 - í‰ê·  ìƒê´€ê´€ê³„
            diversity_scores[model_name] = (
                1.0 - np.mean(correlations) if correlations else 0.5
            )

        return diversity_scores

    def _calculate_performance_scores(
        self, model_predictions: Dict[str, np.ndarray]
    ) -> Dict[str, float]:
        """ëª¨ë¸ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (ê³¼ê±° ì„±ëŠ¥ ê¸°ë°˜)"""

        performance_scores = {}

        # ê³¼ê±° ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
        if self.performance_history:
            latest_performance = self.performance_history[-1]
            for model_name in model_predictions.keys():
                performance_scores[model_name] = latest_performance.get(model_name, 0.5)
        else:
            # ê¸°ë³¸ ì„±ëŠ¥ ì ìˆ˜
            for model_name in model_predictions.keys():
                performance_scores[model_name] = 0.5

        return performance_scores

    def _compute_dynamic_weights(
        self,
        performance_scores: Dict[str, float],
        confidence_scores: Dict[str, float],
        diversity_scores: Dict[str, float],
    ) -> Dict[str, float]:
        """ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°"""

        # ë©”íŠ¸ë¦­ í…ì„œ ìƒì„±
        model_metrics = []
        for model_name in self.model_names:
            if model_name in performance_scores:
                metrics = [
                    performance_scores.get(model_name, 0.5),
                    confidence_scores.get(model_name, 0.5),
                    diversity_scores.get(model_name, 0.5),
                ]
                model_metrics.append(metrics)
            else:
                model_metrics.append([0.5, 0.5, 0.5])

        model_metrics = torch.FloatTensor([model_metrics]).to(self.device)

        # ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        self.dynamic_weights.eval()
        with torch.no_grad():
            weights_tensor = self.dynamic_weights(model_metrics)
            weights_array = weights_tensor.cpu().numpy().flatten()

        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
        dynamic_weights = {}
        for i, model_name in enumerate(self.model_names):
            if i < len(weights_array):
                dynamic_weights[model_name] = float(weights_array[i])
            else:
                dynamic_weights[model_name] = 0.25  # ê¸°ë³¸ê°’

        return dynamic_weights

    def _weighted_ensemble_prediction(
        self, model_predictions: Dict[str, np.ndarray], weights: Dict[str, float]
    ) -> np.ndarray:
        """ê°€ì¤‘ ì•™ìƒë¸” ì˜ˆì¸¡"""

        ensemble_prediction = None
        total_weight = 0.0

        for model_name, predictions in model_predictions.items():
            weight = weights.get(model_name, 0.0)

            if weight > 0:
                if ensemble_prediction is None:
                    ensemble_prediction = weight * predictions
                else:
                    ensemble_prediction += weight * predictions
                total_weight += weight

        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        if total_weight > 0:
            ensemble_prediction /= total_weight

        return ensemble_prediction

    def _calculate_weight_entropy(self, weights: Dict[str, float]) -> float:
        """ê°€ì¤‘ì¹˜ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë‹¤ì–‘ì„± ì¸¡ì •)"""

        weight_values = np.array(list(weights.values()))
        weight_values = weight_values / np.sum(weight_values)  # ì •ê·œí™”

        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        entropy = -np.sum(weight_values * np.log(weight_values + 1e-8))
        max_entropy = np.log(len(weight_values))

        return entropy / max_entropy  # ì •ê·œí™”ëœ ì—”íŠ¸ë¡œí”¼

    def update_performance_history(self, model_performance: Dict[str, float]):
        """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""

        self.performance_history.append(model_performance.copy())

        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]

    def train_dynamic_weights(
        self,
        model_predictions: Dict[str, np.ndarray],
        actual_results: np.ndarray,
        epochs: int = 10,
    ):
        """ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµ"""

        self.logger.info("ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµ ì‹œì‘")

        # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        performance_scores = {}
        for model_name, predictions in model_predictions.items():
            if len(predictions.shape) > 1:
                # ë‹¤ì¤‘ í´ë˜ìŠ¤
                pred_labels = np.argmax(predictions, axis=1)
            else:
                # ì´ì§„ ë¶„ë¥˜
                pred_labels = (predictions > 0.5).astype(int)

            accuracy = accuracy_score(actual_results, pred_labels)
            performance_scores[model_name] = accuracy

        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.update_performance_history(performance_scores)

        # ì‹ ë¢°ë„ ë° ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°
        confidence_scores = self.confidence_estimator.estimate_confidence(
            model_predictions
        )
        diversity_scores = self._calculate_diversity_scores(model_predictions)

        # í•™ìŠµ ë£¨í”„
        for epoch in range(epochs):
            self.optimizer.zero_grad()

            # ë©”íŠ¸ë¦­ í…ì„œ ìƒì„±
            model_metrics = []
            for model_name in self.model_names:
                metrics = [
                    performance_scores.get(model_name, 0.5),
                    confidence_scores.get(model_name, 0.5),
                    diversity_scores.get(model_name, 0.5),
                ]
                model_metrics.append(metrics)

            model_metrics = torch.FloatTensor([model_metrics]).to(self.device)

            # ê°€ì¤‘ì¹˜ ì˜ˆì¸¡
            predicted_weights = self.dynamic_weights(model_metrics)

            # ì†ì‹¤ ê³„ì‚° (ì„±ëŠ¥ ê¸°ë°˜)
            target_weights = torch.FloatTensor([list(performance_scores.values())]).to(
                self.device
            )
            target_weights = torch.softmax(target_weights, dim=-1)

            loss = nn.functional.kl_div(
                torch.log(predicted_weights + 1e-8),
                target_weights,
                reduction="batchmean",
            )

            # ì—­ì „íŒŒ
            loss.backward()
            self.optimizer.step()

            if epoch % 5 == 0:
                self.logger.info(f"Epoch {epoch}: Loss = {loss.item():.4f}")

        self.logger.info("ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµ ì™„ë£Œ")

    def get_weight_analysis(self) -> Dict[str, Any]:
        """ê°€ì¤‘ì¹˜ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""

        # í˜„ì¬ ì•ˆì •í™”ëœ ê°€ì¤‘ì¹˜
        stable_weights = self.dynamic_weights.get_stable_weights().cpu().numpy()

        # ROI ë¶„ì„
        roi_analysis = self.roi_adjuster.get_roi_analysis()

        analysis = {
            "stable_weights": {
                model_name: float(weight)
                for model_name, weight in zip(self.model_names, stable_weights)
            },
            "roi_analysis": roi_analysis,
            "performance_trend": (
                self.performance_history[-10:]
                if len(self.performance_history) >= 10
                else self.performance_history
            ),
            "weight_stability": float(1.0 / (1.0 + np.std(stable_weights))),
            "ensemble_diversity": float(
                self._calculate_weight_entropy({"weights": stable_weights})
            ),
        }

        return analysis

    def print_optimization_summary(self, metadata: Dict[str, Any]):
        """ìµœì í™” ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""

        print("=" * 60)
        print("âš–ï¸  Meta Weight Layer ìµœì í™” ê²°ê³¼")
        print("=" * 60)

        print(f"ğŸ“Š ë™ì  ê°€ì¤‘ì¹˜:")
        for model_name, weight in metadata["dynamic_weights"].items():
            print(f"  â€¢ {model_name}: {weight:.4f}")

        print(f"\nğŸ“ˆ ì‹ ë¢°ë„ ì ìˆ˜:")
        for model_name, confidence in metadata["confidence_scores"].items():
            print(f"  â€¢ {model_name}: {confidence:.4f}")

        print(f"\nğŸ”§ ì ìš©ëœ ìµœì í™” ê¸°ë²•:")
        print(f"  â€¢ ë™ì  ê°€ì¤‘ì¹˜ í•™ìŠµ: ì ì‘ë¥  {self.meta_config.adaptation_rate}")
        print(f"  â€¢ ì‹ ë¢°ë„ ê¸°ë°˜ ì•™ìƒë¸”: {self.confidence_estimator.uncertainty_method}")
        print(f"  â€¢ ROI ê¸°ë°˜ ì¡°ì •: {self.roi_adjuster.target_metric}")
        print(f"  â€¢ GPU ê°€ì†: {'í™œì„±í™”' if self.device.type == 'cuda' else 'ë¹„í™œì„±í™”'}")

        print(f"\nğŸ“Š ì•™ìƒë¸” ë©”íŠ¸ë¦­:")
        print(f"  â€¢ ì•™ìƒë¸” ì‹ ë¢°ë„: {metadata['ensemble_confidence']:.4f}")
        print(f"  â€¢ ê°€ì¤‘ì¹˜ ì—”íŠ¸ë¡œí”¼: {metadata['weight_entropy']:.4f}")

        print("=" * 60)
