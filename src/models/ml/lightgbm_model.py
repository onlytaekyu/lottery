"""
LightGBM ëª¨ë¸

ì´ ëª¨ë“ˆì€ LightGBM ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë¡œë˜ ë²ˆí˜¸ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
feature_vector_full.npy ë˜ëŠ” í•„í„°ë§ëœ ë²¡í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

âœ… v2.0 ì—…ë°ì´íŠ¸: src/utils í†µí•© ì‹œìŠ¤í…œ ì ìš©
- ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” (get_enhanced_process_pool)
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì› (get_unified_async_manager)
- GPU ìµœì í™” ê°•í™” (get_cuda_optimizer)
- í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ (get_unified_memory_manager)
- ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ
"""

import os
import json
import numpy as np
import lightgbm as lgb
from typing import Dict, List, Any, Optional, Tuple
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
from sklearn.metrics import log_loss
try:
    from scipy.sparse import spmatrix
    SCIPY_SPARSE_AVAILABLE = True
except ImportError:
    spmatrix = None
    SCIPY_SPARSE_AVAILABLE = False

# âœ… src/utils í†µí•© ì‹œìŠ¤í…œ í™œìš©
from ...utils.unified_logging import get_logger
from ...utils import (
    get_unified_memory_manager,
    get_cuda_optimizer,
    get_enhanced_process_pool,
    get_unified_async_manager,
    get_pattern_filter
)

# 3. í”„ë¡œì íŠ¸ ë‚´ë¶€
from ..base_model import BaseModel

logger = get_logger(__name__)


@dataclass
class LightGBMOptimizationConfig:
    """LightGBM ìµœì í™” ì„¤ì •"""
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    enable_parallel_training: bool = True
    parallel_workers: int = 4
    lgb_n_jobs: int = -1  # LightGBM ë‚´ë¶€ ë³‘ë ¬ ì²˜ë¦¬
    
    # ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì •
    enable_async_processing: bool = True
    async_batch_size: int = 1000
    
    # GPU ìµœì í™” ì„¤ì •
    auto_gpu_optimization: bool = True
    gpu_memory_fraction: float = 0.8
    use_gpu_tree_learner: bool = True
    
    # ìºì‹œ ì„¤ì •
    enable_smart_caching: bool = True
    cache_feature_vectors: bool = True
    cache_predictions: bool = True
    cache_ttl: int = 3600  # 1ì‹œê°„
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    auto_memory_management: bool = True
    memory_efficient_training: bool = True


class LightGBMModel(BaseModel):
    """
    ğŸš€ LightGBM ê¸°ë°˜ ë¡œë˜ ë²ˆí˜¸ ì˜ˆì¸¡ ëª¨ë¸ (v2.0)

    src/utils í†µí•© ì‹œìŠ¤í…œ ê¸°ë°˜ ê³ ì„±ëŠ¥ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…:
    - ë³‘ë ¬ í›ˆë ¨ ë° ì˜ˆì¸¡
    - ë¹„ë™ê¸° ë°ì´í„° ì²˜ë¦¬
    - GPU ìµœì í™” ê°•í™”
    - ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬
    - ì§€ëŠ¥í˜• ìºì‹œ ì‹œìŠ¤í…œ
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        LightGBM ëª¨ë¸ ì´ˆê¸°í™” (í†µí•© ì‹œìŠ¤í…œ ì ìš©)

        Args:
            config: ëª¨ë¸ ì„¤ì •
        """
        super().__init__(config)

        # ëª¨ë¸ ì´ë¦„
        self.model_name = "LightGBMModel"

        # âœ… ìµœì í™” ì„¤ì • ì´ˆê¸°í™”
        opt_config = config.get("optimization", {}) if config else {}
        self.opt_config = LightGBMOptimizationConfig(
            enable_parallel_training=opt_config.get("enable_parallel_training", True),
            parallel_workers=opt_config.get("parallel_workers", 4),
            lgb_n_jobs=opt_config.get("lgb_n_jobs", -1),
            enable_async_processing=opt_config.get("enable_async_processing", True),
            async_batch_size=opt_config.get("async_batch_size", 1000),
            auto_gpu_optimization=opt_config.get("auto_gpu_optimization", True),
            gpu_memory_fraction=opt_config.get("gpu_memory_fraction", 0.8),
            use_gpu_tree_learner=opt_config.get("use_gpu_tree_learner", True),
            enable_smart_caching=opt_config.get("enable_smart_caching", True),
            cache_feature_vectors=opt_config.get("cache_feature_vectors", True),
            cache_predictions=opt_config.get("cache_predictions", True),
            cache_ttl=opt_config.get("cache_ttl", 3600),
            auto_memory_management=opt_config.get("auto_memory_management", True),
            memory_efficient_training=opt_config.get("memory_efficient_training", True)
        )

        # âœ… src/utils í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self.memory_mgr = get_unified_memory_manager()
            self.cuda_opt = get_cuda_optimizer()
            self.process_pool = get_enhanced_process_pool()
            self.async_mgr = get_unified_async_manager()
            self.pattern_filter = get_pattern_filter()
            self._unified_system_available = True
            logger.info("âœ… LightGBM í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
            self._unified_system_available = False
            self._init_fallback_systems()

        # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ
        if self.opt_config.enable_smart_caching and self._unified_system_available:
            self.smart_cache = True
            self.feature_cache = {}  # íŠ¹ì„± ë²¡í„° ìºì‹œ
            self.prediction_cache = {}  # ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ
            self.model_cache = {}  # ëª¨ë¸ ìºì‹œ
        else:
            self.smart_cache = False
            self.feature_cache = {}
            self.prediction_cache = {}

        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì • (ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”)
        self.params = {
            "objective": "regression",
            "metric": "rmse",
            "boosting_type": "gbdt",
            "num_leaves": 31,
            "learning_rate": 0.05,
            "feature_fraction": 0.9,
            "bagging_fraction": 0.8,
            "bagging_freq": 5,
            "verbose": -1,
            "random_state": 42,
            # âœ… ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
            "n_jobs": self.opt_config.lgb_n_jobs,
            "num_threads": self.opt_config.parallel_workers if self.opt_config.enable_parallel_training else 1,
        }

        # 3ìë¦¬ ëª¨ë“œ ì „ìš© íŒŒë¼ë¯¸í„° (ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”)
        self.three_digit_params = {
            "objective": "multiclass",
            "num_class": 14190,  # C(45,3) = 45*44*43/(3*2*1)
            "metric": "multi_logloss",
            "boosting_type": "gbdt",
            "num_leaves": 63,
            "learning_rate": 0.03,
            "feature_fraction": 0.8,
            "bagging_fraction": 0.7,
            "bagging_freq": 3,
            "verbose": -1,
            "random_state": 42,
            # âœ… ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
            "n_jobs": self.opt_config.lgb_n_jobs,
            "num_threads": self.opt_config.parallel_workers if self.opt_config.enable_parallel_training else 1,
        }

        # ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        if config and "lightgbm" in config:
            self.params.update(config["lightgbm"])

        # 3ìë¦¬ ëª¨ë“œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        if config and "lightgbm_3digit" in config:
            self.three_digit_params.update(config["lightgbm_3digit"])

        # âœ… GPU ì„¤ì • ìµœì í™” (í†µí•© ì‹œìŠ¤í…œ)
        self._setup_advanced_gpu_acceleration(config)

        # íŠ¹ì„± ì´ë¦„ ì €ì¥
        self.feature_names = None

        logger.info(f"âœ… LightGBM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (v2.0)")
        logger.info(f"ğŸš€ ìµœì í™” í™œì„±í™”: ë³‘ë ¬={self.opt_config.enable_parallel_training}, "
                   f"ë¹„ë™ê¸°={self.opt_config.enable_async_processing}, "
                   f"ìŠ¤ë§ˆíŠ¸ìºì‹œ={self.opt_config.enable_smart_caching}")
        logger.info(f"GPU ì‚¬ìš©: {self.params.get('device_type', 'cpu')}")
        logger.info(f"ì¥ì¹˜: {self.device} (GPU ì‚¬ìš© ê°€ëŠ¥: {self.device_manager.gpu_available})")

    def _init_fallback_systems(self):
        """í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # ê¸°ë³¸ ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=self.opt_config.parallel_workers)
        logger.info("ê¸°ë³¸ ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±")

    def _setup_advanced_gpu_acceleration(self, config: Optional[Dict[str, Any]] = None):
        """
        âœ… ê³ ê¸‰ GPU ê°€ì† ì„¤ì • (í†µí•© ì‹œìŠ¤í…œ ì ìš©)

        Args:
            config: ëª¨ë¸ ì„¤ì •
        """
        try:
            # GPU ì‚¬ìš© ì„¤ì • í™•ì¸
            use_gpu = False
            if config:
                use_gpu = config.get("use_gpu", False)
            
            # GPU ê°€ìš©ì„± ìë™ ì²´í¬
            if use_gpu and self.device_manager.gpu_available:
                # âœ… CUDA ìµœì í™”ê¸° í™œìš© (í†µí•© ì‹œìŠ¤í…œ)
                if self._unified_system_available and self.cuda_opt:
                    self.cuda_opt.set_tf32_enabled(True)
                    self.cuda_opt.set_memory_pool_enabled(True)
                    if self.opt_config.use_gpu_tree_learner:
                        self.cuda_opt.optimize_for_inference(True)
                    logger.info("ğŸš€ ê³ ê¸‰ CUDA ìµœì í™” í™œì„±í™”")
                
                # LightGBM GPU ì§€ì› í™•ì¸ ë° ì„¤ì •
                try:
                    # GPU íŒŒë¼ë¯¸í„° ì ìš©
                    gpu_params = {
                        "device_type": "gpu",
                        "gpu_platform_id": 0,
                        "gpu_device_id": 0,
                        "gpu_use_dp": True,  # double precision ì‚¬ìš©
                        "max_bin": 63,       # GPUì—ì„œ ê¶Œì¥ë˜ëŠ” max_bin
                    }
                    
                    # âœ… ê³ ê¸‰ GPU ìµœì í™” ì„¤ì •
                    if self.opt_config.auto_gpu_optimization:
                        memory_info = self.device_manager.check_memory_usage()
                        if memory_info.get("gpu_available", False):
                            total_gpu_memory = memory_info.get("total_gb", 8.0)
                            
                            # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë™ì  ì„¤ì •
                            if total_gpu_memory >= 16.0:  # ê³ ê¸‰ GPU
                                gpu_params.update({
                                    "max_bin": 255,
                                    "num_leaves": min(255, self.params.get("num_leaves", 31) * 2),
                                })
                                logger.info("ğŸ”¥ ê³ ì„±ëŠ¥ GPU ëª¨ë“œ í™œì„±í™”")
                            elif total_gpu_memory >= 8.0:  # ì¤‘ê¸‰ GPU
                                gpu_params.update({
                                    "max_bin": 127,
                                    "num_leaves": min(127, self.params.get("num_leaves", 31)),
                                })
                                logger.info("âš¡ í‘œì¤€ GPU ëª¨ë“œ í™œì„±í™”")
                    
                    self.params.update(gpu_params)
                    self.three_digit_params.update(gpu_params)
                    
                    logger.info("âœ… LightGBM ê³ ê¸‰ GPU ê°€ì† í™œì„±í™”")
                    
                    # âœ… GPU ë©”ëª¨ë¦¬ í’€ë§ ì„¤ì •
                    if self._unified_system_available and self.memory_mgr:
                        gpu_memory_fraction = self.opt_config.gpu_memory_fraction
                        logger.info(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì œí•œ: {gpu_memory_fraction*100:.0f}%")
                        
                except Exception as e:
                    logger.warning(f"LightGBM GPU ì„¤ì • ì‹¤íŒ¨, CPUë¡œ fallback: {e}")
                    self._fallback_to_cpu()
                    
            else:
                if use_gpu and not self.device_manager.gpu_available:
                    logger.warning("GPU ì‚¬ìš©ì´ ìš”ì²­ë˜ì—ˆì§€ë§Œ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ fallback")
                self._fallback_to_cpu()
                
        except Exception as e:
            logger.error(f"GPU ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ, CPUë¡œ fallback: {e}")
            self._fallback_to_cpu()

    def _fallback_to_cpu(self):
        """CPUë¡œ fallback ì²˜ë¦¬ (ìµœì í™”ëœ)"""
        self.params["device_type"] = "cpu"
        self.three_digit_params["device_type"] = "cpu"
        
        # âœ… CPU ìµœì í™” ì„¤ì •
        if self.opt_config.enable_parallel_training:
            cpu_threads = min(self.opt_config.parallel_workers, os.cpu_count() or 4)
            self.params.update({
                "n_jobs": cpu_threads,
                "num_threads": cpu_threads,
                "force_row_wise": True,  # CPU ìµœì í™”
            })
            self.three_digit_params.update({
                "n_jobs": cpu_threads,
                "num_threads": cpu_threads,
                "force_row_wise": True,
            })
            logger.info(f"ğŸ”§ CPU ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”: {cpu_threads} ìŠ¤ë ˆë“œ")
        
        # GPU ì „ìš© íŒŒë¼ë¯¸í„° ì œê±°
        gpu_params = ["gpu_platform_id", "gpu_device_id", "gpu_use_dp"]
        for param in gpu_params:
            self.params.pop(param, None)
            self.three_digit_params.pop(param, None)
            
        logger.info("CPU ëª¨ë“œë¡œ ì„¤ì • ì™„ë£Œ")

    async def _check_gpu_memory_async(self, data_size: int) -> bool:
        """
        ğŸš€ ë¹„ë™ê¸° GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ì„± í™•ì¸

        Args:
            data_size: ë°ì´í„° í¬ê¸° (ëŒ€ëµì ì¸ ë°”ì´íŠ¸ ìˆ˜)

        Returns:
            GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
        """
        if self.params.get("device_type") != "gpu":
            return True
            
        # âœ… í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ì í™œìš©
        if self._unified_system_available and self.memory_mgr:
            try:
                memory_stats = await self.async_mgr.run_in_thread(
                    self.memory_mgr.get_memory_status
                )
                gpu_util = memory_stats.get("gpu_utilization", 0.5)
                
                # ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ í• ë‹¹ ê°€ëŠ¥ì„± ì²´í¬
                (data_size * 4) / (1024**3)
                memory_limit = self.opt_config.gpu_memory_fraction
                
                if gpu_util > memory_limit:
                    logger.warning(
                        f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {gpu_util*100:.1f}% > {memory_limit*100:.0f}%, "
                        f"CPUë¡œ fallback"
                    )
                    await self.async_mgr.run_in_thread(self._fallback_to_cpu)
                    return False
                    
                return True
                
            except Exception as e:
                logger.warning(f"ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì²´í¬ ì‹¤íŒ¨: {e}")
                return self._check_gpu_memory_before_training(data_size)
        else:
            # í´ë°±: ê¸°ì¡´ ë°©ì‹
            return self._check_gpu_memory_before_training(data_size)

    def _check_gpu_memory_before_training(self, data_size: int) -> bool:
        """
        í›ˆë ¨ ì „ GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ì„± í™•ì¸ (ê¸°ì¡´ ë°©ì‹)

        Args:
            data_size: ë°ì´í„° í¬ê¸° (ëŒ€ëµì ì¸ ë°”ì´íŠ¸ ìˆ˜)

        Returns:
            GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
        """
        if self.params.get("device_type") != "gpu":
            return True
            
        memory_info = self.device_manager.check_memory_usage()
        if not memory_info.get("gpu_available", False):
            return False
            
        # í•„ìš”í•œ ë©”ëª¨ë¦¬ ì¶”ì • (ë°ì´í„° í¬ê¸°ì˜ 3-4ë°°)
        estimated_memory_gb = (data_size * 4) / (1024**3)
        available_memory_gb = memory_info.get("total_gb", 0) - memory_info.get("allocated_gb", 0)
        memory_limit = self.opt_config.gpu_memory_fraction
        
        if estimated_memory_gb > available_memory_gb * memory_limit:
            logger.warning(
                f"GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜ˆìƒ: í•„ìš”={estimated_memory_gb:.1f}GB, "
                f"ì‚¬ìš© ê°€ëŠ¥={available_memory_gb:.1f}GB, CPUë¡œ fallback"
            )
            self._fallback_to_cpu()
            return False
            
        return True

    def get_optimal_batch_size(self, data_size: int) -> int:
        """
        ğŸš€ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° (í†µí•© ì‹œìŠ¤í…œ í™œìš©)
        
        Args:
            data_size: ì²˜ë¦¬í•  ë°ì´í„° í¬ê¸°
            
        Returns:
            ìµœì  ë°°ì¹˜ í¬ê¸°
        """
        if self._unified_system_available and self.memory_mgr:
            try:
                memory_stats = self.memory_mgr.get_memory_status()
                
                if self.params.get("device_type") == "gpu":
                    gpu_util = memory_stats.get("gpu_utilization", 0.5)
                    if gpu_util < 0.3:
                        return min(self.opt_config.async_batch_size * 2, data_size)
                    elif gpu_util < 0.7:
                        return min(self.opt_config.async_batch_size, data_size)
                    else:
                        return min(self.opt_config.async_batch_size // 2, data_size)
                else:
                    cpu_util = memory_stats.get("cpu_utilization", 0.5)
                    if cpu_util < 0.3:
                        return min(self.opt_config.async_batch_size, data_size)
                    else:
                        return min(self.opt_config.async_batch_size // 2, data_size)
                        
            except Exception as e:
                logger.debug(f"ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
        return min(self.opt_config.async_batch_size, data_size)

    def get_performance_stats(self) -> Dict[str, Any]:
        """
        ğŸš€ ì„±ëŠ¥ í†µê³„ ë°˜í™˜ (í†µí•© ì‹œìŠ¤í…œ ì •ë³´ í¬í•¨)
        """
        stats = {
            "model_type": self.model_name,
            "unified_system_available": self._unified_system_available,
            "optimization_config": {
                "parallel_training": self.opt_config.enable_parallel_training,
                "async_processing": self.opt_config.enable_async_processing,
                "smart_caching": self.opt_config.enable_smart_caching,
                "gpu_optimization": self.opt_config.auto_gpu_optimization,
                "parallel_workers": self.opt_config.parallel_workers,
                "lgb_n_jobs": self.opt_config.lgb_n_jobs,
            },
            "device_info": {
                "device_type": self.params.get("device_type", "cpu"),
                "gpu_available": self.device_manager.gpu_available,
                "using_gpu": self.params.get("device_type") == "gpu",
            },
            "cache_stats": {
                "smart_cache_enabled": self.smart_cache,
                "feature_cache_size": len(self.feature_cache),
                "prediction_cache_size": len(self.prediction_cache),
            },
            "model_info": {
                "is_trained": self.is_trained,
                "feature_count": len(self.feature_names) if self.feature_names else 0,
            }
        }
        
        # í†µí•© ì‹œìŠ¤í…œ í†µê³„
        if self._unified_system_available:
            if self.memory_mgr:
                try:
                    stats["memory_performance"] = self.memory_mgr.get_performance_metrics()
                except Exception as e:
                    logger.debug(f"ë©”ëª¨ë¦¬ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            if self.cuda_opt:
                try:
                    stats["cuda_optimization"] = self.cuda_opt.get_optimization_stats()
                except Exception as e:
                    logger.debug(f"CUDA ìµœì í™” í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return stats

    def fit(self, X: np.ndarray, y: np.ndarray, **kwargs) -> Dict[str, Any]:
        """
        LightGBM ëª¨ë¸ í•™ìŠµ (GPU ìµœì í™”)

        Args:
            X: íŠ¹ì„± ë²¡í„°
            y: íƒ€ê²Ÿ ì ìˆ˜
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ (eval_set, early_stopping_rounds ë“±)

        Returns:
            í•™ìŠµ ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„°
        """
        # ë¡œê¹…
        logger.info(f"LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘: X í˜•íƒœ={X.shape}, y í˜•íƒœ={y.shape}")

        # âœ… GPU ë©”ëª¨ë¦¬ ì²´í¬ (ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›)
        data_size = X.nbytes + y.nbytes
        if self.opt_config.enable_async_processing and self._unified_system_available:
            try:
                # ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì²´í¬
                import asyncio
                memory_ok = asyncio.run(self._check_gpu_memory_async(data_size))
                if not memory_ok:
                    logger.warning("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ CPU ëª¨ë“œë¡œ ì „í™˜ë¨")
            except Exception as e:
                logger.warning(f"ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì²´í¬ ì‹¤íŒ¨, ê¸°ë³¸ ì²´í¬ ì‚¬ìš©: {e}")
                self._check_gpu_memory_before_training(data_size)
        else:
            # ê¸°ë³¸ ë™ê¸° ë©”ëª¨ë¦¬ ì²´í¬
            self._check_gpu_memory_before_training(data_size)

        # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
        early_stopping_rounds = kwargs.get("early_stopping_rounds", 50)
        num_boost_round = kwargs.get("num_boost_round", 1000)
        feature_names = kwargs.get(
            "feature_names", [f"feature_{i}" for i in range(X.shape[1])]
        )

        # íŠ¹ì„± ì´ë¦„ ì €ì¥
        self.feature_names = feature_names

        try:
            # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ì¤€ë¹„
            if "eval_set" in kwargs:
                eval_set = kwargs["eval_set"]
                train_data = lgb.Dataset(X, label=y, feature_name=feature_names)
                valid_data = lgb.Dataset(
                    eval_set[0][0], label=eval_set[0][1], feature_name=feature_names
                )
            else:
                # ê²€ì¦ ì„¸íŠ¸ê°€ ì—†ìœ¼ë©´ í›ˆë ¨ ë°ì´í„°ì˜ 20%ë¥¼ ê²€ì¦ì— ì‚¬ìš©
                from sklearn.model_selection import train_test_split

                X_train, X_val, y_train, y_val = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                train_data = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)
                valid_data = lgb.Dataset(X_val, label=y_val, feature_name=feature_names)

            # í•™ìŠµ ì‹œì‘
            logger.info(f"LightGBM í›ˆë ¨ ì‹œì‘ (device: {self.params.get('device_type', 'cpu')})")
            start_time = time.time()
            
            self.model = lgb.train(
                self.params,
                train_data,
                num_boost_round=num_boost_round,
                valid_sets=[train_data, valid_data],
                valid_names=["train", "valid"],
                early_stopping_rounds=early_stopping_rounds,
                verbose_eval=100,
            )

            # í•™ìŠµ ì‹œê°„ ê³„ì‚°
            train_time = time.time() - start_time

            # GPU ë©”ëª¨ë¦¬ ì •ë³´ (í›ˆë ¨ í›„)
            gpu_memory_info = self.device_manager.check_memory_usage()

        except Exception as e:
            if "gpu" in str(e).lower() or "cuda" in str(e).lower():
                logger.warning(f"GPU í›ˆë ¨ ì‹¤íŒ¨, CPUë¡œ ì¬ì‹œë„: {e}")
                self._fallback_to_cpu()
                
                # CPUë¡œ ì¬í›ˆë ¨
                return self.fit(X, y, **kwargs)
            else:
                raise

        # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        importance = self.model.feature_importance(importance_type="gain")
        feature_importance = dict(zip(feature_names, importance.tolist()))

        # ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„± ë¡œê¹…
        top_features = sorted(
            feature_importance.items(), key=lambda x: x[1], reverse=True
        )[:10]
        logger.info(f"ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±: {top_features}")

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.metadata.update(
            {
                "train_samples": X.shape[0],
                "features": X.shape[1],
                "best_iteration": self.model.best_iteration,
                "best_score": self.model.best_score,
                "train_time": train_time,
                "feature_importance": feature_importance,
                "device_type": self.params.get("device_type", "cpu"),
                "gpu_memory_info": gpu_memory_info,
            }
        )

        # í›ˆë ¨ ì™„ë£Œ í‘œì‹œ
        self.is_trained = True
        logger.info(
            f"LightGBM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: ìµœì  ë°˜ë³µ={self.model.best_iteration}, "
            f"ìµœì  ì ìˆ˜={self.model.best_score}, ì†Œìš” ì‹œê°„={train_time:.2f}ì´ˆ, "
            f"device={self.params.get('device_type', 'cpu')}"
        )

        return {
            "best_iteration": self.model.best_iteration,
            "best_score": self.model.best_score,
            "train_time": train_time,
            "is_trained": self.is_trained,
            "model_type": self.model_name,
            "device_type": self.params.get("device_type", "cpu"),
            "gpu_memory_info": gpu_memory_info,
        }

    def predict(self, X: np.ndarray, **kwargs) -> np.ndarray:
        """
        LightGBM ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰

        Args:
            X: íŠ¹ì„± ë²¡í„°
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            ì˜ˆì¸¡ ì ìˆ˜
        """
        if not self.is_trained or self.model is None:
            raise ValueError(
                "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit() ë©”ì„œë“œë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )

        logger.info(f"LightGBM ì˜ˆì¸¡ ìˆ˜í–‰: ì…ë ¥ í˜•íƒœ={X.shape}")

        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = self.model.predict(X)

        return predictions

    def evaluate(self, X: np.ndarray, y: np.ndarray, **kwargs) -> Dict[str, Any]:
        """
        LightGBM ëª¨ë¸ í‰ê°€

        Args:
            X: íŠ¹ì„± ë²¡í„°
            y: ì‹¤ì œ íƒ€ê²Ÿ
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            í‰ê°€ ê²°ê³¼
        """
        if not self.is_trained or self.model is None:
            raise ValueError(
                "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit() ë©”ì„œë“œë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )

        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred = self.predict(X)

        # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

        rmse = np.sqrt(mean_squared_error(y, y_pred))
        mae = mean_absolute_error(y, y_pred)
        r2 = r2_score(y, y_pred)

        logger.info(f"LightGBM ëª¨ë¸ í‰ê°€: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

        return {"rmse": rmse, "mae": mae, "r2": r2, "model_type": self.model_name}

    def save(self, path: str) -> bool:
        """
        LightGBM ëª¨ë¸ ì €ì¥

        Args:
            path: ì €ì¥ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if not self.is_trained or self.model is None:
            logger.warning("í•™ìŠµë˜ì§€ ì•Šì€ ëª¨ë¸ì€ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            # ë””ë ‰í† ë¦¬ í™•ì¸
            self._ensure_directory(path)

            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            model_path = path

            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            meta_path = f"{os.path.splitext(path)[0]}.meta.json"

            # ëª¨ë¸ ì €ì¥
            self.model.save_model(model_path)

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(
                    {
                        "model_type": self.model_name,
                        "feature_names": self.feature_names,
                        "params": self.params,
                        "metadata": self.metadata,
                        "saved_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    },
                    f,
                    ensure_ascii=False,
                    indent=2,
                )

            logger.info(f"LightGBM ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")
            return True

        except Exception as e:
            logger.error(f"LightGBM ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def load(self, path: str) -> bool:
        """
        LightGBM ëª¨ë¸ ë¡œë“œ

        Args:
            path: ëª¨ë¸ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(path):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            meta_path = f"{os.path.splitext(path)[0]}.meta.json"

            # ëª¨ë¸ ë¡œë“œ
            self.model = lgb.Booster(model_file=path)

            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(meta_path):
                with open(meta_path, "r", encoding="utf-8") as f:
                    meta_data = json.load(f)
                    self.feature_names = meta_data.get("feature_names", [])
                    self.params = meta_data.get("params", self.params)
                    self.metadata = meta_data.get("metadata", {})

            # í›ˆë ¨ ì™„ë£Œ í‘œì‹œ
            self.is_trained = True
            logger.info(f"LightGBM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
            return True

        except Exception as e:
            logger.error(f"LightGBM ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def get_feature_importance(self, importance_type: str = "gain") -> Dict[str, float]:
        """
        íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜

        Args:
            importance_type: ì¤‘ìš”ë„ íƒ€ì… (gain, split)

        Returns:
            íŠ¹ì„± ì´ë¦„ ë° ì¤‘ìš”ë„ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_trained or self.model is None:
            raise ValueError(
                "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit() ë©”ì„œë“œë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )

        importance = self.model.feature_importance(importance_type=importance_type)

        if not self.feature_names:
            # íŠ¹ì„± ì´ë¦„ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
            self.feature_names = [f"feature_{i}" for i in range(len(importance))]

        return dict(zip(self.feature_names, importance.tolist()))

    # ===== 3ìë¦¬ ì˜ˆì¸¡ ëª¨ë“œ êµ¬í˜„ =====

    def fit_3digit_mode(
        self, X: np.ndarray, y_3digit: np.ndarray, **kwargs
    ) -> Dict[str, Any]:
        """
        3ìë¦¬ ëª¨ë“œ ì „ìš© í›ˆë ¨

        Args:
            X: íŠ¹ì„± ë²¡í„°
            y_3digit: 3ìë¦¬ ì¡°í•© ë ˆì´ë¸” (ì›-í•« ì¸ì½”ë”© ë˜ëŠ” í´ë˜ìŠ¤ ì¸ë±ìŠ¤)
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            Dict[str, Any]: í›ˆë ¨ ê²°ê³¼
        """
        try:
            logger.info(
                f"LightGBM 3ìë¦¬ ëª¨ë“œ í›ˆë ¨ ì‹œì‘: X={X.shape}, y={y_3digit.shape}"
            )

            # í´ë˜ìŠ¤ ë ˆì´ë¸” ë³€í™˜ (ì›-í•« â†’ í´ë˜ìŠ¤ ì¸ë±ìŠ¤)
            if y_3digit.ndim > 1 and y_3digit.shape[1] > 1:
                y_classes = np.argmax(y_3digit, axis=1)
            else:
                y_classes = y_3digit.astype(int)

            # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
            early_stopping_rounds = kwargs.get("early_stopping_rounds", 30)
            num_boost_round = kwargs.get("num_boost_round", 500)
            feature_names = kwargs.get(
                "feature_names", [f"3digit_feature_{i}" for i in range(X.shape[1])]
            )

            # íŠ¹ì„± ì´ë¦„ ì €ì¥
            self.three_digit_feature_names = feature_names

            # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ì¤€ë¹„
            if "eval_set" in kwargs:
                eval_set = kwargs["eval_set"]
                train_data = lgb.Dataset(X, label=y_classes, feature_name=feature_names)
                valid_data = lgb.Dataset(
                    eval_set[0][0], label=eval_set[0][1], feature_name=feature_names
                )
            else:
                from sklearn.model_selection import train_test_split

                X_train, X_val, y_train, y_val = train_test_split(
                    X, y_classes, test_size=0.2, random_state=42, stratify=y_classes
                )
                train_data = lgb.Dataset(
                    X_train, label=y_train, feature_name=feature_names
                )
                valid_data = lgb.Dataset(X_val, label=y_val, feature_name=feature_names)

            # 3ìë¦¬ ëª¨ë¸ í›ˆë ¨
            start_time = time.time()
            self.three_digit_model = lgb.train(
                self.three_digit_params,
                train_data,
                num_boost_round=num_boost_round,
                valid_sets=[train_data, valid_data],
                valid_names=["train", "valid"],
                early_stopping_rounds=early_stopping_rounds,
                verbose_eval=50,
            )

            train_time = time.time() - start_time

            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            self.metadata["3digit_mode"] = {
                "train_samples": X.shape[0],
                "features": X.shape[1],
                "num_classes": self.three_digit_params["num_class"],
                "best_iteration": self.three_digit_model.best_iteration,
                "best_score": self.three_digit_model.best_score,
                "train_time": train_time,
            }

            logger.info(
                f"3ìë¦¬ ëª¨ë“œ í›ˆë ¨ ì™„ë£Œ: ë°˜ë³µ={self.three_digit_model.best_iteration}, "
                f"ì ìˆ˜={self.three_digit_model.best_score}, ì‹œê°„={train_time:.2f}ì´ˆ"
            )

            return {
                "best_iteration": self.three_digit_model.best_iteration,
                "best_score": self.three_digit_model.best_score,
                "train_time": train_time,
                "num_classes": self.three_digit_params["num_class"],
                "is_trained": True,
            }

        except Exception as e:
            logger.error(f"3ìë¦¬ ëª¨ë“œ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def predict_3digit_combinations(
        self, X: np.ndarray, top_k: int = 100, **kwargs
    ) -> List[Tuple[Tuple[int, int, int], float]]:
        """
        3ìë¦¬ ì¡°í•© ì˜ˆì¸¡

        Args:
            X: íŠ¹ì„± ë²¡í„°
            top_k: ìƒìœ„ kê°œ ì¡°í•© ë°˜í™˜
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            List[Tuple[Tuple[int, int, int], float]]: (3ìë¦¬ ì¡°í•©, ì‹ ë¢°ë„) ë¦¬ìŠ¤íŠ¸
        """
        if not self.is_3digit_mode:
            logger.error("3ìë¦¬ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        if self.three_digit_model is None:
            logger.error("3ìë¦¬ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        try:
            logger.info(f"LightGBM 3ìë¦¬ ì˜ˆì¸¡ ìˆ˜í–‰: ì…ë ¥={X.shape}, top_k={top_k}")

            # ì˜ˆì¸¡ ìˆ˜í–‰ (í™•ë¥ )
            predictions = self.three_digit_model.predict(X)

            # ë‹¨ì¼ ìƒ˜í”Œì¸ ê²½ìš° ì°¨ì› ì¡°ì •
            if predictions.ndim == 1:
                predictions = predictions.reshape(1, -1)

            # 3ìë¦¬ ì¡°í•© ìƒì„±
            from itertools import combinations

            all_3digit_combos = list(combinations(range(1, 46), 3))

            results = []

            # ê° ìƒ˜í”Œì— ëŒ€í•´ ìƒìœ„ kê°œ ì˜ˆì¸¡
            for sample_idx in range(predictions.shape[0]):
                sample_probs = predictions[sample_idx]

                # ìƒìœ„ kê°œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ì„ íƒ
                top_indices = np.argsort(sample_probs)[-top_k:][::-1]

                # ì¡°í•©ê³¼ ì‹ ë¢°ë„ ë§¤í•‘
                for idx in top_indices:
                    if idx < len(all_3digit_combos):
                        combo = all_3digit_combos[idx]
                        confidence = float(sample_probs[idx])
                        results.append((combo, confidence))

            # ì‹ ë¢°ë„ ê¸°ì¤€ ì •ë ¬
            results.sort(key=lambda x: x[1], reverse=True)

            logger.info(f"3ìë¦¬ ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results[:top_k]

        except Exception as e:
            logger.error(f"3ìë¦¬ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def evaluate_3digit_mode(
        self, X: np.ndarray, y_3digit: np.ndarray, **kwargs
    ) -> Dict[str, Any]:
        """
        3ìë¦¬ ëª¨ë“œ í‰ê°€

        Args:
            X: íŠ¹ì„± ë²¡í„°
            y_3digit: 3ìë¦¬ ì¡°í•© ë ˆì´ë¸”
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            Dict[str, Any]: í‰ê°€ ê²°ê³¼
        """
        if not self.is_3digit_mode or self.three_digit_model is None:
            return {"error": "3ìë¦¬ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•Šê±°ë‚˜ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ"}

        try:
            # í´ë˜ìŠ¤ ë ˆì´ë¸” ë³€í™˜
            if y_3digit.ndim > 1 and y_3digit.shape[1] > 1:
                y_true = np.argmax(y_3digit, axis=1)
            else:
                y_true = y_3digit.astype(int)

            # ì˜ˆì¸¡ ìˆ˜í–‰
            predictions = self.three_digit_model.predict(X)
            y_pred = np.argmax(predictions, axis=1)

            # ì •í™•ë„ ê³„ì‚°
            accuracy = np.mean(y_true == y_pred)

            # Top-k ì •í™•ë„ ê³„ì‚°
            top_k_accuracies = {}
            for k in [1, 5, 10, 20, 50]:
                top_k_pred = np.argsort(predictions, axis=1)[:, -k:]
                top_k_acc = np.mean(
                    [y_true[i] in top_k_pred[i] for i in range(len(y_true))]
                )
                top_k_accuracies[f"top_{k}_accuracy"] = top_k_acc

            # ì‹ ë¢°ë„ í†µê³„
            max_probs = np.max(predictions, axis=1)
            confidence_stats = {
                "mean_confidence": np.mean(max_probs),
                "std_confidence": np.std(max_probs),
                "min_confidence": np.min(max_probs),
                "max_confidence": np.max(max_probs),
            }

            results = {
                "accuracy": accuracy,
                "samples_evaluated": len(y_true),
                **top_k_accuracies,
                **confidence_stats,
            }

            logger.info(f"3ìë¦¬ ëª¨ë“œ í‰ê°€ ì™„ë£Œ: ì •í™•ë„={accuracy:.4f}")
            return results

        except Exception as e:
            logger.error(f"3ìë¦¬ ëª¨ë“œ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _extract_window_features(self, window_data: List) -> np.ndarray:
        """
        LightGBMìš© ìœˆë„ìš° íŠ¹ì„± ì¶”ì¶œ (BaseModel ë©”ì„œë“œ ì¬ì •ì˜)

        Args:
            window_data: ìœˆë„ìš° ë‹¹ì²¨ ë²ˆí˜¸ ë°ì´í„°

        Returns:
            np.ndarray: ì¶”ì¶œëœ íŠ¹ì„± ë²¡í„°
        """
        try:
            # ê¸°ë³¸ íŠ¹ì„± ì¶”ì¶œ
            base_features = super()._extract_window_features(window_data)

            # LightGBM íŠ¹í™” ì¶”ê°€ íŠ¹ì„±
            all_numbers = []
            for draw in window_data:
                all_numbers.extend(draw.numbers)

            if all_numbers:
                # ê³ ê¸‰ í†µê³„ íŠ¹ì„±
                advanced_features = np.array(
                    [
                        np.percentile(all_numbers, 25),  # Q1
                        np.percentile(all_numbers, 75),  # Q3
                        np.var(all_numbers),  # ë¶„ì‚°
                        len(np.unique(all_numbers)) / len(all_numbers),  # ê³ ìœ ì„± ë¹„ìœ¨
                        np.sum(np.array(all_numbers) % 2)
                        / len(all_numbers),  # í™€ìˆ˜ ë¹„ìœ¨
                    ]
                )
            else:
                advanced_features = np.zeros(5)

            # íŠ¹ì„± ê²°í•©
            combined_features = np.concatenate([base_features, advanced_features])

            return combined_features

        except Exception as e:
            logger.error(f"LightGBM ìœˆë„ìš° íŠ¹ì„± ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return super()._extract_window_features(window_data)

    def optimize_hyperparameters(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        n_trials: int = 50
    ) -> Dict[str, Any]:
        """Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""
        if not OPTUNA_AVAILABLE:
            logger.error("Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}

        def objective(trial: optuna.Trial) -> float:
            param = {
                'objective': 'binary',
                'metric': 'binary_logloss',
                'verbosity': -1,
                'boosting_type': 'gbdt',
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),
                'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),
                'num_leaves': trial.suggest_int('num_leaves', 2, 256),
                'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),
                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),
                'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
            }
            if self.gpu_manager.gpu_available:
                param['device'] = 'gpu'

            model = lgb.LGBMClassifier(**param)
            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], 
                      callbacks=[lgb.early_stopping(10, verbose=False)])
            
            preds_proba = model.predict_proba(X_val)
            
            # í¬ì†Œ í–‰ë ¬ íƒ€ì… ì²´í¬ ê°•í™” ë° ì²˜ë¦¬ ë¡œì§ ë¶„ê¸°
            if SCIPY_SPARSE_AVAILABLE and spmatrix is not None and isinstance(preds_proba, spmatrix):
                dense_preds = preds_proba.toarray()
                preds = dense_preds[:, 1]
            else:
                preds = preds_proba[:, 1]  # type: ignore

            logloss = log_loss(y_val, preds)
            return logloss

        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=n_trials)

        logger.info(f"ìµœì í™” ì™„ë£Œ. Best trial: {study.best_trial.value}")
        logger.info(f"ìµœì  íŒŒë¼ë¯¸í„°: {study.best_params}")
        
        self.params.update(study.best_params)
        self.model = lgb.LGBMClassifier(**self.params)
        
        return study.best_params


if __name__ == "__main__":
    logger.error(
        "ì´ ëª¨ë“ˆì€ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. run/ ë””ë ‰í† ë¦¬ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì‹¤í–‰í•˜ì„¸ìš”."
    )
