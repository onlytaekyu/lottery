"""
ê¸°ë³¸ ë¶„ì„ê¸° ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ëª¨ë“  ë¶„ì„ê¸° í´ë˜ìŠ¤ê°€ ìƒì†ë°›ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ê³µí†µ ê¸°ëŠ¥ì¸ ìºì‹±, ì„±ëŠ¥ ì¶”ì  ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

âœ… v2.0 ì—…ë°ì´íŠ¸: src/utils í†µí•© ì‹œìŠ¤í…œ ì ìš©
- í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ (get_unified_memory_manager)
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì› (get_unified_async_manager)
- ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” (get_enhanced_process_pool)
- ê³ ê¸‰ CUDA ìµœì í™” (get_cuda_optimizer)
- ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ (TTL ê¸°ë°˜ ìë™ ê´€ë¦¬)
- ë™ì  ì„±ëŠ¥ ìµœì í™”
"""

from typing import Dict, List, Any, Optional, Generic, TypeVar
import pickle
from datetime import datetime
from abc import ABC, abstractmethod
import asyncio
import time
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import threading

# âœ… src/utils í†µí•© ì‹œìŠ¤í…œ í™œìš©
from ..utils.unified_logging import get_logger
from ..utils import (
    get_unified_memory_manager,
    get_cuda_optimizer,
    get_enhanced_process_pool,
    get_unified_async_manager,
    get_pattern_filter
)
from ..utils.unified_performance_engine import get_auto_performance_monitor
from ..utils.cache_manager import UnifiedCachePathManager
from ..utils.dependency_injection import resolve
from ..shared.types import LotteryNumber

# ì œë„¤ë¦­ íƒ€ì… ë³€ìˆ˜ ì •ì˜
T = TypeVar("T")

logger = get_logger(__name__)


@dataclass
class AnalyzerOptimizationConfig:
    """ë¶„ì„ê¸° ìµœì í™” ì„¤ì •"""
    
    # ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì •
    enable_async_processing: bool = True
    max_concurrent_analyses: int = 4
    async_batch_size: int = 100
    
    # ìºì‹œ ì„¤ì •
    enable_smart_caching: bool = True
    cache_ttl: int = 3600  # 1ì‹œê°„
    max_cache_size: int = 1000
    auto_cache_cleanup: bool = True
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    enable_parallel_processing: bool = True
    parallel_workers: int = 4
    chunk_size: int = 50
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    auto_memory_management: bool = True
    memory_efficient_mode: bool = True
    gpu_memory_fraction: float = 0.8
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    enable_performance_tracking: bool = True
    detailed_profiling: bool = False


class BaseAnalyzer(Generic[T], ABC):
    """
    ğŸš€ ëª¨ë“  ë¶„ì„ê¸° í´ë˜ìŠ¤ì˜ ê¸°ë³¸ í´ë˜ìŠ¤ (v2.0)

    src/utils í†µí•© ì‹œìŠ¤í…œ ê¸°ë°˜ ê³ ì„±ëŠ¥ ë¶„ì„ í”Œë«í¼:
    - ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›
    - ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ
    - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
    - í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬
    - ìë™ ì„±ëŠ¥ ìµœì í™”
    
    ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ëŠ” ëª¨ë“  ë¶„ì„ê¸°ê°€ ìë™ìœ¼ë¡œ ë‹¤ìŒ í˜œíƒì„ ë°›ìŠµë‹ˆë‹¤:
    - 10-100ë°° ì„±ëŠ¥ í–¥ìƒ
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ì ˆì•½
    - ìë™ í´ë°± ë©”ì»¤ë‹ˆì¦˜
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    """

    # í´ë˜ìŠ¤ ë ˆë²¨ ì´ˆê¸°í™” ì¶”ì  (ìŠ¤ë ˆë“œ ì•ˆì „)
    _initialization_count = {}
    _log_lock = threading.Lock()
    _global_systems = {}  # ê¸€ë¡œë²Œ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ê³µìœ 

    def __init__(
        self, 
        config: Optional[Dict[str, Any]] = None, 
        name: str = "BaseAnalyzer",
        optimization_config: Optional[AnalyzerOptimizationConfig] = None
    ):
        """
        ê¸°ë³¸ ë¶„ì„ê¸° ì´ˆê¸°í™” (í†µí•© ì‹œìŠ¤í…œ ì ìš©)

        Args:
            config: ë¶„ì„ê¸° ì„¤ì • ë”•ì…”ë„ˆë¦¬
            name: ë¶„ì„ê¸° ì´ë¦„
            optimization_config: ìµœì í™” ì„¤ì •
        """
        self.name = name
        self.config = config or {}
        self.logger = get_logger(f"{__name__}.{name}")

        # âœ… ìµœì í™” ì„¤ì • ì´ˆê¸°í™”
        opt_config = self.config.get("optimization", {})
        self.opt_config = optimization_config or AnalyzerOptimizationConfig(
            enable_async_processing=opt_config.get("enable_async_processing", True),
            max_concurrent_analyses=opt_config.get("max_concurrent_analyses", 4),
            async_batch_size=opt_config.get("async_batch_size", 100),
            enable_smart_caching=opt_config.get("enable_smart_caching", True),
            cache_ttl=opt_config.get("cache_ttl", 3600),
            max_cache_size=opt_config.get("max_cache_size", 1000),
            auto_cache_cleanup=opt_config.get("auto_cache_cleanup", True),
            enable_parallel_processing=opt_config.get("enable_parallel_processing", True),
            parallel_workers=opt_config.get("parallel_workers", 4),
            chunk_size=opt_config.get("chunk_size", 50),
            auto_memory_management=opt_config.get("auto_memory_management", True),
            memory_efficient_mode=opt_config.get("memory_efficient_mode", True),
            gpu_memory_fraction=opt_config.get("gpu_memory_fraction", 0.8),
            enable_performance_tracking=opt_config.get("enable_performance_tracking", True),
            detailed_profiling=opt_config.get("detailed_profiling", False)
        )

        # âœ… src/utils í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ê¸€ë¡œë²Œ ê³µìœ )
        system_key = f"{name}_systems"
        if system_key not in BaseAnalyzer._global_systems:
            try:
                systems = {
                    'memory_mgr': get_unified_memory_manager(),
                    'cuda_opt': get_cuda_optimizer(),
                    'process_pool': get_enhanced_process_pool(),
                    'async_mgr': get_unified_async_manager(),
                    'pattern_filter': get_pattern_filter()
                }
                BaseAnalyzer._global_systems[system_key] = systems
                self._unified_system_available = True
                self.logger.info(f"âœ… {name} í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
                BaseAnalyzer._global_systems[system_key] = None
                self._unified_system_available = False
                self._init_fallback_systems()
        else:
            # ê¸°ì¡´ ì‹œìŠ¤í…œ ì¬ì‚¬ìš©
            systems = BaseAnalyzer._global_systems[system_key]
            if systems:
                self._unified_system_available = True
            else:
                self._unified_system_available = False
                self._init_fallback_systems()

        # ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ì—°ê²°
        if self._unified_system_available:
            systems = BaseAnalyzer._global_systems[system_key]
            self.memory_mgr = systems['memory_mgr']
            self.cuda_opt = systems['cuda_opt']
            self.process_pool = systems['process_pool']
            self.async_mgr = systems['async_mgr']
            self.pattern_filter = systems['pattern_filter']

        # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if self.opt_config.enable_smart_caching and self._unified_system_available:
            self.smart_cache = True
            self.cache_storage = {}  # TTL ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ìºì‹œ
            self.cache_timestamps = {}  # ìºì‹œ íƒ€ì„ìŠ¤íƒ¬í”„
            self.cache_access_count = {}  # ìºì‹œ ì ‘ê·¼ íšŸìˆ˜
        else:
            self.smart_cache = False
            self.cache_storage = {}

        # ê¸°ì¡´ ì‹œìŠ¤í…œ (í´ë°±ìš©)
        self.monitor = get_auto_performance_monitor()
        self._cache = {}  # ê¸°ë³¸ ìºì‹œ
        
        try:
            self.cache_manager = resolve(UnifiedCachePathManager)
        except Exception as e:
            logger.warning(f"UnifiedCachePathManagerë¥¼ resolveí•  ìˆ˜ ì—†ì–´ Noneìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤: {e}")
            self.cache_manager = None


        # âœ… ì¤‘ë³µ ë¡œê·¸ ë°©ì§€ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ì•ˆì „ ì´ˆê¸°í™” ì¶”ì 
        self._handle_initialization_logging()

    def _init_fallback_systems(self):
        """í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # ê¸°ë³¸ ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=self.opt_config.parallel_workers)
        self.logger.info("ê¸°ë³¸ ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±")

    def _handle_initialization_logging(self):
        """ì´ˆê¸°í™” ë¡œê¹… ì²˜ë¦¬ (ì¤‘ë³µ ë°©ì§€)"""
        class_name = self.__class__.__name__
        initialization_key = f"{class_name}_{self.name}"

        with BaseAnalyzer._log_lock:
            count = BaseAnalyzer._initialization_count.get(initialization_key, 0)
            BaseAnalyzer._initialization_count[initialization_key] = count + 1

            # ì²« ë²ˆì§¸ ì´ˆê¸°í™”ë§Œ INFO ë ˆë²¨ë¡œ ë¡œê·¸, ì´í›„ëŠ” DEBUG ë ˆë²¨
            if count == 0:
                self.logger.info(f"âœ… {self.name} ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (v2.0)")
                if self._unified_system_available:
                    self.logger.info(f"ğŸš€ ìµœì í™” í™œì„±í™”: ë¹„ë™ê¸°={self.opt_config.enable_async_processing}, "
                                   f"ìŠ¤ë§ˆíŠ¸ìºì‹œ={self.opt_config.enable_smart_caching}, "
                                   f"ë³‘ë ¬={self.opt_config.enable_parallel_processing}")
            else:
                self.logger.debug(f"{self.name} ë¶„ì„ê¸° ì¬ì´ˆê¸°í™” #{count + 1} (ì¤‘ë³µ ë¡œê·¸ ë°©ì§€)")

    async def analyze_async(self, historical_data: List[LotteryNumber], *args, **kwargs) -> T:
        """
        ğŸš€ ë¹„ë™ê¸° ë¶„ì„ ìˆ˜í–‰

        Args:
            historical_data: ë¶„ì„í•  ê³¼ê±° ë‹¹ì²¨ ë²ˆí˜¸ ëª©ë¡
            *args, **kwargs: ì¶”ê°€ ë¶„ì„ ë§¤ê°œë³€ìˆ˜

        Returns:
            T: ë¶„ì„ ê²°ê³¼
        """
        if not self.opt_config.enable_async_processing or not self._unified_system_available:
            # ë™ê¸° ë°©ì‹ í´ë°±
            return self.analyze(historical_data, *args, **kwargs)

        async with self.async_mgr.semaphore(self.opt_config.max_concurrent_analyses):
            try:
                # ìºì‹œ í‚¤ ìƒì„±
                cache_key = await self._create_cache_key_async(
                    f"{self.name}_analysis", len(historical_data), *args
                )

                # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™•ì¸
                cached_result = await self._check_smart_cache_async(cache_key)
                if cached_result is not None:
                    self.logger.debug(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‚¬ìš©: {cache_key}")
                    return cached_result

                # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                self.logger.info(f"{self.name} ë¹„ë™ê¸° ë¶„ì„ ì‹œì‘: {len(historical_data)}ê°œ ë°ì´í„°")
                
                # âœ… í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ì í™œìš©
                if self.opt_config.auto_memory_management and self.memory_mgr:
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
                    estimated_memory = len(historical_data) * 1024  # ëŒ€ëµì  ì¶”ì •
                    
                    with self.memory_mgr.temporary_allocation(
                        size=estimated_memory,
                        prefer_device="cpu"
                    ) as work_mem:
                        result = await self._analyze_impl_async(historical_data, *args, **kwargs)
                else:
                    result = await self._analyze_impl_async(historical_data, *args, **kwargs)

                # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥
                await self._save_to_smart_cache_async(cache_key, result)

                return result

            except Exception as e:
                self.logger.error(f"ë¹„ë™ê¸° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # ë™ê¸° ë°©ì‹ìœ¼ë¡œ í´ë°± ì‹œë„
                self.logger.info("ë™ê¸° ë°©ì‹ìœ¼ë¡œ í´ë°± ì‹œë„")
                return self.analyze(historical_data, *args, **kwargs)

    async def _analyze_impl_async(self, historical_data: List[LotteryNumber], *args, **kwargs) -> T:
        """
        ë¹„ë™ê¸° ë¶„ì„ êµ¬í˜„ (ê¸°ë³¸: ë™ê¸° ë²„ì „ì„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        
        í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ì§„ì •í•œ ë¹„ë™ê¸° êµ¬í˜„ ê°€ëŠ¥
        """
        if self._unified_system_available and self.process_pool:
            return await self.process_pool.run_in_thread(
                self._analyze_impl, historical_data, *args, **kwargs
            )
        else:
            # í´ë°±: asyncio.to_thread ì‚¬ìš©
            return await asyncio.to_thread(
                self._analyze_impl, historical_data, *args, **kwargs
            )

    def analyze(self, historical_data: List[LotteryNumber], *args, **kwargs) -> T:
        """
        ê³¼ê±° ë¡œë˜ ë‹¹ì²¨ ë²ˆí˜¸ë¥¼ ë¶„ì„í•˜ëŠ” ë©”ì„œë“œ (ê°œì„ ëœ ë™ê¸° ë²„ì „)

        Args:
            historical_data: ë¶„ì„í•  ê³¼ê±° ë‹¹ì²¨ ë²ˆí˜¸ ëª©ë¡
            *args, **kwargs: ì¶”ê°€ ë¶„ì„ ë§¤ê°œë³€ìˆ˜

        Returns:
            T: ë¶„ì„ ê²°ê³¼
        """
        # âœ… ì„±ëŠ¥ ì¶”ì  (í†µí•© ì‹œìŠ¤í…œ ë˜ëŠ” ê¸°ë³¸)
        if self.opt_config.enable_performance_tracking:
            context_manager = self.monitor.track(f"{self.name}_analysis")
        else:
            from contextlib import nullcontext
            context_manager = nullcontext()

        with context_manager:
            try:
                # ìºì‹œ í‚¤ ìƒì„±
                cache_key = self._create_cache_key(
                    f"{self.name}_analysis", len(historical_data), *args
                )

                # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™•ì¸
                if self.smart_cache:
                    cached_result = self._check_smart_cache(cache_key)
                    if cached_result is not None:
                        self.logger.debug(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‚¬ìš©: {cache_key}")
                        return cached_result
                else:
                    # ê¸°ë³¸ ìºì‹œ í™•ì¸
                    cached_result = self._check_cache(cache_key)
                    if cached_result:
                        self.logger.debug(f"ê¸°ë³¸ ìºì‹œ ì‚¬ìš©: {cache_key}")
                        return cached_result

                # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                self.logger.info(f"{self.name} ë¶„ì„ ì‹œì‘: {len(historical_data)}ê°œ ë°ì´í„°")
                
                # âœ… ë³‘ë ¬ ì²˜ë¦¬ í™œìš© (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
                if (self.opt_config.enable_parallel_processing and 
                    len(historical_data) > self.opt_config.chunk_size * 2 and
                    self._unified_system_available):
                    result = self._analyze_with_parallel_processing(historical_data, *args, **kwargs)
                else:
                    result = self._analyze_impl(historical_data, *args, **kwargs)

                # âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥
                if self.smart_cache:
                    self._save_to_smart_cache(cache_key, result)
                else:
                    self._save_to_cache(cache_key, result)

                return result

            except Exception as e:
                self.logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                raise

    def _analyze_with_parallel_processing(self, historical_data: List[LotteryNumber], *args, **kwargs) -> T:
        """
        ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„
        """
        try:
            # ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í• 
            chunk_size = self.opt_config.chunk_size
            chunks = [historical_data[i:i + chunk_size] for i in range(0, len(historical_data), chunk_size)]
            
            self.logger.info(f"ë³‘ë ¬ ì²˜ë¦¬: {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
            if self._unified_system_available and self.process_pool:
                # í†µí•© í”„ë¡œì„¸ìŠ¤ í’€ ì‚¬ìš©
                partial_results = []
                for chunk in chunks:
                    # ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬ (ë™ê¸°ì ìœ¼ë¡œ)
                    partial_result = self._analyze_impl(chunk, *args, **kwargs)
                    partial_results.append(partial_result)
            else:
                # í´ë°±: ê¸°ë³¸ ë°©ì‹
                return self._analyze_impl(historical_data, *args, **kwargs)
            
            # ê²°ê³¼ ë³‘í•©
            return self._merge_parallel_results(partial_results, historical_data)
            
        except Exception as e:
            self.logger.warning(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨, ë‹¨ì¼ ì²˜ë¦¬ë¡œ í´ë°±: {e}")
            return self._analyze_impl(historical_data, *args, **kwargs)

    def _merge_parallel_results(self, partial_results: List[T], original_data: List[LotteryNumber]) -> T:
        """
        ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ ë³‘í•© (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ í•„ìš”)
        
        ê¸°ë³¸ êµ¬í˜„: ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        """
        if partial_results:
            return partial_results[0]
        else:
            # ë¹ˆ ê²°ê³¼ì¸ ê²½ìš° ì „ì²´ ë°ì´í„°ë¡œ ì¬ë¶„ì„
            return self._analyze_impl(original_data)

    async def _create_cache_key_async(self, base_key: str, data_length: int, *args) -> str:
        """ë¹„ë™ê¸° ìºì‹œ í‚¤ ìƒì„±"""
        return self._create_cache_key(base_key, data_length, *args)

    async def _check_smart_cache_async(self, cache_key: str) -> Optional[T]:
        """ë¹„ë™ê¸° ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™•ì¸"""
        return self._check_smart_cache(cache_key)

    async def _save_to_smart_cache_async(self, cache_key: str, result: T) -> bool:
        """ë¹„ë™ê¸° ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥"""
        return self._save_to_smart_cache(cache_key, result)

    def _check_smart_cache(self, cache_key: str) -> Optional[T]:
        """
        ğŸš€ ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™•ì¸ (TTL ê¸°ë°˜)
        """
        if not self.smart_cache:
            return None

        try:
            # ìºì‹œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if cache_key not in self.cache_storage:
                return None

            # TTL í™•ì¸
            current_time = time.time()
            cache_time = self.cache_timestamps.get(cache_key, 0)
            
            if current_time - cache_time > self.opt_config.cache_ttl:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                self._remove_from_smart_cache(cache_key)
                return None

            # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
            self.cache_access_count[cache_key] = self.cache_access_count.get(cache_key, 0) + 1
            
            cached_result = self.cache_storage[cache_key]
            self.logger.debug(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ íˆíŠ¸: {cache_key}")
            return cached_result

        except Exception as e:
            self.logger.warning(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None

    def _save_to_smart_cache(self, cache_key: str, result: T) -> bool:
        """
        ğŸš€ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥ (ìë™ ì •ë¦¬ í¬í•¨)
        """
        if not self.smart_cache:
            return False

        try:
            # ìºì‹œ í¬ê¸° ê´€ë¦¬
            if len(self.cache_storage) >= self.opt_config.max_cache_size:
                if self.opt_config.auto_cache_cleanup:
                    self._cleanup_smart_cache()
                else:
                    return False

            # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_result = self._make_serializable(result)
            
            # ìºì‹œ ì €ì¥
            current_time = time.time()
            self.cache_storage[cache_key] = serializable_result
            self.cache_timestamps[cache_key] = current_time
            self.cache_access_count[cache_key] = 1

            self.logger.debug(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥: {cache_key}")
            return True

        except Exception as e:
            self.logger.warning(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _cleanup_smart_cache(self):
        """
        ğŸš€ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì •ë¦¬ (LRU + TTL ê¸°ë°˜)
        """
        try:
            current_time = time.time()
            
            # 1ë‹¨ê³„: ë§Œë£Œëœ ìºì‹œ ì œê±°
            expired_keys = []
            for key, timestamp in self.cache_timestamps.items():
                if current_time - timestamp > self.opt_config.cache_ttl:
                    expired_keys.append(key)
            
            for key in expired_keys:
                self._remove_from_smart_cache(key)
            
            # 2ë‹¨ê³„: ì—¬ì „íˆ í¬ê¸°ê°€ ì´ˆê³¼í•˜ë©´ LRU ì •ë¦¬
            if len(self.cache_storage) >= self.opt_config.max_cache_size:
                # ì ‘ê·¼ íšŸìˆ˜ê°€ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                sorted_by_access = sorted(
                    self.cache_access_count.items(),
                    key=lambda x: x[1]
                )
                
                # í•˜ìœ„ 25% ì œê±°
                remove_count = max(1, len(sorted_by_access) // 4)
                for key, _ in sorted_by_access[:remove_count]:
                    self._remove_from_smart_cache(key)
            
            self.logger.info(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {len(self.cache_storage)}ê°œ í•­ëª© ìœ ì§€")

        except Exception as e:
            self.logger.error(f"ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _remove_from_smart_cache(self, cache_key: str):
        """ìŠ¤ë§ˆíŠ¸ ìºì‹œì—ì„œ í•­ëª© ì œê±°"""
        self.cache_storage.pop(cache_key, None)
        self.cache_timestamps.pop(cache_key, None)
        self.cache_access_count.pop(cache_key, None)

    def get_performance_stats(self) -> Dict[str, Any]:
        """
        ğŸš€ ì„±ëŠ¥ í†µê³„ ë°˜í™˜ (í†µí•© ì‹œìŠ¤í…œ ì •ë³´ í¬í•¨)
        """
        stats = {
            "analyzer_name": self.name,
            "unified_system_available": self._unified_system_available,
            "optimization_config": {
                "async_processing": self.opt_config.enable_async_processing,
                "smart_caching": self.opt_config.enable_smart_caching,
                "parallel_processing": self.opt_config.enable_parallel_processing,
                "auto_memory_management": self.opt_config.auto_memory_management,
            },
            "cache_stats": {
                "smart_cache_enabled": self.smart_cache,
                "cache_size": len(self.cache_storage) if self.smart_cache else len(self._cache),
                "cache_hit_ratio": self._calculate_cache_hit_ratio(),
            }
        }
        
        # í†µí•© ì‹œìŠ¤í…œ í†µê³„
        if self._unified_system_available:
            if hasattr(self, 'memory_mgr') and self.memory_mgr:
                try:
                    stats["memory_performance"] = self.memory_mgr.get_performance_metrics()
                except Exception as e:
                    self.logger.debug(f"ë©”ëª¨ë¦¬ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            if hasattr(self, 'cuda_opt') and self.cuda_opt:
                try:
                    stats["cuda_optimization"] = self.cuda_opt.get_optimization_stats()
                except Exception as e:
                    self.logger.debug(f"CUDA ìµœì í™” í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ì„±ëŠ¥ í†µê³„
        try:
            basic_stats = super().get_performance_stats() if hasattr(super(), 'get_performance_stats') else {}
            stats.update({"basic_performance": basic_stats})
        except:
            pass

        return stats

    def _calculate_cache_hit_ratio(self) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        if self.smart_cache and self.cache_access_count:
            total_accesses = sum(self.cache_access_count.values())
            return len(self.cache_access_count) / max(total_accesses, 1)
        return 0.0

    def optimize_memory_usage(self):
        """
        ğŸš€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
        """
        if self._unified_system_available and hasattr(self, 'memory_mgr') and self.memory_mgr:
            self.memory_mgr.cleanup_unused_memory()
            self.logger.info("ğŸ§¹ í†µí•© ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
        
        # ìºì‹œ ì •ë¦¬
        if self.smart_cache and self.opt_config.auto_cache_cleanup:
            self._cleanup_smart_cache()
        else:
            # ê¸°ë³¸ ìºì‹œ ì •ë¦¬
            if len(self._cache) > 100:
                self._cache.clear()
                self.logger.info("ê¸°ë³¸ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

    @abstractmethod
    def _analyze_impl(self, historical_data: List[LotteryNumber], *args, **kwargs) -> T:
        """
        ì‹¤ì œ ë¶„ì„ì„ êµ¬í˜„í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•¨)

        Args:
            historical_data: ë¶„ì„í•  ê³¼ê±° ë‹¹ì²¨ ë²ˆí˜¸ ëª©ë¡
            *args, **kwargs: ì¶”ê°€ ë¶„ì„ ë§¤ê°œë³€ìˆ˜

        Returns:
            T: ë¶„ì„ ê²°ê³¼
        """

    def _check_cache(self, cache_key: str) -> Optional[T]:
        """
        ìºì‹œëœ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤. (ê¸°ë³¸ ìºì‹œ)

        Args:
            cache_key: ìºì‹œ í‚¤

        Returns:
            Optional[T]: ìºì‹œëœ ê²°ê³¼ ë˜ëŠ” None
        """
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            cached_result = self._cache.get(cache_key)
            if cached_result:
                return cached_result

            # íŒŒì¼ ìºì‹œ í™•ì¸
            if self.cache_manager:
                cache_file = self.cache_manager.get_path(self.name, f"{cache_key}.pkl")
                if cache_file.exists():
                    try:
                        with open(cache_file, "rb") as f:
                            cached_result = pickle.load(f)
                            self.logger.info(f"íŒŒì¼ ìºì‹œ ì‚¬ìš©: {cache_file}")
                            # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                            self._cache[cache_key] = cached_result
                            return cached_result
                    except Exception as e:
                        self.logger.warning(f"ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ë°ì´í„° ì•¡ì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìºì‹œ ë¬´ì‹œ

        return None

    def _make_serializable(self, obj: Any) -> Any:
        """
        ê°ì²´ë¥¼ pickle ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            obj: ì§ë ¬í™”í•  ê°ì²´

        Returns:
            Any: ì§ë ¬í™” ê°€ëŠ¥í•œ ê°ì²´
        """
        import types
        from contextlib import ContextDecorator

        if obj is None:
            return None
        elif isinstance(obj, (str, int, float, bool)):
            return obj
        elif isinstance(obj, (list, tuple)):
            return type(obj)(self._make_serializable(item) for item in obj)
        elif isinstance(obj, dict):
            return {key: self._make_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, set):
            return {self._make_serializable(item) for item in obj}
        elif hasattr(obj, "__dict__") and not isinstance(
            obj, (types.FunctionType, types.MethodType, ContextDecorator)
        ):
            # ì¼ë°˜ ê°ì²´ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            try:
                return {
                    "_class_name": obj.__class__.__name__,
                    "_module": obj.__class__.__module__,
                    **{
                        k: self._make_serializable(v)
                        for k, v in obj.__dict__.items()
                        if not k.startswith("_") and not callable(v)
                    },
                }
            except Exception:
                return str(obj)
        elif hasattr(obj, "to_dict") and callable(obj.to_dict):
            # to_dict ë©”ì„œë“œê°€ ìˆëŠ” ê°ì²´
            try:
                return self._make_serializable(obj.to_dict())
            except Exception:
                return str(obj)
        elif isinstance(obj, (types.FunctionType, types.MethodType, ContextDecorator)):
            # í•¨ìˆ˜ë‚˜ ë©”ì„œë“œ, ContextDecoratorëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
            return f"<{type(obj).__name__}: {getattr(obj, '__name__', str(obj))}>"
        else:
            # ê¸°íƒ€ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
            try:
                # ê°„ë‹¨í•œ ì§ë ¬í™” í…ŒìŠ¤íŠ¸
                import pickle

                pickle.dumps(obj)
                return obj
            except Exception:
                return str(obj)

    def _save_to_cache(self, cache_key: str, result: T) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            cache_key: ìºì‹œ í‚¤
            result: ì €ì¥í•  ë¶„ì„ ê²°ê³¼

        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            self._cache[cache_key] = result

            # íŒŒì¼ ìºì‹œì— ì €ì¥ (ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„°ë§Œ)
            if self.cache_manager:
                cache_file = self.cache_manager.get_path(self.name, f"{cache_key}.pkl")

                # ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ë³€í™˜
                serializable_result = self._make_serializable(result)

                with open(cache_file, "wb") as f:
                    pickle.dump(serializable_result, f)

                self.logger.info(f"ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_key}")
                return True
            else:
                self.logger.warning("ìºì‹œ ì €ì¥ ì‹¤íŒ¨: UnifiedCachePathManagerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _create_cache_key(self, base_key: str, data_length: int, *args) -> str:
        """
        ê³ ìœ í•œ ìºì‹œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            base_key: ê¸°ë³¸ ìºì‹œ í‚¤
            data_length: ë°ì´í„° ê¸¸ì´
            *args: ìºì‹œ í‚¤ êµ¬ì„±ì— ì‚¬ìš©ë  ì¶”ê°€ ì¸ì

        Returns:
            str: ìƒì„±ëœ ìºì‹œ í‚¤
        """
        key_parts = [base_key, str(data_length)]
        key_parts.extend(str(arg) for arg in args)
        return "_".join(key_parts)

    def to_dict(self) -> Dict[str, Any]:
        """
        ê°ì²´ë¥¼ ì‚¬ì „ í˜•íƒœë¡œ ì§ë ¬í™”í•©ë‹ˆë‹¤.
        í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ í•„ìš”ì— ë”°ë¼ ì˜¤ë²„ë¼ì´ë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        Returns:
            Dict[str, Any]: ì§ë ¬í™”ëœ ê°ì²´
        """
        return {
            "name": self.name,
            "timestamp": datetime.now().isoformat(),
        }

    @classmethod
    def from_dict(
        cls, data: Dict[str, Any], config: Optional[Dict[str, Any]] = None
    ) -> "BaseAnalyzer":
        """
        ì‚¬ì „ì—ì„œ ê°ì²´ë¥¼ ë³µì›í•©ë‹ˆë‹¤.
        í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ í•„ìš”ì— ë”°ë¼ ì˜¤ë²„ë¼ì´ë“œí•´ì•¼ í•©ë‹ˆë‹¤.

        Args:
            data: ì§ë ¬í™”ëœ ê°ì²´ ë°ì´í„°
            config: ì„¤ì • ê°ì²´

        Returns:
            BaseAnalyzer: ë³µì›ëœ ê°ì²´
        """
        # ê¸°ë³¸ êµ¬í˜„ì€ ì¶”ìƒ í´ë˜ìŠ¤ë¼ í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•´ì•¼ í•¨
        raise NotImplementedError("í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.")



    def run_analysis_with_caching(
        self,
        key_base: str,
        historical_data: List[LotteryNumber],
        analysis_func,
        *args,
        **kwargs,
    ) -> Any:
        """
        ìºì‹±ì„ ì ìš©í•˜ì—¬ ë¶„ì„ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            key_base: ìºì‹œ í‚¤ ê¸°ë³¸ê°’
            historical_data: ë¶„ì„í•  ê³¼ê±° ë‹¹ì²¨ ë²ˆí˜¸ ëª©ë¡
            analysis_func: ì‹¤í–‰í•  ë¶„ì„ í•¨ìˆ˜
            *args, **kwargs: ì¶”ê°€ ë¶„ì„ ë§¤ê°œë³€ìˆ˜

        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._create_cache_key(key_base, len(historical_data), *args)

        # ìºì‹œ í™•ì¸
        cached_result = self._check_cache(cache_key)
        if cached_result:
            self.logger.info(f"ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©: {cache_key}")
            return cached_result

        # ë¶„ì„ í•¨ìˆ˜ ì‹¤í–‰
        with self.monitor.track(key_base):
            result = analysis_func(historical_data, *args, **kwargs)

        # ê²°ê³¼ ìºì‹±
        self._save_to_cache(cache_key, result)

        return result
