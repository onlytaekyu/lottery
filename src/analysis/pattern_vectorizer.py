"""
íŒ¨í„´ ë²¡í„°í™” ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ë¥¼ ë²¡í„°í™”í•˜ì—¬ ML/DL ëª¨ë¸ ìž…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆê²Œ í•©ë‹ˆë‹¤.
"""

import numpy as np
import os
import logging
import hashlib
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple, Set
from datetime import datetime
from collections import Counter
import gc
import torch

from ..utils.error_handler_refactored import get_logger
from ..utils.unified_performance import performance_monitor
from ..utils.unified_config import ConfigProxy
from ..utils.normalizer import Normalizer
from ..shared.types import LotteryNumber, PatternAnalysis, PatternFeatures
from ..shared.graph_utils import calculate_segment_entropy

# type: ignore ì£¼ì„ ì¶”ê°€
# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)


class PatternVectorizer:
    """
    íŒ¨í„´ ë²¡í„°í™”ê¸° (ë‹¨ìˆœ ëž˜í¼)

    EnhancedPatternVectorizerë¥¼ ëž˜í•‘í•˜ëŠ” ë‹¨ìˆœí•œ ì¸í„°íŽ˜ì´ìŠ¤
    """

    def __init__(self, config: Optional[Union[Dict[str, Any], ConfigProxy]] = None):
        """ë‹¨ìˆœ ëž˜í¼ ì´ˆê¸°í™”"""
        # ðŸš¨ ì¤‘ë³µ ì´ˆê¸°í™” ì™„ì „ ë°©ì§€
        if hasattr(self, "_wrapper_initialized"):
            return
        self._wrapper_initialized = True

        # ê¸°ë³¸ ì„¤ì •
        self.config = config if config is not None else {}
        self.logger = get_logger(__name__)

        # í–¥ìƒëœ ì‹œìŠ¤í…œ ì§ì ‘ ì—°ê²° (ë‹¨ìˆœí™”)
        try:
            from .enhanced_pattern_vectorizer import EnhancedPatternVectorizer

            self._enhanced = EnhancedPatternVectorizer(self.config)
            self.feature_names = self._enhanced.get_feature_names()
            self.vector_dimensions = len(self.feature_names)
            self.logger.info("âœ… ëž˜í¼ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"ëž˜í¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._enhanced = None
            self.feature_names = []
            self.vector_dimensions = 0

    def vectorize_full_analysis(self, full_analysis: Dict[str, Any]) -> np.ndarray:
        """ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ ë²¡í„°í™” (ëž˜í¼)"""
        if self._enhanced:
            try:
                vector, names = self._enhanced.vectorize_extended_features(
                    full_analysis
                )
                return vector
            except Exception as e:
                self.logger.error(f"í–¥ìƒëœ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
                return np.zeros(168, dtype=np.float32)
        else:
            self.logger.warning("í–¥ìƒëœ ì‹œìŠ¤í…œ ì—†ìŒ - ì˜ë²¡í„° ë°˜í™˜")
            return np.zeros(168, dtype=np.float32)

    def get_feature_names(self) -> List[str]:
        """íŠ¹ì„± ì´ë¦„ ë°˜í™˜"""
        if self._enhanced:
            return self._enhanced.get_feature_names()
        return [f"feature_{i+1}" for i in range(168)]

    def save_vector_to_file(
        self,
        vector: np.ndarray,
        feature_names: List[str],
        filename: str = "feature_vector_full.npy",
    ) -> bool:
        """ë²¡í„°ë¥¼ íŒŒì¼ë¡œ ì €ìž¥"""
        try:
            from pathlib import Path
            import json

            cache_path = Path("data/cache")
            cache_path.mkdir(parents=True, exist_ok=True)

            # ë²¡í„° ì €ìž¥
            vector_path = cache_path / filename
            np.save(vector_path, vector)

            # íŠ¹ì„± ì´ë¦„ ì €ìž¥
            names_filename = filename.replace(".npy", ".names.json")
            names_path = cache_path / names_filename
            with open(names_path, "w", encoding="utf-8") as f:
                json.dump(feature_names, f, ensure_ascii=False, indent=2)

            # ë²¡í„° í’ˆì§ˆ ì •ë³´
            zero_ratio = (vector == 0).sum() / len(vector) * 100

            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° ìˆ˜ì • (ì •ê·œí™”ëœ ë°©ì‹)
            if len(vector) > 0:
                # ë²¡í„°ë¥¼ í™•ë¥  ë¶„í¬ë¡œ ì •ê·œí™”
                vector_normalized = (
                    vector / np.sum(vector) if np.sum(vector) > 0 else vector
                )
                # 0ì´ ì•„ë‹Œ ê°’ë“¤ì— ëŒ€í•´ì„œë§Œ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                non_zero_mask = vector_normalized > 0
                if np.any(non_zero_mask):
                    entropy = -np.sum(
                        vector_normalized[non_zero_mask]
                        * np.log(vector_normalized[non_zero_mask])
                    )
                else:
                    entropy = 0.0
            else:
                entropy = 0.0

            self.logger.info(
                f"âœ… ë²¡í„° ì €ìž¥ ì™„ë£Œ: {vector_path} ({vector_path.stat().st_size:,} bytes)"
            )
            self.logger.info(f"   - ë²¡í„° ì°¨ì›: {vector.shape}")
            self.logger.info(f"   - ë°ì´í„° íƒ€ìž…: {vector.dtype}")
            self.logger.info(f"   - íŠ¹ì„± ì´ë¦„ ìˆ˜: {len(feature_names)}")
            self.logger.info(f"âœ… íŠ¹ì„± ì´ë¦„ ì €ìž¥ ì™„ë£Œ: {names_path}")
            self.logger.info(f"ðŸ“Š ë²¡í„° í’ˆì§ˆ:")
            self.logger.info(f"   - 0ê°’ ë¹„ìœ¨: {zero_ratio:.1f}%")
            self.logger.info(f"   - ì—”íŠ¸ë¡œí”¼: {entropy:.3f}")
            self.logger.info(f"   - ìµœì†Ÿê°’: {vector.min():.3f}")
            self.logger.info(f"   - ìµœëŒ“ê°’: {vector.max():.3f}")
            self.logger.info(f"   - í‰ê· ê°’: {vector.mean():.3f}")

            return True

        except Exception as e:
            self.logger.error(f"ë²¡í„° ì €ìž¥ ì‹¤íŒ¨: {e}")
            return False

    def _get_config_value(self, key: str, default: Any = None) -> Any:
        """ì„¤ì • ê°’ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            keys = key.split(".")
            value = self.config
            for k in keys:
                value = value[k]
            return value
        except (KeyError, TypeError):
            return default
