#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ë¶„ì„ê¸° íŒ©í† ë¦¬ ëª¨ë“ˆ

ì¤‘ë³µ ì´ˆê¸°í™”ë¥¼ ë°©ì§€í•˜ê³  ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import hashlib
import json
import threading
from typing import Dict, Any, Optional, Union
from ..utils.unified_logging import get_logger

logger = get_logger(__name__)


class AnalyzerFactory:
    """ë¶„ì„ê¸° íŒ©í† ë¦¬ í´ë˜ìŠ¤ - ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬"""

    _instance = None
    _lock = threading.Lock()
    _analyzers: Dict[str, Any] = {}

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "_initialized"):
            self._initialized = True
            logger.debug("AnalyzerFactory ì´ˆê¸°í™” ì™„ë£Œ")

    def _create_config_hash(self, config: Dict[str, Any]) -> str:
        """ì„¤ì • ë”•ì…”ë„ˆë¦¬ì˜ í•´ì‹œê°’ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì„¤ì •ì„ ì •ë ¬ëœ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í•´ì‹œ ìƒì„±
            config_str = json.dumps(config, sort_keys=True, default=str)
            return hashlib.md5(config_str.encode()).hexdigest()[:8]
        except Exception as e:
            logger.warning(f"ì„¤ì • í•´ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            return "default"

    def get_analyzer(self, analyzer_type: str, config: Dict[str, Any]) -> Any:
        """ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
        # ì„¤ì • í•´ì‹œ ëŒ€ì‹  ê°„ë‹¨í•œ íƒ€ì… ê¸°ë°˜ ìºì‹±ìœ¼ë¡œ ë³€ê²½ (ë” ê°•ë ¥í•œ ì¤‘ë³µ ë°©ì§€)
        cache_key = f"{analyzer_type}_singleton"

        with self._lock:
            # ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ë°˜í™˜
            if cache_key in self._analyzers:
                logger.debug(f"ìºì‹œëœ {analyzer_type} ë¶„ì„ê¸° ì¬ì‚¬ìš©: {cache_key}")
                return self._analyzers[cache_key]

            # ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            logger.debug(f"ìƒˆë¡œìš´ {analyzer_type} ë¶„ì„ê¸° ìƒì„± ì‹œì‘...")
            analyzer = self._create_analyzer(analyzer_type, config)
            if analyzer is not None:
                self._analyzers[cache_key] = analyzer
                logger.info(f"âœ… {analyzer_type} ë¶„ì„ê¸° íŒ©í† ë¦¬ ìƒì„± ì™„ë£Œ")
            else:
                logger.error(f"âŒ {analyzer_type} ë¶„ì„ê¸° ìƒì„± ì‹¤íŒ¨")

            return analyzer

    def _create_analyzer(
        self, analyzer_type: str, config: Dict[str, Any]
    ) -> Optional[Any]:
        """ì‹¤ì œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if analyzer_type == "pattern":
                from .pattern_analyzer import PatternAnalyzer

                return PatternAnalyzer(config)

            elif analyzer_type == "distribution":
                from .distribution_analyzer import DistributionAnalyzer

                return DistributionAnalyzer(config)

            elif analyzer_type == "roi":
                from .roi_analyzer import ROIAnalyzer

                return ROIAnalyzer(config)

            elif analyzer_type == "pair":
                from .pair_analyzer import PairAnalyzer

                return PairAnalyzer(config)

            elif analyzer_type == "vectorizer":
                from .enhanced_pattern_vectorizer import EnhancedPatternVectorizer

                return EnhancedPatternVectorizer(config)

            # ğŸ”¥ ëª¨ë“  11ê°œ ë¶„ì„ê¸° ì™„ì „ ì§€ì›
            elif analyzer_type == "cluster":
                from .cluster_analyzer import ClusterAnalyzer

                return ClusterAnalyzer(config)

            elif analyzer_type == "trend":
                from .trend_analyzer import TrendAnalyzer

                return TrendAnalyzer(config)

            elif analyzer_type == "overlap":
                from .overlap_analyzer import OverlapAnalyzer

                return OverlapAnalyzer(config)

            elif analyzer_type == "structural":
                from .structural_analyzer import StructuralAnalyzer

                return StructuralAnalyzer(config)

            elif analyzer_type == "statistical":
                from .statistical_analyzer import StatisticalAnalyzer

                return StatisticalAnalyzer(config)

            elif analyzer_type == "negative_sample":
                from .negative_sample_generator import NegativeSampleGenerator

                return NegativeSampleGenerator(config)

            elif analyzer_type == "unified":
                from .unified_analyzer import UnifiedAnalyzer

                return UnifiedAnalyzer(config)

            # ===== ì‹ ê·œ ê³ ê¸‰ ë¶„ì„ê¸° ì¶”ê°€ =====
            elif analyzer_type == "bayesian":
                from .bayesian_analyzer import BayesianAnalyzer

                return BayesianAnalyzer(config)

            elif analyzer_type == "trend_v2":
                from .trend_analyzer_v2 import TrendAnalyzerV2

                return TrendAnalyzerV2(config)

            elif analyzer_type == "ensemble":
                from .ensemble_analyzer import EnsembleAnalyzer

                return EnsembleAnalyzer(config)

            elif analyzer_type == "graph_network":
                from .graph_network_analyzer import GraphNetworkAnalyzer

                return GraphNetworkAnalyzer(config)

            elif analyzer_type == "meta_feature":
                from .meta_feature_analyzer import MetaFeatureAnalyzer

                return MetaFeatureAnalyzer(config)

            elif analyzer_type == "optimized_vectorizer":
                from .optimized_pattern_vectorizer import OptimizedPatternVectorizer

                return OptimizedPatternVectorizer(config)

            elif analyzer_type == "three_digit_engine":
                from .three_digit_expansion_engine import ThreeDigitExpansionEngine

                return ThreeDigitExpansionEngine(config)

            elif analyzer_type == "three_digit_predictor":
                from .three_digit_priority_predictor import ThreeDigitPriorityPredictor

                return ThreeDigitPriorityPredictor(config)

            else:
                raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„ê¸° íƒ€ì…: {analyzer_type}")

        except Exception as e:
            logger.error(f"{analyzer_type} ë¶„ì„ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def clear_cache(self):
        """ìºì‹œëœ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤."""
        with self._lock:
            self._analyzers.clear()
            logger.info("ë¶„ì„ê¸° ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    def get_cache_info(self) -> Dict[str, int]:
        """ìºì‹œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        with self._lock:
            return {
                "cached_analyzers": len(self._analyzers),
                "analyzer_types": list(
                    set(key.split("_")[0] for key in self._analyzers.keys())
                ),
            }


# ì „ì—­ íŒ©í† ë¦¬ ì¸ìŠ¤í„´ìŠ¤
analyzer_factory = AnalyzerFactory()


def get_analyzer(analyzer_type: str, config: Dict[str, Any]) -> Any:
    """ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” í¸ì˜ í•¨ìˆ˜"""
    return analyzer_factory.get_analyzer(analyzer_type, config)


def clear_analyzer_cache():
    """ë¶„ì„ê¸° ìºì‹œë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    analyzer_factory.clear_cache()
